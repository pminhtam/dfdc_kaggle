{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://github.com/qubvel/residual_attention_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tampm/miniconda3/envs/face/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/tampm/miniconda3/envs/face/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/tampm/miniconda3/envs/face/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/tampm/miniconda3/envs/face/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/tampm/miniconda3/envs/face/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/tampm/miniconda3/envs/face/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/tampm/miniconda3/envs/face/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/tampm/miniconda3/envs/face/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/tampm/miniconda3/envs/face/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/tampm/miniconda3/envs/face/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/tampm/miniconda3/envs/face/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/tampm/miniconda3/envs/face/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "# config.gpu_options.visible_device_list = \"0\"\n",
    "set_session(tf.Session(config=config))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import UpSampling2D\n",
    "from keras.layers import Activation\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.layers import Add\n",
    "from keras.layers import Multiply\n",
    "from keras.layers import Lambda\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Activation\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "\n",
    "\n",
    "\n",
    "import keras\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(input, input_channels=None, output_channels=None, kernel_size=(3, 3), stride=1):\n",
    "    \"\"\"\n",
    "    full pre-activation residual block\n",
    "    https://arxiv.org/pdf/1603.05027.pdf\n",
    "    \"\"\"\n",
    "    if output_channels is None:\n",
    "        output_channels = input.get_shape()[-1].value\n",
    "    if input_channels is None:\n",
    "        input_channels = output_channels // 4\n",
    "\n",
    "    strides = (stride, stride)\n",
    "\n",
    "    x = BatchNormalization()(input)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(input_channels, (1, 1))(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(input_channels, kernel_size, padding='same', strides=stride)(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(output_channels, (1, 1), padding='same')(x)\n",
    "\n",
    "    if input_channels != output_channels or stride != 1:\n",
    "        input = Conv2D(output_channels, (1, 1), padding='same', strides=strides)(input)\n",
    "\n",
    "    x = Add()([x, input])\n",
    "    return x\n",
    "\n",
    "\n",
    "def attention_block(input, input_channels=None, output_channels=None, encoder_depth=1):\n",
    "    \"\"\"\n",
    "    attention block\n",
    "    https://arxiv.org/abs/1704.06904\n",
    "    \"\"\"\n",
    "\n",
    "    p = 1\n",
    "    t = 2\n",
    "    r = 1\n",
    "\n",
    "    if input_channels is None:\n",
    "        input_channels = input.get_shape()[-1].value\n",
    "    if output_channels is None:\n",
    "        output_channels = input_channels\n",
    "\n",
    "    # First Residual Block\n",
    "    for i in range(p):\n",
    "        input = residual_block(input)\n",
    "\n",
    "    # Trunc Branch\n",
    "    output_trunk = input\n",
    "    for i in range(t):\n",
    "        output_trunk = residual_block(output_trunk)\n",
    "\n",
    "    # Soft Mask Branch\n",
    "\n",
    "    ## encoder\n",
    "    ### first down sampling\n",
    "    output_soft_mask = MaxPool2D(padding='same')(input)  # 32x32\n",
    "    for i in range(r):\n",
    "        output_soft_mask = residual_block(output_soft_mask)\n",
    "\n",
    "    skip_connections = []\n",
    "    for i in range(encoder_depth - 1):\n",
    "\n",
    "        ## skip connections\n",
    "        output_skip_connection = residual_block(output_soft_mask)\n",
    "        skip_connections.append(output_skip_connection)\n",
    "        # print ('skip shape:', output_skip_connection.get_shape())\n",
    "\n",
    "        ## down sampling\n",
    "        output_soft_mask = MaxPool2D(padding='same')(output_soft_mask)\n",
    "        for _ in range(r):\n",
    "            output_soft_mask = residual_block(output_soft_mask)\n",
    "\n",
    "            ## decoder\n",
    "    skip_connections = list(reversed(skip_connections))\n",
    "    for i in range(encoder_depth - 1):\n",
    "        ## upsampling\n",
    "        for _ in range(r):\n",
    "            output_soft_mask = residual_block(output_soft_mask)\n",
    "        output_soft_mask = UpSampling2D()(output_soft_mask)\n",
    "        ## skip connections\n",
    "        output_soft_mask = Add()([output_soft_mask, skip_connections[i]])\n",
    "\n",
    "    ### last upsampling\n",
    "    for i in range(r):\n",
    "        output_soft_mask = residual_block(output_soft_mask)\n",
    "    output_soft_mask = UpSampling2D()(output_soft_mask)\n",
    "\n",
    "    ## Output\n",
    "    output_soft_mask = Conv2D(input_channels, (1, 1))(output_soft_mask)\n",
    "    output_soft_mask = Conv2D(input_channels, (1, 1))(output_soft_mask)\n",
    "    output_soft_mask = Activation('sigmoid')(output_soft_mask)\n",
    "\n",
    "    # Attention: (1 + output_soft_mask) * output_trunk\n",
    "    output = Lambda(lambda x: x + 1)(output_soft_mask)\n",
    "    output = Multiply()([output, output_trunk])  #\n",
    "\n",
    "    # Last Residual Block\n",
    "    for i in range(p):\n",
    "        output = residual_block(output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AttentionResNet92(shape=(224, 224, 3), n_channels=64, n_classes=100,\n",
    "                      dropout=0, regularization=0.01):\n",
    "    \"\"\"\n",
    "    Attention-92 ResNet\n",
    "    https://arxiv.org/abs/1704.06904\n",
    "    \"\"\"\n",
    "    regularizer = l2(regularization)\n",
    "\n",
    "    input_ = Input(shape=shape)\n",
    "    x = Conv2D(n_channels, (7, 7), strides=(2, 2), padding='same')(input_) # 112x112\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)  # 56x56\n",
    "\n",
    "    x = residual_block(x, output_channels=n_channels * 4)  # 56x56\n",
    "    x = attention_block(x, encoder_depth=3)  # bottleneck 7x7\n",
    "\n",
    "    x = residual_block(x, output_channels=n_channels * 8, stride=2)  # 28x28\n",
    "    x = attention_block(x, encoder_depth=2)  # bottleneck 7x7\n",
    "    x = attention_block(x, encoder_depth=2)  # bottleneck 7x7\n",
    "\n",
    "    x = residual_block(x, output_channels=n_channels * 16, stride=2)  # 14x14\n",
    "    x = attention_block(x, encoder_depth=1)  # bottleneck 7x7\n",
    "    x = attention_block(x, encoder_depth=1)  # bottleneck 7x7\n",
    "    x = attention_block(x, encoder_depth=1)  # bottleneck 7x7\n",
    "\n",
    "    x = residual_block(x, output_channels=n_channels * 32, stride=2)  # 7x7\n",
    "    x = residual_block(x, output_channels=n_channels * 32)\n",
    "    x = residual_block(x, output_channels=n_channels * 32)\n",
    "\n",
    "    pool_size = (x.get_shape()[1].value, x.get_shape()[2].value)\n",
    "    x = AveragePooling2D(pool_size=pool_size, strides=(1, 1))(x)\n",
    "    x = Flatten()(x)\n",
    "    if dropout:\n",
    "        x = Dropout(dropout)(x)\n",
    "    output = Dense(n_classes, kernel_regularizer=regularizer, activation='softmax')(x)\n",
    "\n",
    "    model = Model(input_, output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AttentionResNet92(shape=(128, 128, 3),n_channels=32, n_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"adam\", loss = 'binary_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 637965 images belonging to 2 classes.\n",
      "Found 3879 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "batch_size = 32\n",
    "dataGenerator = ImageDataGenerator(rescale=1./255,rotation_range=5,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    horizontal_flip=True,shear_range=0.05)\n",
    "generator = dataGenerator.flow_from_directory(\n",
    "        '/data/tam/kaggle/train_imgs/',\n",
    "        target_size=(128, 128),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        subset='training',shuffle=True)\n",
    "test_generator = dataGenerator.flow_from_directory(\n",
    "        '/data/tam/kaggle/test_imgs/',\n",
    "        target_size=(128, 128),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        subset='training',shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tampm/miniconda3/envs/face/lib/python3.7/site-packages/keras/callbacks.py:1065: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "lr_reducer = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=7, min_lr=10e-7, epsilon=0.01, verbose=1)\n",
    "early_stopper = EarlyStopping(monitor='val_acc', min_delta=0, patience=15, verbose=1)\n",
    "callbacks= [lr_reducer, early_stopper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "counter = Counter(generator.classes)                          \n",
    "max_val = float(max(counter.values()))       \n",
    "class_weights = {class_id : max_val/num_images for class_id, num_images in counter.items()}                     \n",
    "\n",
    "class_weights_2 = class_weight.compute_class_weight(\n",
    "               'balanced',\n",
    "                np.unique(generator.classes), \n",
    "                generator.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "  281/19936 [..............................] - ETA: 1:26:09 - loss: 12.3380 - acc: 0.2261"
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator,validation_data=test_generator,\\\n",
    "                    steps_per_epoch=int(637965/batch_size), epochs=2,workers=4,validation_steps=3879/batch_size,class_weight = class_weights,callbacks = callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
