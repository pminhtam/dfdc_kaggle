{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorchcv.model_provider import get_model\n",
    "model = get_model(\"xception\", pretrained=False)\n",
    "model = nn.Sequential(*list(model.children())[:-1]) # Remove original output layer\n",
    "\n",
    "class Pooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Pooling, self).__init__()\n",
    "\n",
    "        self.p1 = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.p2 = nn.AdaptiveMaxPool2d((1,1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.p1(x)\n",
    "        x2 = self.p2(x)\n",
    "        return (x1+x2) * 0.5\n",
    "\n",
    "model[0].final_block.pool = nn.Sequential(nn.AdaptiveAvgPool2d((1,1)))\n",
    "\n",
    "class Head(torch.nn.Module):\n",
    "    def __init__(self, in_f, out_f):\n",
    "        super(Head, self).__init__()\n",
    "\n",
    "        self.f = nn.Flatten()\n",
    "        self.l = nn.Linear(in_f, 512)\n",
    "        self.d = nn.Dropout(0.5)\n",
    "        self.o = nn.Linear(512, out_f)\n",
    "        self.b1 = nn.BatchNorm1d(in_f)\n",
    "        self.b2 = nn.BatchNorm1d(512)\n",
    "        self.r = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.f(x)\n",
    "        x = self.b1(x)\n",
    "        x = self.d(x)\n",
    "\n",
    "        x = self.l(x)\n",
    "        x = self.r(x)\n",
    "        x = self.b2(x)\n",
    "        x = self.d(x)\n",
    "\n",
    "        out = self.o(x)\n",
    "        out = nn.Sigmoid()(out)\n",
    "        return out\n",
    "\n",
    "class FCN(torch.nn.Module):\n",
    "    def __init__(self, base, in_f):\n",
    "        super(FCN, self).__init__()\n",
    "        self.base = base\n",
    "        self.h1 = Head(in_f, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base(x)\n",
    "        return self.h1(x)\n",
    "\n",
    "    \n",
    "class FCN2(torch.nn.Module):\n",
    "    def __init__(self, base):\n",
    "        super(FCN2, self).__init__()\n",
    "        self.base = base\n",
    "        self.l = nn.Linear(2048*8*8, 1)\n",
    "    def forward(self, x):\n",
    "        x = self.base(x)\n",
    "#         print(x.size(-1))\n",
    "        x = self.l(x)\n",
    "#         x = nn.Linear(2048*8*8, 1)(x)\n",
    "#         print(x.size)\n",
    "        x = nn.Sigmoid()(x)\n",
    "        return x\n",
    "def xception2():\n",
    "    model = get_model(\"xception\", pretrained=False)\n",
    "    model = nn.Sequential(*list(model.children())[:-1]) # Remove original output layer\n",
    "    model[0].final_block.pool = nn.Sequential(nn.Flatten())\n",
    "    model = FCN2(model)\n",
    "    return model\n",
    "# net = []\n",
    "# model = FCN(model, 2048)\n",
    "# model = model.cuda()\n",
    "model = xception2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FCN2(\n",
       "  (base): Sequential(\n",
       "    (0): Sequential(\n",
       "      (init_block): XceptionInitBlock(\n",
       "        (conv1): ConvBlock(\n",
       "          (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activ): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): ConvBlock(\n",
       "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activ): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (stage1): Sequential(\n",
       "        (unit1): XceptionUnit(\n",
       "          (identity_conv): ConvBlock(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (body): Sequential(\n",
       "            (block1): DwsConvBlock(\n",
       "              (conv): DwsConv(\n",
       "                (dw_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "                (pw_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (block2): DwsConvBlock(\n",
       "              (activ): ReLU()\n",
       "              (conv): DwsConv(\n",
       "                (dw_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "                (pw_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (stage2): Sequential(\n",
       "        (unit1): XceptionUnit(\n",
       "          (identity_conv): ConvBlock(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (body): Sequential(\n",
       "            (block1): DwsConvBlock(\n",
       "              (activ): ReLU()\n",
       "              (conv): DwsConv(\n",
       "                (dw_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "                (pw_conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (block2): DwsConvBlock(\n",
       "              (activ): ReLU()\n",
       "              (conv): DwsConv(\n",
       "                (dw_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "                (pw_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (stage3): Sequential(\n",
       "        (unit1): XceptionUnit(\n",
       "          (identity_conv): ConvBlock(\n",
       "            (conv): Conv2d(256, 728, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (body): Sequential(\n",
       "            (block1): DwsConvBlock(\n",
       "              (activ): ReLU()\n",
       "              (conv): DwsConv(\n",
       "                (dw_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "                (pw_conv): Conv2d(256, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (block2): DwsConvBlock(\n",
       "              (activ): ReLU()\n",
       "              (conv): DwsConv(\n",
       "                (dw_conv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "                (pw_conv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "          )\n",
       "        )\n",
       "        (unit2): XceptionUnit(\n",
       "          (body): Sequential(\n",
       "            (block1): DwsConvBlock(\n",
       "              (activ): ReLU()\n",
       "              (conv): DwsConv(\n",
       "                (dw_conv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "                (pw_conv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (block2): DwsConvBlock(\n",
       "              (activ): ReLU()\n",
       "              (conv): DwsConv(\n",
       "                (dw_conv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "                (pw_conv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (block3): DwsConvBlock(\n",
       "              (activ): ReLU()\n",
       "              (conv): DwsConv(\n",
       "                (dw_conv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "                (pw_conv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (unit3): XceptionUnit(\n",
       "          (body): Sequential(\n",
       "            (block1): DwsConvBlock(\n",
       "              (activ): ReLU()\n",
       "              (conv): DwsConv(\n",
       "                (dw_conv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "                (pw_conv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (block2): DwsConvBlock(\n",
       "              (activ): ReLU()\n",
       "              (conv): DwsConv(\n",
       "                (dw_conv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "                (pw_conv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (block3): DwsConvBlock(\n",
       "              (activ): ReLU()\n",
       "              (conv): DwsConv(\n",
       "                (dw_conv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "                (pw_conv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (unit4): XceptionUnit(\n",
       "          (body): Sequential(\n",
       "            (block1): DwsConvBlock(\n",
       "              (activ): ReLU()\n",
       "              (conv): DwsConv(\n",
       "                (dw_conv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "                (pw_conv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (block2): DwsConvBlock(\n",
       "              (activ): ReLU()\n",
       "              (conv): DwsConv(\n",
       "                (dw_conv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "                (pw_conv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (block3): DwsConvBlock(\n",
       "              (activ): ReLU()\n",
       "              (conv): DwsConv(\n",
       "                (dw_conv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "                (pw_conv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (unit5): XceptionUnit(\n",
       "          (body): Sequential(\n",
       "            (block1): DwsConvBlock(\n",
       "              (activ): ReLU()\n",
       "              (conv): DwsConv(\n",
       "                (dw_conv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "                (pw_conv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (block2): DwsConvBlock(\n",
       "              (activ): ReLU()\n",
       "              (conv): DwsConv(\n",
       "                (dw_conv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "                (pw_conv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (block3): DwsConvBlock(\n",
       "              (activ): ReLU()\n",
       "              (conv): DwsConv(\n",
       "                (dw_conv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "                (pw_conv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (unit6): XceptionUnit(\n",
       "          (body): Sequential(\n",
       "            (block1): DwsConvBlock(\n",
       "              (activ): ReLU()\n",
       "              (conv): DwsConv(\n",
       "                (dw_conv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "                (pw_conv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (block2): DwsConvBlock(\n",
       "              (activ): ReLU()\n",
       "              (conv): DwsConv(\n",
       "                (dw_conv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "                (pw_conv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (block3): DwsConvBlock(\n",
       "              (activ): ReLU()\n",
       "              (conv): DwsConv(\n",
       "                (dw_conv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "                (pw_conv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (unit7): XceptionUnit(\n",
       "          (body): Sequential(\n",
       "            (block1): DwsConvBlock(\n",
       "              (activ): ReLU()\n",
       "              (conv): DwsConv(\n",
       "                (dw_conv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "                (pw_conv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (block2): DwsConvBlock(\n",
       "              (activ): ReLU()\n",
       "              (conv): DwsConv(\n",
       "                (dw_conv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "                (pw_conv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (block3): DwsConvBlock(\n",
       "              (activ): ReLU()\n",
       "              (conv): DwsConv(\n",
       "                (dw_conv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "                (pw_conv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (unit8): XceptionUnit(\n",
       "          (body): Sequential(\n",
       "            (block1): DwsConvBlock(\n",
       "              (activ): ReLU()\n",
       "              (conv): DwsConv(\n",
       "                (dw_conv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "                (pw_conv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (block2): DwsConvBlock(\n",
       "              (activ): ReLU()\n",
       "              (conv): DwsConv(\n",
       "                (dw_conv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "                (pw_conv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (block3): DwsConvBlock(\n",
       "              (activ): ReLU()\n",
       "              (conv): DwsConv(\n",
       "                (dw_conv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "                (pw_conv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (unit9): XceptionUnit(\n",
       "          (body): Sequential(\n",
       "            (block1): DwsConvBlock(\n",
       "              (activ): ReLU()\n",
       "              (conv): DwsConv(\n",
       "                (dw_conv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "                (pw_conv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (block2): DwsConvBlock(\n",
       "              (activ): ReLU()\n",
       "              (conv): DwsConv(\n",
       "                (dw_conv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "                (pw_conv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (block3): DwsConvBlock(\n",
       "              (activ): ReLU()\n",
       "              (conv): DwsConv(\n",
       "                (dw_conv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "                (pw_conv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (stage4): Sequential(\n",
       "        (unit1): XceptionUnit(\n",
       "          (identity_conv): ConvBlock(\n",
       "            (conv): Conv2d(728, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (body): Sequential(\n",
       "            (block1): DwsConvBlock(\n",
       "              (activ): ReLU()\n",
       "              (conv): DwsConv(\n",
       "                (dw_conv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "                (pw_conv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (block2): DwsConvBlock(\n",
       "              (activ): ReLU()\n",
       "              (conv): DwsConv(\n",
       "                (dw_conv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "                (pw_conv): Conv2d(728, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_block): XceptionFinalBlock(\n",
       "        (conv1): DwsConvBlock(\n",
       "          (conv): DwsConv(\n",
       "            (dw_conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
       "            (pw_conv): Conv2d(1024, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (bn): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (conv2): DwsConvBlock(\n",
       "          (activ): ReLU()\n",
       "          (conv): DwsConv(\n",
       "            (dw_conv): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (pw_conv): Conv2d(1536, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (activ): ReLU(inplace=True)\n",
       "        (pool): Sequential(\n",
       "          (0): Flatten()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import PIL.ImageOps    \n",
    "import torch.nn as nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import datasets, transforms, models\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class resnext50(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"Load the pretrained ResNet-152 and replace top fc layer.\"\"\"\n",
    "        super(resnext50, self).__init__()\n",
    "\n",
    "        self.resnext50 = models.resnext50_32x4d(pretrained=True)\n",
    "        self.fc = nn.Sequential(nn.Linear(2048, 1),\n",
    "                                 nn.Sigmoid())\n",
    "        self.resnext50.fc = self.fc\n",
    "    def forward(self, x):\n",
    "        out = self.resnext50(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /home/tampm/.cache/torch/checkpoints/mobilenet_v2-b0353104.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5138af49587a450794decff939ae686e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14212972.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = models.mobilenet_v2(pretrained=True).cuda()\n",
    "# model.classifier = nn.Sequential(nn.Linear(1280, 1),\n",
    "#                                  nn.Sigmoid())\n",
    "# model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MNASNet(\n",
       "  (layers): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(16, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "    (8): Sequential(\n",
       "      (0): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
       "          (4): BatchNorm2d(48, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
       "          (4): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
       "          (4): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(24, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): Sequential(\n",
       "      (0): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
       "          (4): BatchNorm2d(72, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(40, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(120, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "          (4): BatchNorm2d(120, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(40, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(120, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "          (4): BatchNorm2d(120, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(40, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): Sequential(\n",
       "      (0): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(240, 240, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=240, bias=False)\n",
       "          (4): BatchNorm2d(240, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(80, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "          (4): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(80, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "          (4): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(80, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): Sequential(\n",
       "      (0): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "          (4): BatchNorm2d(480, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(96, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (4): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(96, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (12): Sequential(\n",
       "      (0): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(576, 576, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=576, bias=False)\n",
       "          (4): BatchNorm2d(576, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(192, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "          (4): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(192, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "          (4): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(192, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "          (4): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(192, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (13): Sequential(\n",
       "      (0): _InvertedResidual(\n",
       "        (layers): Sequential(\n",
       "          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "          (4): BatchNorm2d(1152, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (7): BatchNorm2d(320, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (14): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (15): BatchNorm2d(1280, eps=1e-05, momentum=0.00029999999999996696, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.mnasnet1_0(pretrained=True).cuda()\n",
    "model.classifier = nn.Sequential(nn.Linear(1280, 1),nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnext50 = models.resnext50_32x4d(pretrained=True)\n",
    "resnext50.fc = nn.Sequential(nn.Linear(2048, 1),\n",
    "                                 nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=resnext50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.cuda()\n",
    "resnext50 = resnext50.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "resnext50(\n",
       "  (resnext50): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=2048, out_features=1, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 127, 127]             864\n",
      "       BatchNorm2d-2         [-1, 32, 127, 127]              64\n",
      "              ReLU-3         [-1, 32, 127, 127]               0\n",
      "         ConvBlock-4         [-1, 32, 127, 127]               0\n",
      "            Conv2d-5         [-1, 64, 125, 125]          18,432\n",
      "       BatchNorm2d-6         [-1, 64, 125, 125]             128\n",
      "              ReLU-7         [-1, 64, 125, 125]               0\n",
      "         ConvBlock-8         [-1, 64, 125, 125]               0\n",
      " XceptionInitBlock-9         [-1, 64, 125, 125]               0\n",
      "           Conv2d-10          [-1, 128, 63, 63]           8,192\n",
      "      BatchNorm2d-11          [-1, 128, 63, 63]             256\n",
      "        ConvBlock-12          [-1, 128, 63, 63]               0\n",
      "           Conv2d-13         [-1, 64, 125, 125]             576\n",
      "           Conv2d-14        [-1, 128, 125, 125]           8,192\n",
      "          DwsConv-15        [-1, 128, 125, 125]               0\n",
      "      BatchNorm2d-16        [-1, 128, 125, 125]             256\n",
      "     DwsConvBlock-17        [-1, 128, 125, 125]               0\n",
      "             ReLU-18        [-1, 128, 125, 125]               0\n",
      "           Conv2d-19        [-1, 128, 125, 125]           1,152\n",
      "           Conv2d-20        [-1, 128, 125, 125]          16,384\n",
      "          DwsConv-21        [-1, 128, 125, 125]               0\n",
      "      BatchNorm2d-22        [-1, 128, 125, 125]             256\n",
      "     DwsConvBlock-23        [-1, 128, 125, 125]               0\n",
      "        MaxPool2d-24          [-1, 128, 63, 63]               0\n",
      "     XceptionUnit-25          [-1, 128, 63, 63]               0\n",
      "           Conv2d-26          [-1, 256, 32, 32]          32,768\n",
      "      BatchNorm2d-27          [-1, 256, 32, 32]             512\n",
      "        ConvBlock-28          [-1, 256, 32, 32]               0\n",
      "             ReLU-29          [-1, 128, 63, 63]               0\n",
      "           Conv2d-30          [-1, 128, 63, 63]           1,152\n",
      "           Conv2d-31          [-1, 256, 63, 63]          32,768\n",
      "          DwsConv-32          [-1, 256, 63, 63]               0\n",
      "      BatchNorm2d-33          [-1, 256, 63, 63]             512\n",
      "     DwsConvBlock-34          [-1, 256, 63, 63]               0\n",
      "             ReLU-35          [-1, 256, 63, 63]               0\n",
      "           Conv2d-36          [-1, 256, 63, 63]           2,304\n",
      "           Conv2d-37          [-1, 256, 63, 63]          65,536\n",
      "          DwsConv-38          [-1, 256, 63, 63]               0\n",
      "      BatchNorm2d-39          [-1, 256, 63, 63]             512\n",
      "     DwsConvBlock-40          [-1, 256, 63, 63]               0\n",
      "        MaxPool2d-41          [-1, 256, 32, 32]               0\n",
      "     XceptionUnit-42          [-1, 256, 32, 32]               0\n",
      "           Conv2d-43          [-1, 728, 16, 16]         186,368\n",
      "      BatchNorm2d-44          [-1, 728, 16, 16]           1,456\n",
      "        ConvBlock-45          [-1, 728, 16, 16]               0\n",
      "             ReLU-46          [-1, 256, 32, 32]               0\n",
      "           Conv2d-47          [-1, 256, 32, 32]           2,304\n",
      "           Conv2d-48          [-1, 728, 32, 32]         186,368\n",
      "          DwsConv-49          [-1, 728, 32, 32]               0\n",
      "      BatchNorm2d-50          [-1, 728, 32, 32]           1,456\n",
      "     DwsConvBlock-51          [-1, 728, 32, 32]               0\n",
      "             ReLU-52          [-1, 728, 32, 32]               0\n",
      "           Conv2d-53          [-1, 728, 32, 32]           6,552\n",
      "           Conv2d-54          [-1, 728, 32, 32]         529,984\n",
      "          DwsConv-55          [-1, 728, 32, 32]               0\n",
      "      BatchNorm2d-56          [-1, 728, 32, 32]           1,456\n",
      "     DwsConvBlock-57          [-1, 728, 32, 32]               0\n",
      "        MaxPool2d-58          [-1, 728, 16, 16]               0\n",
      "     XceptionUnit-59          [-1, 728, 16, 16]               0\n",
      "             ReLU-60          [-1, 728, 16, 16]               0\n",
      "           Conv2d-61          [-1, 728, 16, 16]           6,552\n",
      "           Conv2d-62          [-1, 728, 16, 16]         529,984\n",
      "          DwsConv-63          [-1, 728, 16, 16]               0\n",
      "      BatchNorm2d-64          [-1, 728, 16, 16]           1,456\n",
      "     DwsConvBlock-65          [-1, 728, 16, 16]               0\n",
      "             ReLU-66          [-1, 728, 16, 16]               0\n",
      "           Conv2d-67          [-1, 728, 16, 16]           6,552\n",
      "           Conv2d-68          [-1, 728, 16, 16]         529,984\n",
      "          DwsConv-69          [-1, 728, 16, 16]               0\n",
      "      BatchNorm2d-70          [-1, 728, 16, 16]           1,456\n",
      "     DwsConvBlock-71          [-1, 728, 16, 16]               0\n",
      "             ReLU-72          [-1, 728, 16, 16]               0\n",
      "           Conv2d-73          [-1, 728, 16, 16]           6,552\n",
      "           Conv2d-74          [-1, 728, 16, 16]         529,984\n",
      "          DwsConv-75          [-1, 728, 16, 16]               0\n",
      "      BatchNorm2d-76          [-1, 728, 16, 16]           1,456\n",
      "     DwsConvBlock-77          [-1, 728, 16, 16]               0\n",
      "     XceptionUnit-78          [-1, 728, 16, 16]               0\n",
      "             ReLU-79          [-1, 728, 16, 16]               0\n",
      "           Conv2d-80          [-1, 728, 16, 16]           6,552\n",
      "           Conv2d-81          [-1, 728, 16, 16]         529,984\n",
      "          DwsConv-82          [-1, 728, 16, 16]               0\n",
      "      BatchNorm2d-83          [-1, 728, 16, 16]           1,456\n",
      "     DwsConvBlock-84          [-1, 728, 16, 16]               0\n",
      "             ReLU-85          [-1, 728, 16, 16]               0\n",
      "           Conv2d-86          [-1, 728, 16, 16]           6,552\n",
      "           Conv2d-87          [-1, 728, 16, 16]         529,984\n",
      "          DwsConv-88          [-1, 728, 16, 16]               0\n",
      "      BatchNorm2d-89          [-1, 728, 16, 16]           1,456\n",
      "     DwsConvBlock-90          [-1, 728, 16, 16]               0\n",
      "             ReLU-91          [-1, 728, 16, 16]               0\n",
      "           Conv2d-92          [-1, 728, 16, 16]           6,552\n",
      "           Conv2d-93          [-1, 728, 16, 16]         529,984\n",
      "          DwsConv-94          [-1, 728, 16, 16]               0\n",
      "      BatchNorm2d-95          [-1, 728, 16, 16]           1,456\n",
      "     DwsConvBlock-96          [-1, 728, 16, 16]               0\n",
      "     XceptionUnit-97          [-1, 728, 16, 16]               0\n",
      "             ReLU-98          [-1, 728, 16, 16]               0\n",
      "           Conv2d-99          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-100          [-1, 728, 16, 16]         529,984\n",
      "         DwsConv-101          [-1, 728, 16, 16]               0\n",
      "     BatchNorm2d-102          [-1, 728, 16, 16]           1,456\n",
      "    DwsConvBlock-103          [-1, 728, 16, 16]               0\n",
      "            ReLU-104          [-1, 728, 16, 16]               0\n",
      "          Conv2d-105          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-106          [-1, 728, 16, 16]         529,984\n",
      "         DwsConv-107          [-1, 728, 16, 16]               0\n",
      "     BatchNorm2d-108          [-1, 728, 16, 16]           1,456\n",
      "    DwsConvBlock-109          [-1, 728, 16, 16]               0\n",
      "            ReLU-110          [-1, 728, 16, 16]               0\n",
      "          Conv2d-111          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-112          [-1, 728, 16, 16]         529,984\n",
      "         DwsConv-113          [-1, 728, 16, 16]               0\n",
      "     BatchNorm2d-114          [-1, 728, 16, 16]           1,456\n",
      "    DwsConvBlock-115          [-1, 728, 16, 16]               0\n",
      "    XceptionUnit-116          [-1, 728, 16, 16]               0\n",
      "            ReLU-117          [-1, 728, 16, 16]               0\n",
      "          Conv2d-118          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-119          [-1, 728, 16, 16]         529,984\n",
      "         DwsConv-120          [-1, 728, 16, 16]               0\n",
      "     BatchNorm2d-121          [-1, 728, 16, 16]           1,456\n",
      "    DwsConvBlock-122          [-1, 728, 16, 16]               0\n",
      "            ReLU-123          [-1, 728, 16, 16]               0\n",
      "          Conv2d-124          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-125          [-1, 728, 16, 16]         529,984\n",
      "         DwsConv-126          [-1, 728, 16, 16]               0\n",
      "     BatchNorm2d-127          [-1, 728, 16, 16]           1,456\n",
      "    DwsConvBlock-128          [-1, 728, 16, 16]               0\n",
      "            ReLU-129          [-1, 728, 16, 16]               0\n",
      "          Conv2d-130          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-131          [-1, 728, 16, 16]         529,984\n",
      "         DwsConv-132          [-1, 728, 16, 16]               0\n",
      "     BatchNorm2d-133          [-1, 728, 16, 16]           1,456\n",
      "    DwsConvBlock-134          [-1, 728, 16, 16]               0\n",
      "    XceptionUnit-135          [-1, 728, 16, 16]               0\n",
      "            ReLU-136          [-1, 728, 16, 16]               0\n",
      "          Conv2d-137          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-138          [-1, 728, 16, 16]         529,984\n",
      "         DwsConv-139          [-1, 728, 16, 16]               0\n",
      "     BatchNorm2d-140          [-1, 728, 16, 16]           1,456\n",
      "    DwsConvBlock-141          [-1, 728, 16, 16]               0\n",
      "            ReLU-142          [-1, 728, 16, 16]               0\n",
      "          Conv2d-143          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-144          [-1, 728, 16, 16]         529,984\n",
      "         DwsConv-145          [-1, 728, 16, 16]               0\n",
      "     BatchNorm2d-146          [-1, 728, 16, 16]           1,456\n",
      "    DwsConvBlock-147          [-1, 728, 16, 16]               0\n",
      "            ReLU-148          [-1, 728, 16, 16]               0\n",
      "          Conv2d-149          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-150          [-1, 728, 16, 16]         529,984\n",
      "         DwsConv-151          [-1, 728, 16, 16]               0\n",
      "     BatchNorm2d-152          [-1, 728, 16, 16]           1,456\n",
      "    DwsConvBlock-153          [-1, 728, 16, 16]               0\n",
      "    XceptionUnit-154          [-1, 728, 16, 16]               0\n",
      "            ReLU-155          [-1, 728, 16, 16]               0\n",
      "          Conv2d-156          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-157          [-1, 728, 16, 16]         529,984\n",
      "         DwsConv-158          [-1, 728, 16, 16]               0\n",
      "     BatchNorm2d-159          [-1, 728, 16, 16]           1,456\n",
      "    DwsConvBlock-160          [-1, 728, 16, 16]               0\n",
      "            ReLU-161          [-1, 728, 16, 16]               0\n",
      "          Conv2d-162          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-163          [-1, 728, 16, 16]         529,984\n",
      "         DwsConv-164          [-1, 728, 16, 16]               0\n",
      "     BatchNorm2d-165          [-1, 728, 16, 16]           1,456\n",
      "    DwsConvBlock-166          [-1, 728, 16, 16]               0\n",
      "            ReLU-167          [-1, 728, 16, 16]               0\n",
      "          Conv2d-168          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-169          [-1, 728, 16, 16]         529,984\n",
      "         DwsConv-170          [-1, 728, 16, 16]               0\n",
      "     BatchNorm2d-171          [-1, 728, 16, 16]           1,456\n",
      "    DwsConvBlock-172          [-1, 728, 16, 16]               0\n",
      "    XceptionUnit-173          [-1, 728, 16, 16]               0\n",
      "            ReLU-174          [-1, 728, 16, 16]               0\n",
      "          Conv2d-175          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-176          [-1, 728, 16, 16]         529,984\n",
      "         DwsConv-177          [-1, 728, 16, 16]               0\n",
      "     BatchNorm2d-178          [-1, 728, 16, 16]           1,456\n",
      "    DwsConvBlock-179          [-1, 728, 16, 16]               0\n",
      "            ReLU-180          [-1, 728, 16, 16]               0\n",
      "          Conv2d-181          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-182          [-1, 728, 16, 16]         529,984\n",
      "         DwsConv-183          [-1, 728, 16, 16]               0\n",
      "     BatchNorm2d-184          [-1, 728, 16, 16]           1,456\n",
      "    DwsConvBlock-185          [-1, 728, 16, 16]               0\n",
      "            ReLU-186          [-1, 728, 16, 16]               0\n",
      "          Conv2d-187          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-188          [-1, 728, 16, 16]         529,984\n",
      "         DwsConv-189          [-1, 728, 16, 16]               0\n",
      "     BatchNorm2d-190          [-1, 728, 16, 16]           1,456\n",
      "    DwsConvBlock-191          [-1, 728, 16, 16]               0\n",
      "    XceptionUnit-192          [-1, 728, 16, 16]               0\n",
      "            ReLU-193          [-1, 728, 16, 16]               0\n",
      "          Conv2d-194          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-195          [-1, 728, 16, 16]         529,984\n",
      "         DwsConv-196          [-1, 728, 16, 16]               0\n",
      "     BatchNorm2d-197          [-1, 728, 16, 16]           1,456\n",
      "    DwsConvBlock-198          [-1, 728, 16, 16]               0\n",
      "            ReLU-199          [-1, 728, 16, 16]               0\n",
      "          Conv2d-200          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-201          [-1, 728, 16, 16]         529,984\n",
      "         DwsConv-202          [-1, 728, 16, 16]               0\n",
      "     BatchNorm2d-203          [-1, 728, 16, 16]           1,456\n",
      "    DwsConvBlock-204          [-1, 728, 16, 16]               0\n",
      "            ReLU-205          [-1, 728, 16, 16]               0\n",
      "          Conv2d-206          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-207          [-1, 728, 16, 16]         529,984\n",
      "         DwsConv-208          [-1, 728, 16, 16]               0\n",
      "     BatchNorm2d-209          [-1, 728, 16, 16]           1,456\n",
      "    DwsConvBlock-210          [-1, 728, 16, 16]               0\n",
      "    XceptionUnit-211          [-1, 728, 16, 16]               0\n",
      "          Conv2d-212           [-1, 1024, 8, 8]         745,472\n",
      "     BatchNorm2d-213           [-1, 1024, 8, 8]           2,048\n",
      "       ConvBlock-214           [-1, 1024, 8, 8]               0\n",
      "            ReLU-215          [-1, 728, 16, 16]               0\n",
      "          Conv2d-216          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-217          [-1, 728, 16, 16]         529,984\n",
      "         DwsConv-218          [-1, 728, 16, 16]               0\n",
      "     BatchNorm2d-219          [-1, 728, 16, 16]           1,456\n",
      "    DwsConvBlock-220          [-1, 728, 16, 16]               0\n",
      "            ReLU-221          [-1, 728, 16, 16]               0\n",
      "          Conv2d-222          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-223         [-1, 1024, 16, 16]         745,472\n",
      "         DwsConv-224         [-1, 1024, 16, 16]               0\n",
      "     BatchNorm2d-225         [-1, 1024, 16, 16]           2,048\n",
      "    DwsConvBlock-226         [-1, 1024, 16, 16]               0\n",
      "       MaxPool2d-227           [-1, 1024, 8, 8]               0\n",
      "    XceptionUnit-228           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-229           [-1, 1024, 8, 8]           9,216\n",
      "          Conv2d-230           [-1, 1536, 8, 8]       1,572,864\n",
      "         DwsConv-231           [-1, 1536, 8, 8]               0\n",
      "     BatchNorm2d-232           [-1, 1536, 8, 8]           3,072\n",
      "    DwsConvBlock-233           [-1, 1536, 8, 8]               0\n",
      "            ReLU-234           [-1, 1536, 8, 8]               0\n",
      "          Conv2d-235           [-1, 1536, 8, 8]          13,824\n",
      "          Conv2d-236           [-1, 2048, 8, 8]       3,145,728\n",
      "         DwsConv-237           [-1, 2048, 8, 8]               0\n",
      "     BatchNorm2d-238           [-1, 2048, 8, 8]           4,096\n",
      "    DwsConvBlock-239           [-1, 2048, 8, 8]               0\n",
      "            ReLU-240           [-1, 2048, 8, 8]               0\n",
      "AdaptiveAvgPool2d-241           [-1, 2048, 1, 1]               0\n",
      "XceptionFinalBlock-242           [-1, 2048, 1, 1]               0\n",
      "         Flatten-243                 [-1, 2048]               0\n",
      "     BatchNorm1d-244                 [-1, 2048]           4,096\n",
      "         Dropout-245                 [-1, 2048]               0\n",
      "          Linear-246                  [-1, 512]       1,049,088\n",
      "            ReLU-247                  [-1, 512]               0\n",
      "     BatchNorm1d-248                  [-1, 512]           1,024\n",
      "         Dropout-249                  [-1, 512]               0\n",
      "          Linear-250                    [-1, 1]             513\n",
      "            Head-251                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 21,861,673\n",
      "Trainable params: 21,861,673\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 644.84\n",
      "Params size (MB): 83.40\n",
      "Estimated Total Size (MB): 728.99\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# summary(model,(3,256,256))\n",
    "model = model.cuda()\n",
    "summary(model,(3,256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 127, 127]             864\n",
      "       BatchNorm2d-2         [-1, 32, 127, 127]              64\n",
      "              ReLU-3         [-1, 32, 127, 127]               0\n",
      "         ConvBlock-4         [-1, 32, 127, 127]               0\n",
      "            Conv2d-5         [-1, 64, 125, 125]          18,432\n",
      "       BatchNorm2d-6         [-1, 64, 125, 125]             128\n",
      "              ReLU-7         [-1, 64, 125, 125]               0\n",
      "         ConvBlock-8         [-1, 64, 125, 125]               0\n",
      " XceptionInitBlock-9         [-1, 64, 125, 125]               0\n",
      "           Conv2d-10          [-1, 128, 63, 63]           8,192\n",
      "      BatchNorm2d-11          [-1, 128, 63, 63]             256\n",
      "        ConvBlock-12          [-1, 128, 63, 63]               0\n",
      "           Conv2d-13         [-1, 64, 125, 125]             576\n",
      "           Conv2d-14        [-1, 128, 125, 125]           8,192\n",
      "          DwsConv-15        [-1, 128, 125, 125]               0\n",
      "      BatchNorm2d-16        [-1, 128, 125, 125]             256\n",
      "     DwsConvBlock-17        [-1, 128, 125, 125]               0\n",
      "             ReLU-18        [-1, 128, 125, 125]               0\n",
      "           Conv2d-19        [-1, 128, 125, 125]           1,152\n",
      "           Conv2d-20        [-1, 128, 125, 125]          16,384\n",
      "          DwsConv-21        [-1, 128, 125, 125]               0\n",
      "      BatchNorm2d-22        [-1, 128, 125, 125]             256\n",
      "     DwsConvBlock-23        [-1, 128, 125, 125]               0\n",
      "        MaxPool2d-24          [-1, 128, 63, 63]               0\n",
      "     XceptionUnit-25          [-1, 128, 63, 63]               0\n",
      "           Conv2d-26          [-1, 256, 32, 32]          32,768\n",
      "      BatchNorm2d-27          [-1, 256, 32, 32]             512\n",
      "        ConvBlock-28          [-1, 256, 32, 32]               0\n",
      "             ReLU-29          [-1, 128, 63, 63]               0\n",
      "           Conv2d-30          [-1, 128, 63, 63]           1,152\n",
      "           Conv2d-31          [-1, 256, 63, 63]          32,768\n",
      "          DwsConv-32          [-1, 256, 63, 63]               0\n",
      "      BatchNorm2d-33          [-1, 256, 63, 63]             512\n",
      "     DwsConvBlock-34          [-1, 256, 63, 63]               0\n",
      "             ReLU-35          [-1, 256, 63, 63]               0\n",
      "           Conv2d-36          [-1, 256, 63, 63]           2,304\n",
      "           Conv2d-37          [-1, 256, 63, 63]          65,536\n",
      "          DwsConv-38          [-1, 256, 63, 63]               0\n",
      "      BatchNorm2d-39          [-1, 256, 63, 63]             512\n",
      "     DwsConvBlock-40          [-1, 256, 63, 63]               0\n",
      "        MaxPool2d-41          [-1, 256, 32, 32]               0\n",
      "     XceptionUnit-42          [-1, 256, 32, 32]               0\n",
      "           Conv2d-43          [-1, 728, 16, 16]         186,368\n",
      "      BatchNorm2d-44          [-1, 728, 16, 16]           1,456\n",
      "        ConvBlock-45          [-1, 728, 16, 16]               0\n",
      "             ReLU-46          [-1, 256, 32, 32]               0\n",
      "           Conv2d-47          [-1, 256, 32, 32]           2,304\n",
      "           Conv2d-48          [-1, 728, 32, 32]         186,368\n",
      "          DwsConv-49          [-1, 728, 32, 32]               0\n",
      "      BatchNorm2d-50          [-1, 728, 32, 32]           1,456\n",
      "     DwsConvBlock-51          [-1, 728, 32, 32]               0\n",
      "             ReLU-52          [-1, 728, 32, 32]               0\n",
      "           Conv2d-53          [-1, 728, 32, 32]           6,552\n",
      "           Conv2d-54          [-1, 728, 32, 32]         529,984\n",
      "          DwsConv-55          [-1, 728, 32, 32]               0\n",
      "      BatchNorm2d-56          [-1, 728, 32, 32]           1,456\n",
      "     DwsConvBlock-57          [-1, 728, 32, 32]               0\n",
      "        MaxPool2d-58          [-1, 728, 16, 16]               0\n",
      "     XceptionUnit-59          [-1, 728, 16, 16]               0\n",
      "             ReLU-60          [-1, 728, 16, 16]               0\n",
      "           Conv2d-61          [-1, 728, 16, 16]           6,552\n",
      "           Conv2d-62          [-1, 728, 16, 16]         529,984\n",
      "          DwsConv-63          [-1, 728, 16, 16]               0\n",
      "      BatchNorm2d-64          [-1, 728, 16, 16]           1,456\n",
      "     DwsConvBlock-65          [-1, 728, 16, 16]               0\n",
      "             ReLU-66          [-1, 728, 16, 16]               0\n",
      "           Conv2d-67          [-1, 728, 16, 16]           6,552\n",
      "           Conv2d-68          [-1, 728, 16, 16]         529,984\n",
      "          DwsConv-69          [-1, 728, 16, 16]               0\n",
      "      BatchNorm2d-70          [-1, 728, 16, 16]           1,456\n",
      "     DwsConvBlock-71          [-1, 728, 16, 16]               0\n",
      "             ReLU-72          [-1, 728, 16, 16]               0\n",
      "           Conv2d-73          [-1, 728, 16, 16]           6,552\n",
      "           Conv2d-74          [-1, 728, 16, 16]         529,984\n",
      "          DwsConv-75          [-1, 728, 16, 16]               0\n",
      "      BatchNorm2d-76          [-1, 728, 16, 16]           1,456\n",
      "     DwsConvBlock-77          [-1, 728, 16, 16]               0\n",
      "     XceptionUnit-78          [-1, 728, 16, 16]               0\n",
      "             ReLU-79          [-1, 728, 16, 16]               0\n",
      "           Conv2d-80          [-1, 728, 16, 16]           6,552\n",
      "           Conv2d-81          [-1, 728, 16, 16]         529,984\n",
      "          DwsConv-82          [-1, 728, 16, 16]               0\n",
      "      BatchNorm2d-83          [-1, 728, 16, 16]           1,456\n",
      "     DwsConvBlock-84          [-1, 728, 16, 16]               0\n",
      "             ReLU-85          [-1, 728, 16, 16]               0\n",
      "           Conv2d-86          [-1, 728, 16, 16]           6,552\n",
      "           Conv2d-87          [-1, 728, 16, 16]         529,984\n",
      "          DwsConv-88          [-1, 728, 16, 16]               0\n",
      "      BatchNorm2d-89          [-1, 728, 16, 16]           1,456\n",
      "     DwsConvBlock-90          [-1, 728, 16, 16]               0\n",
      "             ReLU-91          [-1, 728, 16, 16]               0\n",
      "           Conv2d-92          [-1, 728, 16, 16]           6,552\n",
      "           Conv2d-93          [-1, 728, 16, 16]         529,984\n",
      "          DwsConv-94          [-1, 728, 16, 16]               0\n",
      "      BatchNorm2d-95          [-1, 728, 16, 16]           1,456\n",
      "     DwsConvBlock-96          [-1, 728, 16, 16]               0\n",
      "     XceptionUnit-97          [-1, 728, 16, 16]               0\n",
      "             ReLU-98          [-1, 728, 16, 16]               0\n",
      "           Conv2d-99          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-100          [-1, 728, 16, 16]         529,984\n",
      "         DwsConv-101          [-1, 728, 16, 16]               0\n",
      "     BatchNorm2d-102          [-1, 728, 16, 16]           1,456\n",
      "    DwsConvBlock-103          [-1, 728, 16, 16]               0\n",
      "            ReLU-104          [-1, 728, 16, 16]               0\n",
      "          Conv2d-105          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-106          [-1, 728, 16, 16]         529,984\n",
      "         DwsConv-107          [-1, 728, 16, 16]               0\n",
      "     BatchNorm2d-108          [-1, 728, 16, 16]           1,456\n",
      "    DwsConvBlock-109          [-1, 728, 16, 16]               0\n",
      "            ReLU-110          [-1, 728, 16, 16]               0\n",
      "          Conv2d-111          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-112          [-1, 728, 16, 16]         529,984\n",
      "         DwsConv-113          [-1, 728, 16, 16]               0\n",
      "     BatchNorm2d-114          [-1, 728, 16, 16]           1,456\n",
      "    DwsConvBlock-115          [-1, 728, 16, 16]               0\n",
      "    XceptionUnit-116          [-1, 728, 16, 16]               0\n",
      "            ReLU-117          [-1, 728, 16, 16]               0\n",
      "          Conv2d-118          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-119          [-1, 728, 16, 16]         529,984\n",
      "         DwsConv-120          [-1, 728, 16, 16]               0\n",
      "     BatchNorm2d-121          [-1, 728, 16, 16]           1,456\n",
      "    DwsConvBlock-122          [-1, 728, 16, 16]               0\n",
      "            ReLU-123          [-1, 728, 16, 16]               0\n",
      "          Conv2d-124          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-125          [-1, 728, 16, 16]         529,984\n",
      "         DwsConv-126          [-1, 728, 16, 16]               0\n",
      "     BatchNorm2d-127          [-1, 728, 16, 16]           1,456\n",
      "    DwsConvBlock-128          [-1, 728, 16, 16]               0\n",
      "            ReLU-129          [-1, 728, 16, 16]               0\n",
      "          Conv2d-130          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-131          [-1, 728, 16, 16]         529,984\n",
      "         DwsConv-132          [-1, 728, 16, 16]               0\n",
      "     BatchNorm2d-133          [-1, 728, 16, 16]           1,456\n",
      "    DwsConvBlock-134          [-1, 728, 16, 16]               0\n",
      "    XceptionUnit-135          [-1, 728, 16, 16]               0\n",
      "            ReLU-136          [-1, 728, 16, 16]               0\n",
      "          Conv2d-137          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-138          [-1, 728, 16, 16]         529,984\n",
      "         DwsConv-139          [-1, 728, 16, 16]               0\n",
      "     BatchNorm2d-140          [-1, 728, 16, 16]           1,456\n",
      "    DwsConvBlock-141          [-1, 728, 16, 16]               0\n",
      "            ReLU-142          [-1, 728, 16, 16]               0\n",
      "          Conv2d-143          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-144          [-1, 728, 16, 16]         529,984\n",
      "         DwsConv-145          [-1, 728, 16, 16]               0\n",
      "     BatchNorm2d-146          [-1, 728, 16, 16]           1,456\n",
      "    DwsConvBlock-147          [-1, 728, 16, 16]               0\n",
      "            ReLU-148          [-1, 728, 16, 16]               0\n",
      "          Conv2d-149          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-150          [-1, 728, 16, 16]         529,984\n",
      "         DwsConv-151          [-1, 728, 16, 16]               0\n",
      "     BatchNorm2d-152          [-1, 728, 16, 16]           1,456\n",
      "    DwsConvBlock-153          [-1, 728, 16, 16]               0\n",
      "    XceptionUnit-154          [-1, 728, 16, 16]               0\n",
      "            ReLU-155          [-1, 728, 16, 16]               0\n",
      "          Conv2d-156          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-157          [-1, 728, 16, 16]         529,984\n",
      "         DwsConv-158          [-1, 728, 16, 16]               0\n",
      "     BatchNorm2d-159          [-1, 728, 16, 16]           1,456\n",
      "    DwsConvBlock-160          [-1, 728, 16, 16]               0\n",
      "            ReLU-161          [-1, 728, 16, 16]               0\n",
      "          Conv2d-162          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-163          [-1, 728, 16, 16]         529,984\n",
      "         DwsConv-164          [-1, 728, 16, 16]               0\n",
      "     BatchNorm2d-165          [-1, 728, 16, 16]           1,456\n",
      "    DwsConvBlock-166          [-1, 728, 16, 16]               0\n",
      "            ReLU-167          [-1, 728, 16, 16]               0\n",
      "          Conv2d-168          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-169          [-1, 728, 16, 16]         529,984\n",
      "         DwsConv-170          [-1, 728, 16, 16]               0\n",
      "     BatchNorm2d-171          [-1, 728, 16, 16]           1,456\n",
      "    DwsConvBlock-172          [-1, 728, 16, 16]               0\n",
      "    XceptionUnit-173          [-1, 728, 16, 16]               0\n",
      "            ReLU-174          [-1, 728, 16, 16]               0\n",
      "          Conv2d-175          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-176          [-1, 728, 16, 16]         529,984\n",
      "         DwsConv-177          [-1, 728, 16, 16]               0\n",
      "     BatchNorm2d-178          [-1, 728, 16, 16]           1,456\n",
      "    DwsConvBlock-179          [-1, 728, 16, 16]               0\n",
      "            ReLU-180          [-1, 728, 16, 16]               0\n",
      "          Conv2d-181          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-182          [-1, 728, 16, 16]         529,984\n",
      "         DwsConv-183          [-1, 728, 16, 16]               0\n",
      "     BatchNorm2d-184          [-1, 728, 16, 16]           1,456\n",
      "    DwsConvBlock-185          [-1, 728, 16, 16]               0\n",
      "            ReLU-186          [-1, 728, 16, 16]               0\n",
      "          Conv2d-187          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-188          [-1, 728, 16, 16]         529,984\n",
      "         DwsConv-189          [-1, 728, 16, 16]               0\n",
      "     BatchNorm2d-190          [-1, 728, 16, 16]           1,456\n",
      "    DwsConvBlock-191          [-1, 728, 16, 16]               0\n",
      "    XceptionUnit-192          [-1, 728, 16, 16]               0\n",
      "            ReLU-193          [-1, 728, 16, 16]               0\n",
      "          Conv2d-194          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-195          [-1, 728, 16, 16]         529,984\n",
      "         DwsConv-196          [-1, 728, 16, 16]               0\n",
      "     BatchNorm2d-197          [-1, 728, 16, 16]           1,456\n",
      "    DwsConvBlock-198          [-1, 728, 16, 16]               0\n",
      "            ReLU-199          [-1, 728, 16, 16]               0\n",
      "          Conv2d-200          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-201          [-1, 728, 16, 16]         529,984\n",
      "         DwsConv-202          [-1, 728, 16, 16]               0\n",
      "     BatchNorm2d-203          [-1, 728, 16, 16]           1,456\n",
      "    DwsConvBlock-204          [-1, 728, 16, 16]               0\n",
      "            ReLU-205          [-1, 728, 16, 16]               0\n",
      "          Conv2d-206          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-207          [-1, 728, 16, 16]         529,984\n",
      "         DwsConv-208          [-1, 728, 16, 16]               0\n",
      "     BatchNorm2d-209          [-1, 728, 16, 16]           1,456\n",
      "    DwsConvBlock-210          [-1, 728, 16, 16]               0\n",
      "    XceptionUnit-211          [-1, 728, 16, 16]               0\n",
      "          Conv2d-212           [-1, 1024, 8, 8]         745,472\n",
      "     BatchNorm2d-213           [-1, 1024, 8, 8]           2,048\n",
      "       ConvBlock-214           [-1, 1024, 8, 8]               0\n",
      "            ReLU-215          [-1, 728, 16, 16]               0\n",
      "          Conv2d-216          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-217          [-1, 728, 16, 16]         529,984\n",
      "         DwsConv-218          [-1, 728, 16, 16]               0\n",
      "     BatchNorm2d-219          [-1, 728, 16, 16]           1,456\n",
      "    DwsConvBlock-220          [-1, 728, 16, 16]               0\n",
      "            ReLU-221          [-1, 728, 16, 16]               0\n",
      "          Conv2d-222          [-1, 728, 16, 16]           6,552\n",
      "          Conv2d-223         [-1, 1024, 16, 16]         745,472\n",
      "         DwsConv-224         [-1, 1024, 16, 16]               0\n",
      "     BatchNorm2d-225         [-1, 1024, 16, 16]           2,048\n",
      "    DwsConvBlock-226         [-1, 1024, 16, 16]               0\n",
      "       MaxPool2d-227           [-1, 1024, 8, 8]               0\n",
      "    XceptionUnit-228           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-229           [-1, 1024, 8, 8]           9,216\n",
      "          Conv2d-230           [-1, 1536, 8, 8]       1,572,864\n",
      "         DwsConv-231           [-1, 1536, 8, 8]               0\n",
      "     BatchNorm2d-232           [-1, 1536, 8, 8]           3,072\n",
      "    DwsConvBlock-233           [-1, 1536, 8, 8]               0\n",
      "            ReLU-234           [-1, 1536, 8, 8]               0\n",
      "          Conv2d-235           [-1, 1536, 8, 8]          13,824\n",
      "          Conv2d-236           [-1, 2048, 8, 8]       3,145,728\n",
      "         DwsConv-237           [-1, 2048, 8, 8]               0\n",
      "     BatchNorm2d-238           [-1, 2048, 8, 8]           4,096\n",
      "    DwsConvBlock-239           [-1, 2048, 8, 8]               0\n",
      "            ReLU-240           [-1, 2048, 8, 8]               0\n",
      "         Flatten-241               [-1, 131072]               0\n",
      "XceptionFinalBlock-242               [-1, 131072]               0\n",
      "          Linear-243                    [-1, 1]         131,073\n",
      "================================================================\n",
      "Total params: 20,938,025\n",
      "Trainable params: 20,938,025\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 646.75\n",
      "Params size (MB): 79.87\n",
      "Estimated Total Size (MB): 727.37\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = model.cuda()\n",
    "summary(model,(3,256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.ones((1,3,256,256))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "pic should be 2/3 dimensional. Got 5 dimensions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-a50ed3e80499>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/face/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \"\"\"\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/face/lib/python3.7/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_numpy_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pic should be 2/3 dimensional. Got {} dimensions.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: pic should be 2/3 dimensional. Got 5 dimensions."
     ]
    }
   ],
   "source": [
    "model.forward(transforms.ToTensor()(np.array([i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([transforms.Resize(256,256),\n",
    "                                       transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                       transforms.RandomApply([\n",
    "                                           transforms.RandomRotation(5),\n",
    "                                           transforms.RandomAffine(degrees=5,scale=(0.95,1.05))\n",
    "                                           ], p=0.5),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                             std=[0.229, 0.224, 0.225])\n",
    "                                       \n",
    "                                       ])\n",
    "train_data = datasets.ImageFolder('/hdd/tam/kaggle/image/test/',       \n",
    "# train_data = datasets.ImageFolder('/hdd/tam/Celeb-DF/image/test/',  \n",
    "                    transform=train_transforms)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "lis = glob.glob('/hdd/tam/Celeb-DF/image/test/*/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/hdd/tam/Celeb-DF/image/test/df/id3_id2_0001_62.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id2_id9_0008_123.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id3_0005_37.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id29_id37_0008_101.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id26_id16_0001_67.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id2_id1_0004_80.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id3_0006_27.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id17_id16_0000_12.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id2_0007_53.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id2_id9_0008_87.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id10_id13_0007_58.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id28_id35_0008_49.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id25_id19_0008_26.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id17_id23_0000_42.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id26_0004_42.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id46_id41_0000_13.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id3_id28_0001_43.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id17_id2_0003_39.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id34_0008_45.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id3_0009_66.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id21_0002_60.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id35_id28_0006_13.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id25_id19_0008_37.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id54_id56_0000_14.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id10_id7_0004_95.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id10_id13_0004_94.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id16_0005_26.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id10_id7_0004_40.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id20_0002_81.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id8_id6_0002_102.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id57_id53_0006_52.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id17_id6_0000_74.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id22_id26_0005_21.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id3_0002_77.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id3_id6_0001_33.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id29_0002_85.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id3_id20_0008_76.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id35_0001_65.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id27_id19_0001_50.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id35_id20_0007_56.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id10_id7_0008_22.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id52_id58_0005_83.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id16_id2_0006_51.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id53_id52_0003_62.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id21_0005_37.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id0_id21_0000_31.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id2_id9_0008_108.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id7_id11_0009_49.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id23_0007_26.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id26_id2_0005_41.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id53_id57_0005_51.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id17_0007_58.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id31_id33_0009_57.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id13_id7_0012_123.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id7_id10_0009_75.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id4_0000_110.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id7_id11_0009_31.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id7_id11_0007_52.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id47_id43_0007_20.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id3_id4_0001_36.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id38_id33_0005_50.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id16_id2_0011_11.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id21_0005_83.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id53_id57_0005_8.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id28_id20_0006_45.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id1_0005_90.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id22_id27_0005_1.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id2_0003_47.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id29_id37_0008_97.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id0_id1_0001_7.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id31_id33_0009_20.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id3_id20_0008_82.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id32_id33_0004_34.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id54_id56_0000_73.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id2_id0_0008_92.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id3_0004_40.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id28_id35_0008_82.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id0_id16_0004_74.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id1_0007_25.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id3_0005_47.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id24_id21_0006_13.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id29_id30_0009_112.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id3_id9_0003_52.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id31_0008_25.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id3_id9_0003_16.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id30_0000_93.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id16_id20_0012_16.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id2_id9_0008_70.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id3_0000_29.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id27_id21_0008_23.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id28_0008_112.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id16_0000_86.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id53_id58_0005_72.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id38_id34_0003_102.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id54_id56_0000_68.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id7_id10_0009_65.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id1_0005_82.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id2_id0_0002_60.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id17_0007_47.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id31_id30_0009_34.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id0_id1_0005_47.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id0_id21_0000_77.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id4_0000_12.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id3_0002_59.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id33_id29_0004_31.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id10_id7_0004_102.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id28_0007_103.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id17_id26_0006_2.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id16_id2_0011_61.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id16_id1_0011_62.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id28_0006_47.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id50_id49_0001_15.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id25_id19_0008_34.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id54_id49_0003_55.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id28_0006_57.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id52_id50_0007_113.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id20_0000_92.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id2_0007_0.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id3_id28_0009_112.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id35_id26_0003_9.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id21_0005_92.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id21_0006_25.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id0_0001_4.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id25_id28_0010_74.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id10_id7_0004_12.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id16_0007_53.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id25_id19_0002_12.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id2_id16_0004_15.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id23_0006_50.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id29_id32_0003_62.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id20_id0_0006_19.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id27_id23_0008_62.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id21_id3_0009_68.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id54_id56_0000_52.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id28_0007_97.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id28_id9_0000_50.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id31_id33_0009_98.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id29_id30_0009_98.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id48_id47_0008_70.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id12_id10_0005_71.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id21_id2_0002_79.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id57_id51_0000_138.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id19_id23_0001_25.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id28_id0_0009_43.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id52_id50_0007_6.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id23_0006_23.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id23_id16_0003_39.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id35_id31_0009_47.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id2_id0_0008_82.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id10_id7_0004_57.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id38_id34_0003_12.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id25_id19_0008_17.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id16_id6_0011_49.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id6_0000_18.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id3_id28_0009_8.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id0_0004_94.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id6_0000_80.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id24_id20_0009_64.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id9_0006_39.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id6_0005_98.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id21_0006_44.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id10_id7_0004_35.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id10_id12_0004_104.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id28_0008_11.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id3_0000_72.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id46_id45_0001_15.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id48_id41_0001_36.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id13_id7_0012_88.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id21_id2_0000_50.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id35_id20_0007_20.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id35_id31_0007_36.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id3_id1_0001_16.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id21_id28_0009_43.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id25_id28_0010_6.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id10_id12_0004_105.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id26_id2_0005_60.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id33_id38_0001_66.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id10_id13_0004_58.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id21_0002_21.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id25_id21_0005_2.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id8_id6_0002_114.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id2_id3_0008_71.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id2_0007_28.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id23_0006_18.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id12_id10_0005_42.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id20_id9_0008_75.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id23_0002_58.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id10_id11_0001_9.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id54_id56_0006_3.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id26_id2_0005_61.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id0_id16_0007_91.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id6_0007_65.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id21_id20_0006_71.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id3_id16_0001_76.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id0_0000_33.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id29_id30_0009_20.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id38_id33_0005_103.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id28_id9_0000_81.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id19_id23_0001_51.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id4_0001_5.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id37_0006_45.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id6_0007_53.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id8_id6_0002_90.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id34_0003_51.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id53_id58_0005_106.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id0_id16_0007_60.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id20_0008_67.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id52_id50_0007_69.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id10_id13_0007_1.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id50_id56_0005_88.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id24_id21_0006_50.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id2_0007_58.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id31_id30_0009_5.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id29_id30_0009_16.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id4_0000_14.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id16_id6_0011_4.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id2_id0_0002_84.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id0_id16_0003_79.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id56_id55_0009_7.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id13_id7_0012_87.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id34_0003_71.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id2_id26_0001_9.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id8_id6_0002_4.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id17_0007_77.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id3_0006_70.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id21_id4_0002_49.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id35_id23_0007_84.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id1_0002_70.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id17_id16_0007_55.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id21_id19_0009_4.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id28_0008_119.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id35_id23_0007_76.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id31_id33_0009_21.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id35_0009_19.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id38_0009_105.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id22_id27_0001_9.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id2_0000_10.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id20_0001_3.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id28_0008_61.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id28_id26_0000_20.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id32_id33_0002_9.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id23_id19_0000_47.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id21_0005_102.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id29_id37_0008_39.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id44_id42_0001_54.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id16_id3_0009_47.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id23_0006_70.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id56_id51_0000_53.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id23_id3_0009_52.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id35_0005_107.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id3_0002_86.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id50_id56_0005_45.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id56_id51_0000_66.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id3_id28_0009_101.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id1_0007_48.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id0_0007_76.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id28_id9_0000_54.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id3_id20_0008_33.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id3_id2_0001_87.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id28_id4_0006_27.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id3_id6_0001_30.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id21_0004_6.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id57_id53_0006_97.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id21_id4_0002_68.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id8_id6_0002_61.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id23_0006_51.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id22_id26_0005_2.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id37_0006_14.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id26_id3_0002_31.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id3_id2_0001_90.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id27_id26_0006_19.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id10_id13_0004_11.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id7_id13_0009_19.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id0_id26_0009_78.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id26_0004_34.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id35_id31_0007_94.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id29_id30_0000_6.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id2_0009_6.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id28_id0_0009_21.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id0_id16_0003_92.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id52_id58_0005_20.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id35_0009_83.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id20_id9_0008_17.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id20_0000_36.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id2_id9_0008_104.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id0_0001_26.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id20_id9_0008_45.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id16_0007_62.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id26_id2_0005_59.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id2_0003_105.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id44_id42_0001_59.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id7_id10_0009_26.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id28_id35_0008_50.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id6_0002_44.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id27_id22_0007_19.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id20_id37_0004_18.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id46_id41_0000_29.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id35_id16_0004_6.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id27_id25_0008_43.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id35_0009_29.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id31_id33_0008_2.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id7_id11_0007_34.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id50_id49_0001_3.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id44_id41_0005_54.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id43_id40_0005_20.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id54_id49_0003_39.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id8_id5_0008_88.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id3_id1_0001_86.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id31_id30_0009_22.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id3_0006_46.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id16_id1_0011_16.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id3_0005_0.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id26_0000_66.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id21_id3_0009_49.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id58_id57_0008_38.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id29_id30_0009_61.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id20_0002_92.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id0_id16_0003_86.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id2_0006_48.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id29_id37_0009_82.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id34_id33_0002_19.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id38_id30_0006_36.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id34_0008_6.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id17_0007_34.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id24_id21_0006_62.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id23_id3_0009_22.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id32_id33_0004_91.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id17_id1_0000_55.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id2_0005_85.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id28_0000_53.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id26_0007_50.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id21_id19_0009_13.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id10_id7_0005_41.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id21_id9_0008_55.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id57_id51_0000_151.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id28_id20_0008_11.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id53_id57_0005_78.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id26_0000_67.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id0_0005_82.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id16_id20_0000_44.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id2_0008_72.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id21_id2_0000_11.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id2_id3_0008_31.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id52_id50_0007_4.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id10_id12_0004_6.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id16_0000_67.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id28_0004_0.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id22_id27_0001_0.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id16_0000_53.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id0_0001_102.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id21_id20_0006_1.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id2_0006_83.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id24_id20_0009_65.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id48_id45_0002_45.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id6_0005_77.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id2_id0_0008_78.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id21_0004_26.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id27_id23_0008_33.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id2_id16_0004_29.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id38_id33_0005_84.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id46_id39_0000_33.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id20_0002_63.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id28_0004_54.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id57_id53_0006_88.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id35_id28_0006_17.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id21_0009_66.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id2_0003_82.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id23_0006_25.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id20_0002_57.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id2_0006_93.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id44_id45_0000_65.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id22_id26_0005_5.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id27_id21_0002_83.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id3_0007_71.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id10_id13_0004_95.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id30_0000_50.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id16_id3_0010_29.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id3_0009_93.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id20_0001_41.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id35_id23_0007_26.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id49_id52_0007_21.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id16_id2_0001_47.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id30_0000_52.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id0_id16_0003_20.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id49_id52_0007_92.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id26_0007_90.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id23_id2_0007_5.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id22_id27_0001_10.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id21_0000_76.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id0_id16_0007_106.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id27_id19_0001_53.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id26_0007_26.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id51_id50_0008_97.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id17_id2_0007_49.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id28_id35_0008_46.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id23_id2_0007_24.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id0_id16_0007_83.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id35_0005_46.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id16_id6_0001_66.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id10_id7_0008_82.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id29_id32_0000_20.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id16_id2_0001_28.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id20_0007_25.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id28_id0_0009_48.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id7_id13_0009_79.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id38_id34_0004_34.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id38_id33_0005_30.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id49_id52_0007_75.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id29_id35_0000_42.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id19_id23_0001_20.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id3_0002_75.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id0_id16_0007_26.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id0_id26_0009_19.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id0_id16_0007_31.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id26_0004_74.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id23_id26_0003_8.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id34_id33_0002_0.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id2_0008_52.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id31_0008_115.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id3_id1_0001_52.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id23_0009_74.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id39_id44_0008_12.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id54_id56_0006_25.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id7_id10_0009_35.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id8_id0_0002_80.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id29_id30_0009_72.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id0_0004_29.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id53_id57_0005_23.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id3_id20_0008_99.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id35_id31_0009_53.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id57_id51_0000_39.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id2_0003_58.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id35_id32_0007_24.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id50_id53_0000_2.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id3_0002_94.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id51_id57_0004_69.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id1_0002_115.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id8_id5_0008_80.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id19_id20_0000_32.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id28_0000_92.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id3_0004_56.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id2_0000_92.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id10_id7_0008_16.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id21_id4_0002_17.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id51_id57_0004_3.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id17_id2_0007_23.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id52_id50_0007_24.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id3_id28_0009_102.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id16_0005_70.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id2_0008_61.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id0_0000_48.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id3_0004_74.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id3_id9_0003_7.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id28_0008_64.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id28_id9_0000_36.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id21_0006_55.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id49_id52_0005_67.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id42_id40_0001_3.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id35_id31_0006_39.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id53_id52_0003_78.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id2_0000_86.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id38_id33_0005_56.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id42_id40_0001_31.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id3_0002_72.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id21_0005_64.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id35_id20_0007_40.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id20_id1_0003_37.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id25_id24_0003_5.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id1_0007_109.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id25_id19_0002_14.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id51_id57_0004_82.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id37_0006_60.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id2_id0_0008_46.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id21_id2_0002_5.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id29_id37_0009_6.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id24_id21_0006_4.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id6_0007_58.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id35_id32_0007_55.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id16_id3_0010_64.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id38_id30_0006_0.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id17_id21_0000_69.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id21_id9_0008_29.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id0_0006_13.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id1_0000_6.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id38_id34_0003_97.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id53_id52_0003_46.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id21_id9_0008_0.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id0_id1_0005_107.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id29_id37_0005_54.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id24_id21_0006_24.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id10_id11_0004_113.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id28_0002_93.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id48_id45_0002_56.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id50_id53_0000_29.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id33_id29_0004_49.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id26_0007_43.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id10_id13_0007_100.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id21_0005_54.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id9_0007_80.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id0_id16_0003_6.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id38_id33_0005_2.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id3_id2_0001_41.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id21_id3_0009_58.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id2_0008_79.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id29_id30_0000_71.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id2_id28_0003_18.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id21_0000_71.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id29_id32_0000_9.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id31_id30_0009_29.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id2_0007_40.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id49_id52_0007_43.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id0_id3_0007_63.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id24_id19_0000_65.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id16_id2_0001_46.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id2_0005_29.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id46_id41_0000_82.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id35_id23_0007_35.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id21_0009_82.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id19_id20_0000_43.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id1_0000_103.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id26_0007_9.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id20_0007_117.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id17_id16_0000_41.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id21_0004_108.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id52_id58_0005_74.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id17_id28_0001_77.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id34_id32_0007_59.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id3_id6_0001_3.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id19_id20_0004_14.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id2_0005_66.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id31_id33_0008_68.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id1_0007_63.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id26_0007_45.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id21_0005_66.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id54_id49_0003_75.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id23_id35_0009_48.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id53_id52_0003_11.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id26_id3_0002_24.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id51_id50_0008_72.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id23_id2_0007_7.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id16_0007_86.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id8_id0_0002_9.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id43_id40_0005_66.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id1_0003_32.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id53_id57_0005_0.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id16_id20_0000_58.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id3_0007_8.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id2_0003_65.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id38_id30_0006_24.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id8_id3_0003_88.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id3_0006_0.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id17_id28_0001_10.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id34_0003_85.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id16_id3_0010_56.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id27_id25_0008_64.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id3_id2_0001_69.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id2_id0_0008_17.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id1_0007_24.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id51_id50_0008_71.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id57_id53_0006_84.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id35_id16_0007_27.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id26_id16_0001_41.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id8_id3_0003_74.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id2_id9_0008_2.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id17_id3_0000_75.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id50_id56_0005_57.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id16_0000_11.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id17_id21_0000_49.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id38_0009_71.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id38_id34_0003_87.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id20_0002_62.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id3_0005_71.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id2_id9_0008_66.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id10_id7_0005_59.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id10_id7_0004_4.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id30_0000_8.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id2_0005_0.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id21_0005_56.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id58_id57_0008_11.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id0_0000_15.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id57_id53_0006_39.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id0_id21_0000_6.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id17_0007_11.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id1_0002_86.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id22_id21_0005_49.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id28_id0_0009_57.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id31_id30_0009_27.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id16_id20_0000_28.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id26_id3_0002_48.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id42_id40_0001_26.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id24_id26_0004_76.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id12_id10_0002_3.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id16_id2_0001_74.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id21_0004_38.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id1_0007_101.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id34_id32_0007_78.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id2_0008_0.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id29_id37_0008_91.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id17_id23_0000_49.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id13_id10_0005_6.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id0_id3_0007_52.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id0_0006_64.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id3_0002_90.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id29_id38_0008_12.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id35_id16_0007_26.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id35_id26_0003_56.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id0_0004_65.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id23_0001_38.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id8_id3_0003_48.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id54_id58_0006_9.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id28_0007_64.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id1_0000_83.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id9_0006_24.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id16_id20_0000_26.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id29_id37_0005_107.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id57_id51_0000_153.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id39_id44_0000_15.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id32_0006_15.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id21_id4_0002_7.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id26_id16_0001_73.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id23_0006_7.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id9_0006_67.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id32_id33_0004_94.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id3_0005_90.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id17_0007_66.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id16_id28_0005_48.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id54_id56_0000_77.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id28_0006_37.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id48_id41_0001_2.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id3_0000_110.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id20_0000_61.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id19_id23_0001_44.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id3_id9_0001_32.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id19_id23_0001_73.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id51_id50_0008_104.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id38_id30_0006_62.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id2_0007_76.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id1_0007_78.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id2_0008_55.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id21_id9_0008_3.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id35_id26_0003_37.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id24_id21_0006_64.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id20_id1_0003_83.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id47_id43_0007_50.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id2_id0_0008_93.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id57_id51_0000_108.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id39_id47_0004_34.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id7_id13_0009_12.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id20_id19_0002_39.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id54_id58_0006_48.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id57_id51_0000_50.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id10_id11_0001_16.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id21_id3_0009_35.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id3_0003_0.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id16_id6_0011_30.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id0_0000_89.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id16_id3_0010_69.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id23_0001_59.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id49_id52_0005_101.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id24_id20_0009_1.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id1_0002_91.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id3_0006_67.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id2_id16_0004_30.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id54_id56_0006_103.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id29_id30_0009_35.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id17_id3_0007_30.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id54_id58_0006_87.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id20_id0_0006_50.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id29_id30_0000_7.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id3_id16_0001_4.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id35_id30_0006_24.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id50_id49_0001_28.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id8_id6_0002_117.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id25_id21_0005_45.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id17_id21_0000_31.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id32_id33_0002_118.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id3_0007_66.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id3_0002_27.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id0_0006_95.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id35_id26_0003_57.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id28_0008_90.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id17_id6_0000_52.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id3_0009_7.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id20_id1_0003_36.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id2_id0_0008_90.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id28_0000_54.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id2_0003_66.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id13_id7_0012_11.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id28_0004_25.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id35_0001_27.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id32_0006_85.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id28_0002_81.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id0_id1_0001_35.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id23_id19_0000_28.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id0_id16_0004_34.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id35_id28_0006_10.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id3_id16_0001_5.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id28_id21_0006_61.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id13_id7_0012_101.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id0_0000_18.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id25_id21_0005_30.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id56_id51_0000_10.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id56_id54_0007_29.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id54_id58_0006_84.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id2_0007_3.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id35_id20_0007_12.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id27_id21_0002_25.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id16_id2_0001_12.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id12_id7_0006_2.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id43_id40_0005_22.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id8_id5_0008_72.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id2_0008_86.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id53_id57_0005_29.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id21_0006_23.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id31_id30_0009_60.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id3_0002_31.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id31_id16_0002_67.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id17_id2_0007_19.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id25_id23_0010_41.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id2_0003_27.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id16_0007_13.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id3_id6_0001_77.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id26_id28_0002_65.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id16_id20_0000_51.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id34_0008_36.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id16_0007_54.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id25_id21_0005_41.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id29_id38_0008_80.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id21_id19_0005_30.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id20_id31_0008_39.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id50_id56_0005_96.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id57_id53_0006_90.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id19_id23_0001_76.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id16_0005_90.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id16_id20_0006_25.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id2_id28_0003_23.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id52_id58_0005_58.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id13_id10_0005_70.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id21_0002_64.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id49_id52_0007_25.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id3_0003_79.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id2_0003_22.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id43_id40_0005_51.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id32_id31_0008_18.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id10_id7_0008_21.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id57_id51_0000_92.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id1_0005_58.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id28_id20_0008_69.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id23_0001_64.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id3_id28_0001_4.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id3_0003_86.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id21_id28_0009_63.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id22_id27_0005_56.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id34_0008_12.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id0_id3_0007_90.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id20_id31_0008_67.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id33_id29_0004_17.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id7_id11_0009_39.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id28_id3_0001_81.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id2_id28_0003_31.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id6_0007_76.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id23_0009_34.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id16_id3_0011_52.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id0_id1_0000_72.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id23_id2_0007_64.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id26_id28_0002_58.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id3_0005_9.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id1_0007_29.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id26_0006_66.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id24_id26_0009_76.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id10_id12_0004_3.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id16_0004_24.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id35_id31_0009_37.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id51_id57_0004_18.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id16_id6_0001_29.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id22_id25_0001_43.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id16_id3_0010_78.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id35_id28_0006_9.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id23_id2_0007_1.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id33_id38_0001_3.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id0_id6_0007_117.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id25_id24_0003_10.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id28_id20_0008_43.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id16_id21_0002_66.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id51_id50_0008_7.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id2_id9_0008_69.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id26_id28_0002_72.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id2_id6_0002_71.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id51_id57_0004_17.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id2_0009_64.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id29_id32_0000_87.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id0_id16_0003_36.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id21_id20_0006_37.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id20_0001_66.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id35_0009_69.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id4_0001_37.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id16_0005_89.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id0_id21_0000_113.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id29_id32_0000_75.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id2_id0_0002_24.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id26_id16_0001_45.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id20_0007_69.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id10_id12_0004_54.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id23_0006_78.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id23_0009_65.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id21_0006_70.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id1_0005_0.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id6_0007_35.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id34_0008_8.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id3_0002_27.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id23_id35_0006_55.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id48_id41_0001_52.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id17_id23_0000_14.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id31_id33_0009_54.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id1_0003_89.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id0_0001_94.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id0_id3_0007_2.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id2_0003_97.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id53_id58_0005_51.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id17_id16_0000_21.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id50_id49_0001_19.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id0_id26_0009_34.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id20_id1_0003_44.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id28_id26_0000_77.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id3_0002_58.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id29_id38_0008_87.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id21_0005_19.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id12_id10_0002_15.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id2_0007_43.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id3_0002_80.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id17_id26_0006_7.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id11_id7_0008_89.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id31_id2_0004_108.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id28_id6_0006_36.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id22_id25_0001_32.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id0_0004_2.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id16_0007_74.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id22_id27_0001_73.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id13_id7_0000_44.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id1_0003_21.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id3_id1_0001_87.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id17_id6_0000_50.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id20_id1_0003_40.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id26_id2_0005_56.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id24_id20_0009_15.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id20_0001_6.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id21_0009_28.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id28_id4_0006_32.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id57_id51_0000_11.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id2_id28_0003_44.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id2_id6_0002_52.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id17_id26_0006_32.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id38_id34_0004_64.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id50_id49_0001_62.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id26_id3_0002_74.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id2_0006_79.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id56_id55_0009_36.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id35_id23_0007_24.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id31_id16_0002_51.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id25_id24_0003_57.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id35_id31_0007_70.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id10_id7_0001_10.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id3_id28_0001_67.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id31_id2_0004_63.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id28_0006_53.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id28_id6_0006_31.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id10_id7_0004_82.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id2_id3_0008_68.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id23_0009_47.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id2_id28_0003_66.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id0_id6_0007_82.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id24_id26_0009_5.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id1_0007_12.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id8_id0_0002_20.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id3_0003_89.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id7_id13_0009_4.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id38_id34_0004_112.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id0_id21_0000_32.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id23_id19_0000_61.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id55_id57_0002_25.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id6_0007_86.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id3_id28_0001_17.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id23_id26_0003_27.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id0_id16_0003_104.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id20_id1_0003_63.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id47_id43_0007_49.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id27_id24_0007_26.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id21_id4_0002_50.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id44_id41_0005_53.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id35_id31_0007_48.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id0_id26_0009_110.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id29_id37_0008_53.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id3_0002_8.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id26_id3_0002_47.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id29_id37_0008_7.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id20_0008_69.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id20_0001_44.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id28_id26_0000_73.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id29_id38_0008_27.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id0_0007_31.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id27_id21_0008_81.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id16_0007_10.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id23_0006_16.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id8_id6_0002_87.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id7_id11_0009_74.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id3_id16_0001_31.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id28_0004_79.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id17_id3_0007_22.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id20_0004_90.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id1_0007_26.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id8_id5_0008_58.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id26_id28_0002_59.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id26_id2_0005_33.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id17_id1_0000_22.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id23_id35_0009_29.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id21_id6_0005_20.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id17_id2_0007_20.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id43_id40_0005_27.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id28_id20_0008_79.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id1_0003_45.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id0_id1_0001_17.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id7_id11_0007_81.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id17_id2_0007_12.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id57_id53_0006_82.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id22_id25_0001_57.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id28_id20_0006_71.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id44_id41_0005_80.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id16_id6_0011_32.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id21_id4_0002_44.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id31_id33_0009_95.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id20_id1_0007_10.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id21_0004_83.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id23_id35_0009_4.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id39_id47_0004_44.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id17_id16_0000_16.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id20_0000_40.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id23_id35_0006_65.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id33_id29_0004_46.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id44_id41_0005_50.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id33_id38_0001_110.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id22_id26_0005_46.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id31_id33_0009_53.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id3_0006_106.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id43_id39_0000_12.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id0_0004_31.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id42_id40_0001_20.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id17_id2_0000_63.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id29_id37_0005_68.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id23_id26_0003_3.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id16_0007_57.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id17_id2_0000_57.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id20_id19_0002_38.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id45_id39_0008_38.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id0_id1_0005_30.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id28_id4_0006_31.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id50_id56_0005_1.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id24_id19_0000_2.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id7_id11_0009_8.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id35_id32_0007_90.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id0_id1_0000_100.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id3_0009_30.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id35_id28_0006_18.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id21_0004_11.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id10_id13_0007_56.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id23_0001_27.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id3_0009_48.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id16_id0_0011_47.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id3_0004_55.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id31_id33_0008_47.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id39_id44_0008_54.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id16_id6_0001_48.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id29_id30_0000_53.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id6_id16_0005_3.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id24_id26_0009_44.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id12_id10_0002_29.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id49_id52_0005_88.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id55_id57_0002_38.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id1_0002_93.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id28_id21_0006_78.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id29_id30_0009_64.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id4_id0_0001_71.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id17_id31_0009_38.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id29_0002_111.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id25_id23_0010_86.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id23_id35_0006_21.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id38_id33_0005_60.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id44_id45_0000_16.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id21_id6_0005_23.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id34_id29_0008_39.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id37_id31_0008_27.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id35_id20_0007_25.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id30_id26_0006_29.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id20_id31_0006_13.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id3_id6_0001_73.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id48_id45_0002_76.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id9_id0_0000_44.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id28_id0_0009_0.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id34_id33_0002_12.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id3_id28_0002_73.jpg',\n",
       " '/hdd/tam/Celeb-DF/image/test/df/id1_id4_0007_0.jpg',\n",
       " ...]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(266, 187, 3)\n",
      "(457, 315, 3)\n",
      "(246, 180, 3)\n",
      "(233, 149, 3)\n",
      "(155, 119, 3)\n",
      "(229, 170, 3)\n",
      "(335, 253, 3)\n",
      "(219, 166, 3)\n",
      "(251, 197, 3)\n",
      "(454, 310, 3)\n",
      "(327, 240, 3)\n",
      "(219, 163, 3)\n",
      "(204, 147, 3)\n",
      "(222, 168, 3)\n",
      "(184, 153, 3)\n",
      "(168, 126, 3)\n",
      "(254, 173, 3)\n",
      "(217, 163, 3)\n",
      "(239, 170, 3)\n",
      "(238, 183, 3)\n",
      "(203, 139, 3)\n",
      "(253, 188, 3)\n",
      "(204, 146, 3)\n",
      "(219, 161, 3)\n",
      "(254, 187, 3)\n",
      "(252, 183, 3)\n",
      "(243, 181, 3)\n",
      "(245, 181, 3)\n",
      "(330, 245, 3)\n",
      "(273, 210, 3)\n",
      "(237, 166, 3)\n",
      "(229, 170, 3)\n",
      "(191, 141, 3)\n",
      "(209, 146, 3)\n",
      "(264, 183, 3)\n",
      "(289, 224, 3)\n",
      "(209, 154, 3)\n",
      "(215, 166, 3)\n",
      "(238, 174, 3)\n",
      "(153, 121, 3)\n",
      "(195, 142, 3)\n",
      "(187, 135, 3)\n",
      "(229, 166, 3)\n",
      "(362, 239, 3)\n",
      "(237, 166, 3)\n",
      "(156, 126, 3)\n",
      "(448, 317, 3)\n",
      "(359, 259, 3)\n",
      "(243, 181, 3)\n",
      "(288, 203, 3)\n",
      "(254, 182, 3)\n",
      "(261, 204, 3)\n",
      "(260, 184, 3)\n",
      "(314, 215, 3)\n",
      "(351, 254, 3)\n",
      "(240, 183, 3)\n",
      "(364, 267, 3)\n",
      "(190, 145, 3)\n",
      "(159, 113, 3)\n",
      "(259, 182, 3)\n",
      "(170, 114, 3)\n",
      "(203, 146, 3)\n",
      "(232, 163, 3)\n",
      "(253, 187, 3)\n",
      "(187, 138, 3)\n",
      "(240, 175, 3)\n",
      "(216, 148, 3)\n",
      "(343, 246, 3)\n",
      "(230, 156, 3)\n",
      "(194, 159, 3)\n",
      "(247, 194, 3)\n",
      "(211, 155, 3)\n",
      "(273, 210, 3)\n",
      "(210, 161, 3)\n",
      "(434, 307, 3)\n",
      "(330, 230, 3)\n",
      "(219, 159, 3)\n",
      "(285, 222, 3)\n",
      "(247, 174, 3)\n",
      "(229, 170, 3)\n",
      "(201, 156, 3)\n",
      "(197, 134, 3)\n",
      "(252, 181, 3)\n",
      "(229, 163, 3)\n",
      "(259, 184, 3)\n",
      "(278, 217, 3)\n",
      "(246, 177, 3)\n",
      "(464, 307, 3)\n",
      "(303, 238, 3)\n",
      "(161, 131, 3)\n",
      "(229, 168, 3)\n",
      "(323, 246, 3)\n",
      "(251, 174, 3)\n",
      "(168, 121, 3)\n",
      "(217, 170, 3)\n",
      "(357, 267, 3)\n",
      "(246, 181, 3)\n",
      "(300, 218, 3)\n",
      "(252, 203, 3)\n",
      "(259, 198, 3)\n",
      "(258, 219, 3)\n",
      "(173, 133, 3)\n",
      "(233, 176, 3)\n",
      "(243, 187, 3)\n",
      "(201, 147, 3)\n",
      "(251, 176, 3)\n",
      "(279, 202, 3)\n",
      "(260, 203, 3)\n",
      "(205, 145, 3)\n",
      "(205, 153, 3)\n",
      "(182, 155, 3)\n",
      "(201, 147, 3)\n",
      "(202, 153, 3)\n",
      "(160, 121, 3)\n",
      "(405, 307, 3)\n",
      "(162, 124, 3)\n",
      "(275, 218, 3)\n",
      "(250, 197, 3)\n",
      "(357, 246, 3)\n",
      "(321, 260, 3)\n",
      "(205, 153, 3)\n",
      "(233, 177, 3)\n",
      "(271, 191, 3)\n",
      "(247, 173, 3)\n",
      "(247, 188, 3)\n",
      "(257, 204, 3)\n",
      "(222, 163, 3)\n",
      "(222, 162, 3)\n",
      "(247, 177, 3)\n",
      "(230, 162, 3)\n",
      "(190, 131, 3)\n",
      "(187, 126, 3)\n",
      "(288, 217, 3)\n",
      "(215, 173, 3)\n",
      "(267, 195, 3)\n",
      "(253, 190, 3)\n",
      "(252, 204, 3)\n",
      "(198, 140, 3)\n",
      "(210, 145, 3)\n",
      "(377, 279, 3)\n",
      "(126, 99, 3)\n",
      "(257, 187, 3)\n",
      "(182, 145, 3)\n",
      "(261, 190, 3)\n",
      "(154, 120, 3)\n",
      "(307, 223, 3)\n",
      "(219, 163, 3)\n",
      "(161, 127, 3)\n",
      "(443, 316, 3)\n",
      "(265, 190, 3)\n",
      "(176, 133, 3)\n",
      "(203, 152, 3)\n",
      "(189, 140, 3)\n",
      "(334, 239, 3)\n",
      "(336, 253, 3)\n",
      "(229, 162, 3)\n",
      "(315, 232, 3)\n",
      "(155, 105, 3)\n",
      "(250, 181, 3)\n",
      "(359, 259, 3)\n",
      "(257, 180, 3)\n",
      "(240, 175, 3)\n",
      "(258, 187, 3)\n",
      "(236, 166, 3)\n",
      "(309, 245, 3)\n",
      "(286, 197, 3)\n",
      "(222, 159, 3)\n",
      "(299, 216, 3)\n",
      "(275, 190, 3)\n",
      "(161, 127, 3)\n",
      "(163, 121, 3)\n",
      "(251, 173, 3)\n",
      "(299, 219, 3)\n",
      "(223, 168, 3)\n",
      "(250, 177, 3)\n",
      "(289, 201, 3)\n",
      "(217, 167, 3)\n",
      "(250, 190, 3)\n",
      "(210, 159, 3)\n",
      "(246, 183, 3)\n",
      "(278, 208, 3)\n",
      "(441, 296, 3)\n",
      "(257, 204, 3)\n",
      "(299, 222, 3)\n",
      "(364, 259, 3)\n",
      "(266, 195, 3)\n",
      "(205, 146, 3)\n",
      "(348, 252, 3)\n",
      "(237, 168, 3)\n",
      "(288, 196, 3)\n",
      "(299, 218, 3)\n",
      "(253, 189, 3)\n",
      "(316, 210, 3)\n",
      "(274, 180, 3)\n",
      "(328, 240, 3)\n",
      "(204, 145, 3)\n",
      "(180, 121, 3)\n",
      "(275, 188, 3)\n",
      "(176, 145, 3)\n",
      "(208, 142, 3)\n",
      "(378, 278, 3)\n",
      "(268, 190, 3)\n",
      "(265, 201, 3)\n",
      "(244, 187, 3)\n",
      "(247, 184, 3)\n",
      "(309, 230, 3)\n",
      "(247, 168, 3)\n",
      "(161, 124, 3)\n",
      "(302, 216, 3)\n",
      "(148, 114, 3)\n",
      "(260, 180, 3)\n",
      "(253, 197, 3)\n",
      "(260, 197, 3)\n",
      "(188, 140, 3)\n",
      "(240, 184, 3)\n",
      "(209, 159, 3)\n",
      "(286, 211, 3)\n",
      "(273, 208, 3)\n",
      "(224, 182, 3)\n",
      "(300, 205, 3)\n",
      "(239, 182, 3)\n",
      "(351, 247, 3)\n",
      "(273, 204, 3)\n",
      "(251, 197, 3)\n",
      "(308, 223, 3)\n",
      "(194, 140, 3)\n",
      "(162, 127, 3)\n",
      "(259, 180, 3)\n",
      "(233, 181, 3)\n",
      "(282, 226, 3)\n",
      "(232, 169, 3)\n",
      "(161, 120, 3)\n",
      "(245, 190, 3)\n",
      "(233, 170, 3)\n",
      "(198, 142, 3)\n",
      "(163, 113, 3)\n",
      "(314, 240, 3)\n",
      "(244, 191, 3)\n",
      "(239, 173, 3)\n",
      "(251, 182, 3)\n",
      "(201, 149, 3)\n",
      "(148, 110, 3)\n",
      "(231, 166, 3)\n",
      "(239, 155, 3)\n",
      "(251, 187, 3)\n",
      "(331, 233, 3)\n",
      "(387, 321, 3)\n",
      "(180, 131, 3)\n",
      "(273, 212, 3)\n",
      "(217, 168, 3)\n",
      "(251, 188, 3)\n",
      "(148, 106, 3)\n",
      "(180, 125, 3)\n",
      "(351, 236, 3)\n",
      "(244, 170, 3)\n",
      "(258, 202, 3)\n",
      "(261, 197, 3)\n",
      "(225, 162, 3)\n",
      "(247, 177, 3)\n",
      "(184, 134, 3)\n",
      "(253, 180, 3)\n",
      "(251, 180, 3)\n",
      "(218, 161, 3)\n",
      "(194, 138, 3)\n",
      "(278, 205, 3)\n",
      "(251, 180, 3)\n",
      "(208, 142, 3)\n",
      "(394, 294, 3)\n",
      "(306, 226, 3)\n",
      "(250, 175, 3)\n",
      "(323, 232, 3)\n",
      "(245, 188, 3)\n",
      "(355, 253, 3)\n",
      "(195, 148, 3)\n",
      "(189, 152, 3)\n",
      "(149, 120, 3)\n",
      "(232, 174, 3)\n",
      "(203, 152, 3)\n",
      "(253, 187, 3)\n",
      "(286, 204, 3)\n",
      "(177, 133, 3)\n",
      "(230, 162, 3)\n",
      "(253, 190, 3)\n",
      "(279, 215, 3)\n",
      "(439, 317, 3)\n",
      "(266, 190, 3)\n",
      "(264, 196, 3)\n",
      "(321, 231, 3)\n",
      "(287, 194, 3)\n",
      "(334, 252, 3)\n",
      "(244, 182, 3)\n",
      "(365, 267, 3)\n",
      "(236, 161, 3)\n",
      "(253, 183, 3)\n",
      "(146, 112, 3)\n",
      "(441, 377, 3)\n",
      "(173, 131, 3)\n",
      "(210, 149, 3)\n",
      "(201, 132, 3)\n",
      "(236, 173, 3)\n",
      "(379, 266, 3)\n",
      "(194, 139, 3)\n",
      "(203, 153, 3)\n",
      "(261, 183, 3)\n",
      "(264, 197, 3)\n",
      "(167, 125, 3)\n",
      "(126, 99, 3)\n",
      "(267, 183, 3)\n",
      "(259, 195, 3)\n",
      "(306, 217, 3)\n",
      "(197, 148, 3)\n",
      "(230, 167, 3)\n",
      "(313, 240, 3)\n",
      "(287, 222, 3)\n",
      "(166, 113, 3)\n",
      "(191, 134, 3)\n",
      "(240, 191, 3)\n",
      "(282, 203, 3)\n",
      "(271, 205, 3)\n",
      "(182, 149, 3)\n",
      "(212, 156, 3)\n",
      "(231, 162, 3)\n",
      "(225, 163, 3)\n",
      "(246, 197, 3)\n",
      "(254, 176, 3)\n",
      "(271, 210, 3)\n",
      "(267, 210, 3)\n",
      "(225, 160, 3)\n",
      "(233, 174, 3)\n",
      "(219, 163, 3)\n",
      "(299, 219, 3)\n",
      "(288, 222, 3)\n",
      "(279, 202, 3)\n",
      "(210, 154, 3)\n",
      "(232, 162, 3)\n",
      "(236, 168, 3)\n",
      "(264, 191, 3)\n",
      "(306, 244, 3)\n",
      "(239, 175, 3)\n",
      "(286, 198, 3)\n",
      "(219, 174, 3)\n",
      "(295, 208, 3)\n",
      "(474, 324, 3)\n",
      "(152, 120, 3)\n",
      "(245, 181, 3)\n",
      "(294, 229, 3)\n",
      "(182, 153, 3)\n",
      "(152, 111, 3)\n",
      "(314, 243, 3)\n",
      "(272, 210, 3)\n",
      "(288, 194, 3)\n",
      "(281, 208, 3)\n",
      "(156, 105, 3)\n",
      "(184, 146, 3)\n",
      "(369, 271, 3)\n",
      "(446, 334, 3)\n",
      "(231, 166, 3)\n",
      "(197, 126, 3)\n",
      "(202, 155, 3)\n",
      "(182, 124, 3)\n",
      "(180, 125, 3)\n",
      "(342, 250, 3)\n",
      "(183, 153, 3)\n",
      "(225, 162, 3)\n",
      "(243, 181, 3)\n",
      "(247, 187, 3)\n",
      "(309, 244, 3)\n",
      "(386, 299, 3)\n",
      "(345, 257, 3)\n",
      "(264, 194, 3)\n",
      "(194, 149, 3)\n",
      "(215, 155, 3)\n",
      "(245, 180, 3)\n",
      "(257, 202, 3)\n",
      "(252, 183, 3)\n",
      "(294, 208, 3)\n",
      "(218, 161, 3)\n",
      "(295, 211, 3)\n",
      "(246, 190, 3)\n",
      "(159, 120, 3)\n",
      "(289, 187, 3)\n",
      "(224, 156, 3)\n",
      "(292, 216, 3)\n",
      "(286, 204, 3)\n",
      "(261, 182, 3)\n",
      "(286, 217, 3)\n",
      "(266, 180, 3)\n",
      "(162, 113, 3)\n",
      "(236, 180, 3)\n",
      "(307, 224, 3)\n",
      "(239, 163, 3)\n",
      "(292, 216, 3)\n",
      "(181, 134, 3)\n",
      "(237, 176, 3)\n",
      "(212, 162, 3)\n",
      "(253, 184, 3)\n",
      "(314, 223, 3)\n",
      "(202, 160, 3)\n",
      "(212, 147, 3)\n",
      "(225, 169, 3)\n",
      "(219, 154, 3)\n",
      "(223, 156, 3)\n",
      "(239, 175, 3)\n",
      "(274, 189, 3)\n",
      "(351, 264, 3)\n",
      "(244, 187, 3)\n",
      "(174, 114, 3)\n",
      "(267, 188, 3)\n",
      "(222, 167, 3)\n",
      "(180, 145, 3)\n",
      "(251, 196, 3)\n",
      "(313, 222, 3)\n",
      "(163, 134, 3)\n",
      "(316, 222, 3)\n",
      "(191, 154, 3)\n",
      "(229, 162, 3)\n",
      "(215, 162, 3)\n",
      "(341, 251, 3)\n",
      "(230, 162, 3)\n",
      "(252, 170, 3)\n",
      "(237, 170, 3)\n",
      "(222, 154, 3)\n",
      "(232, 155, 3)\n",
      "(363, 264, 3)\n",
      "(294, 215, 3)\n",
      "(198, 135, 3)\n",
      "(238, 173, 3)\n",
      "(245, 183, 3)\n",
      "(217, 154, 3)\n",
      "(161, 120, 3)\n",
      "(209, 146, 3)\n",
      "(303, 238, 3)\n",
      "(155, 120, 3)\n",
      "(205, 152, 3)\n",
      "(253, 195, 3)\n",
      "(279, 212, 3)\n",
      "(250, 177, 3)\n",
      "(120, 96, 3)\n",
      "(279, 218, 3)\n",
      "(224, 168, 3)\n",
      "(313, 224, 3)\n",
      "(321, 240, 3)\n",
      "(198, 152, 3)\n",
      "(195, 141, 3)\n",
      "(183, 153, 3)\n",
      "(225, 169, 3)\n",
      "(156, 120, 3)\n",
      "(343, 225, 3)\n",
      "(244, 180, 3)\n",
      "(331, 257, 3)\n",
      "(288, 215, 3)\n",
      "(345, 229, 3)\n",
      "(271, 190, 3)\n",
      "(232, 166, 3)\n",
      "(244, 169, 3)\n",
      "(251, 184, 3)\n",
      "(197, 161, 3)\n",
      "(155, 114, 3)\n",
      "(251, 176, 3)\n",
      "(357, 260, 3)\n",
      "(315, 243, 3)\n",
      "(170, 114, 3)\n",
      "(149, 114, 3)\n",
      "(259, 189, 3)\n",
      "(222, 167, 3)\n",
      "(153, 119, 3)\n",
      "(261, 191, 3)\n",
      "(244, 175, 3)\n",
      "(257, 180, 3)\n",
      "(218, 168, 3)\n",
      "(272, 209, 3)\n",
      "(376, 294, 3)\n",
      "(456, 324, 3)\n",
      "(202, 145, 3)\n",
      "(177, 131, 3)\n",
      "(258, 168, 3)\n",
      "(260, 191, 3)\n",
      "(160, 121, 3)\n",
      "(210, 154, 3)\n",
      "(236, 175, 3)\n",
      "(222, 162, 3)\n",
      "(222, 154, 3)\n",
      "(264, 204, 3)\n",
      "(320, 238, 3)\n",
      "(163, 121, 3)\n",
      "(351, 245, 3)\n",
      "(209, 147, 3)\n",
      "(279, 208, 3)\n",
      "(147, 110, 3)\n",
      "(203, 154, 3)\n",
      "(243, 182, 3)\n",
      "(230, 175, 3)\n",
      "(175, 138, 3)\n",
      "(223, 161, 3)\n",
      "(216, 153, 3)\n",
      "(287, 210, 3)\n",
      "(316, 237, 3)\n",
      "(239, 167, 3)\n",
      "(250, 202, 3)\n",
      "(273, 203, 3)\n",
      "(177, 120, 3)\n",
      "(253, 175, 3)\n",
      "(293, 224, 3)\n",
      "(352, 264, 3)\n",
      "(233, 170, 3)\n",
      "(268, 188, 3)\n",
      "(237, 180, 3)\n",
      "(244, 175, 3)\n",
      "(252, 195, 3)\n",
      "(258, 202, 3)\n",
      "(247, 175, 3)\n",
      "(303, 224, 3)\n",
      "(217, 166, 3)\n",
      "(229, 161, 3)\n",
      "(240, 176, 3)\n",
      "(176, 128, 3)\n",
      "(155, 118, 3)\n",
      "(246, 189, 3)\n",
      "(282, 211, 3)\n",
      "(313, 238, 3)\n",
      "(287, 211, 3)\n",
      "(238, 174, 3)\n",
      "(226, 168, 3)\n",
      "(452, 435, 3)\n",
      "(187, 141, 3)\n",
      "(161, 107, 3)\n",
      "(236, 168, 3)\n",
      "(247, 170, 3)\n",
      "(237, 175, 3)\n",
      "(251, 181, 3)\n",
      "(386, 271, 3)\n",
      "(238, 177, 3)\n",
      "(282, 204, 3)\n",
      "(247, 177, 3)\n",
      "(163, 124, 3)\n",
      "(278, 215, 3)\n",
      "(365, 250, 3)\n",
      "(295, 226, 3)\n",
      "(180, 131, 3)\n",
      "(264, 191, 3)\n",
      "(337, 245, 3)\n",
      "(285, 217, 3)\n",
      "(258, 188, 3)\n",
      "(331, 251, 3)\n",
      "(264, 182, 3)\n",
      "(279, 183, 3)\n",
      "(252, 198, 3)\n",
      "(331, 244, 3)\n",
      "(232, 167, 3)\n",
      "(182, 133, 3)\n",
      "(324, 260, 3)\n",
      "(169, 119, 3)\n",
      "(237, 181, 3)\n",
      "(219, 162, 3)\n",
      "(196, 132, 3)\n",
      "(253, 177, 3)\n",
      "(439, 303, 3)\n",
      "(251, 174, 3)\n",
      "(184, 134, 3)\n",
      "(218, 162, 3)\n",
      "(163, 124, 3)\n",
      "(148, 111, 3)\n",
      "(174, 126, 3)\n",
      "(456, 324, 3)\n",
      "(224, 163, 3)\n",
      "(149, 114, 3)\n",
      "(299, 230, 3)\n",
      "(229, 167, 3)\n",
      "(197, 149, 3)\n",
      "(176, 124, 3)\n",
      "(342, 252, 3)\n",
      "(250, 183, 3)\n",
      "(443, 301, 3)\n",
      "(279, 198, 3)\n",
      "(244, 182, 3)\n",
      "(274, 219, 3)\n",
      "(233, 174, 3)\n",
      "(244, 175, 3)\n",
      "(169, 120, 3)\n",
      "(272, 203, 3)\n",
      "(226, 168, 3)\n",
      "(154, 113, 3)\n",
      "(247, 196, 3)\n",
      "(285, 224, 3)\n",
      "(210, 148, 3)\n",
      "(259, 190, 3)\n",
      "(253, 195, 3)\n",
      "(275, 191, 3)\n",
      "(315, 244, 3)\n",
      "(159, 112, 3)\n",
      "(146, 111, 3)\n",
      "(388, 282, 3)\n",
      "(238, 167, 3)\n",
      "(230, 166, 3)\n",
      "(259, 166, 3)\n",
      "(240, 174, 3)\n",
      "(229, 168, 3)\n",
      "(237, 155, 3)\n",
      "(223, 163, 3)\n",
      "(453, 320, 3)\n",
      "(303, 229, 3)\n",
      "(274, 202, 3)\n",
      "(244, 189, 3)\n",
      "(225, 154, 3)\n",
      "(161, 124, 3)\n",
      "(330, 253, 3)\n",
      "(245, 166, 3)\n",
      "(218, 161, 3)\n",
      "(180, 139, 3)\n",
      "(223, 160, 3)\n",
      "(268, 190, 3)\n",
      "(328, 244, 3)\n",
      "(239, 183, 3)\n",
      "(279, 198, 3)\n",
      "(138, 97, 3)\n",
      "(230, 154, 3)\n",
      "(175, 125, 3)\n",
      "(182, 135, 3)\n",
      "(191, 145, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155, 114, 3)\n",
      "(373, 302, 3)\n",
      "(253, 181, 3)\n",
      "(272, 211, 3)\n",
      "(246, 181, 3)\n",
      "(250, 196, 3)\n",
      "(308, 226, 3)\n",
      "(209, 169, 3)\n",
      "(384, 301, 3)\n",
      "(202, 148, 3)\n",
      "(328, 232, 3)\n",
      "(288, 198, 3)\n",
      "(182, 139, 3)\n",
      "(254, 181, 3)\n",
      "(177, 146, 3)\n",
      "(182, 138, 3)\n",
      "(240, 173, 3)\n",
      "(250, 194, 3)\n",
      "(243, 166, 3)\n",
      "(240, 174, 3)\n",
      "(216, 149, 3)\n",
      "(321, 266, 3)\n",
      "(250, 169, 3)\n",
      "(287, 209, 3)\n",
      "(316, 230, 3)\n",
      "(443, 314, 3)\n",
      "(191, 138, 3)\n",
      "(205, 148, 3)\n",
      "(358, 257, 3)\n",
      "(187, 125, 3)\n",
      "(225, 155, 3)\n",
      "(203, 141, 3)\n",
      "(343, 252, 3)\n",
      "(292, 217, 3)\n",
      "(224, 167, 3)\n",
      "(197, 153, 3)\n",
      "(273, 215, 3)\n",
      "(224, 162, 3)\n",
      "(226, 170, 3)\n",
      "(217, 161, 3)\n",
      "(140, 104, 3)\n",
      "(252, 176, 3)\n",
      "(310, 224, 3)\n",
      "(197, 154, 3)\n",
      "(217, 154, 3)\n",
      "(194, 133, 3)\n",
      "(226, 176, 3)\n",
      "(237, 153, 3)\n",
      "(191, 128, 3)\n",
      "(223, 169, 3)\n",
      "(254, 182, 3)\n",
      "(240, 187, 3)\n",
      "(195, 148, 3)\n",
      "(280, 208, 3)\n",
      "(260, 184, 3)\n",
      "(225, 166, 3)\n",
      "(215, 155, 3)\n",
      "(252, 198, 3)\n",
      "(217, 154, 3)\n",
      "(266, 187, 3)\n",
      "(328, 259, 3)\n",
      "(219, 167, 3)\n",
      "(229, 170, 3)\n",
      "(237, 190, 3)\n",
      "(266, 190, 3)\n",
      "(429, 317, 3)\n",
      "(231, 166, 3)\n",
      "(327, 236, 3)\n",
      "(307, 204, 3)\n",
      "(181, 149, 3)\n",
      "(202, 149, 3)\n",
      "(196, 140, 3)\n",
      "(224, 170, 3)\n",
      "(219, 159, 3)\n",
      "(127, 92, 3)\n",
      "(315, 224, 3)\n",
      "(246, 184, 3)\n",
      "(253, 181, 3)\n",
      "(181, 138, 3)\n",
      "(306, 216, 3)\n",
      "(267, 197, 3)\n",
      "(259, 180, 3)\n",
      "(176, 134, 3)\n",
      "(240, 184, 3)\n",
      "(218, 149, 3)\n",
      "(253, 201, 3)\n",
      "(166, 126, 3)\n",
      "(245, 175, 3)\n",
      "(223, 162, 3)\n",
      "(145, 105, 3)\n",
      "(254, 202, 3)\n",
      "(126, 97, 3)\n",
      "(231, 168, 3)\n",
      "(252, 180, 3)\n",
      "(259, 191, 3)\n",
      "(233, 183, 3)\n",
      "(201, 148, 3)\n",
      "(194, 155, 3)\n",
      "(231, 170, 3)\n",
      "(233, 176, 3)\n",
      "(337, 252, 3)\n",
      "(323, 243, 3)\n",
      "(271, 176, 3)\n",
      "(342, 244, 3)\n",
      "(264, 190, 3)\n",
      "(224, 168, 3)\n",
      "(258, 205, 3)\n",
      "(251, 183, 3)\n",
      "(229, 153, 3)\n",
      "(232, 175, 3)\n",
      "(264, 203, 3)\n",
      "(146, 107, 3)\n",
      "(222, 162, 3)\n",
      "(173, 142, 3)\n",
      "(244, 180, 3)\n",
      "(246, 183, 3)\n",
      "(288, 203, 3)\n",
      "(184, 140, 3)\n",
      "(440, 300, 3)\n",
      "(202, 139, 3)\n",
      "(252, 182, 3)\n",
      "(217, 149, 3)\n",
      "(331, 244, 3)\n",
      "(253, 182, 3)\n",
      "(194, 146, 3)\n",
      "(201, 154, 3)\n",
      "(217, 154, 3)\n",
      "(247, 183, 3)\n",
      "(247, 174, 3)\n",
      "(225, 163, 3)\n",
      "(251, 175, 3)\n",
      "(225, 166, 3)\n",
      "(301, 236, 3)\n",
      "(209, 147, 3)\n",
      "(231, 170, 3)\n",
      "(307, 217, 3)\n",
      "(275, 205, 3)\n",
      "(226, 155, 3)\n",
      "(356, 272, 3)\n",
      "(239, 209, 3)\n",
      "(267, 191, 3)\n",
      "(259, 188, 3)\n",
      "(238, 182, 3)\n",
      "(196, 145, 3)\n",
      "(169, 133, 3)\n",
      "(271, 183, 3)\n",
      "(341, 244, 3)\n",
      "(240, 181, 3)\n",
      "(238, 170, 3)\n",
      "(190, 140, 3)\n",
      "(140, 100, 3)\n",
      "(238, 181, 3)\n",
      "(237, 177, 3)\n",
      "(161, 120, 3)\n",
      "(196, 156, 3)\n",
      "(229, 161, 3)\n",
      "(413, 287, 3)\n",
      "(223, 160, 3)\n",
      "(251, 180, 3)\n",
      "(260, 183, 3)\n",
      "(211, 154, 3)\n",
      "(370, 280, 3)\n",
      "(231, 160, 3)\n",
      "(226, 162, 3)\n",
      "(219, 148, 3)\n",
      "(174, 138, 3)\n",
      "(449, 314, 3)\n",
      "(321, 233, 3)\n",
      "(307, 216, 3)\n",
      "(184, 148, 3)\n",
      "(197, 149, 3)\n",
      "(236, 169, 3)\n",
      "(295, 222, 3)\n",
      "(300, 209, 3)\n",
      "(247, 189, 3)\n",
      "(236, 173, 3)\n",
      "(202, 148, 3)\n",
      "(231, 170, 3)\n",
      "(188, 140, 3)\n",
      "(226, 167, 3)\n",
      "(279, 197, 3)\n",
      "(154, 117, 3)\n",
      "(236, 173, 3)\n",
      "(267, 190, 3)\n",
      "(289, 211, 3)\n",
      "(244, 183, 3)\n",
      "(259, 181, 3)\n",
      "(226, 168, 3)\n",
      "(268, 188, 3)\n",
      "(233, 163, 3)\n",
      "(243, 188, 3)\n",
      "(203, 149, 3)\n",
      "(217, 155, 3)\n",
      "(223, 166, 3)\n",
      "(244, 187, 3)\n",
      "(331, 250, 3)\n",
      "(275, 198, 3)\n",
      "(309, 230, 3)\n",
      "(336, 250, 3)\n",
      "(257, 181, 3)\n",
      "(222, 167, 3)\n",
      "(201, 148, 3)\n",
      "(145, 133, 3)\n",
      "(267, 195, 3)\n",
      "(251, 190, 3)\n",
      "(231, 180, 3)\n",
      "(225, 155, 3)\n",
      "(205, 161, 3)\n",
      "(419, 285, 3)\n",
      "(257, 205, 3)\n",
      "(245, 190, 3)\n",
      "(260, 201, 3)\n",
      "(181, 128, 3)\n",
      "(264, 202, 3)\n",
      "(187, 140, 3)\n",
      "(419, 288, 3)\n",
      "(232, 168, 3)\n",
      "(323, 237, 3)\n",
      "(191, 132, 3)\n",
      "(243, 181, 3)\n",
      "(321, 237, 3)\n",
      "(259, 181, 3)\n",
      "(219, 163, 3)\n",
      "(282, 196, 3)\n",
      "(296, 204, 3)\n",
      "(160, 107, 3)\n",
      "(267, 196, 3)\n",
      "(264, 184, 3)\n",
      "(181, 133, 3)\n",
      "(209, 146, 3)\n",
      "(257, 210, 3)\n",
      "(294, 204, 3)\n",
      "(246, 202, 3)\n",
      "(254, 188, 3)\n",
      "(189, 149, 3)\n",
      "(310, 229, 3)\n",
      "(278, 211, 3)\n",
      "(226, 174, 3)\n",
      "(155, 120, 3)\n",
      "(191, 139, 3)\n",
      "(244, 170, 3)\n",
      "(160, 118, 3)\n",
      "(343, 250, 3)\n",
      "(253, 182, 3)\n",
      "(271, 198, 3)\n",
      "(428, 308, 3)\n",
      "(176, 133, 3)\n",
      "(240, 177, 3)\n",
      "(426, 295, 3)\n",
      "(245, 184, 3)\n",
      "(268, 203, 3)\n",
      "(309, 215, 3)\n",
      "(142, 104, 3)\n",
      "(250, 175, 3)\n",
      "(280, 210, 3)\n",
      "(217, 160, 3)\n",
      "(365, 258, 3)\n",
      "(251, 183, 3)\n",
      "(156, 125, 3)\n",
      "(154, 113, 3)\n",
      "(209, 152, 3)\n",
      "(257, 190, 3)\n",
      "(264, 182, 3)\n",
      "(219, 161, 3)\n",
      "(280, 195, 3)\n",
      "(279, 191, 3)\n",
      "(303, 226, 3)\n",
      "(148, 114, 3)\n",
      "(190, 138, 3)\n",
      "(267, 196, 3)\n",
      "(159, 121, 3)\n",
      "(204, 154, 3)\n",
      "(224, 156, 3)\n",
      "(257, 197, 3)\n",
      "(321, 245, 3)\n",
      "(222, 168, 3)\n",
      "(240, 174, 3)\n",
      "(267, 198, 3)\n",
      "(247, 184, 3)\n",
      "(226, 153, 3)\n",
      "(245, 194, 3)\n",
      "(190, 128, 3)\n",
      "(320, 243, 3)\n",
      "(386, 295, 3)\n",
      "(279, 196, 3)\n",
      "(345, 251, 3)\n",
      "(260, 181, 3)\n",
      "(177, 153, 3)\n",
      "(232, 167, 3)\n",
      "(191, 149, 3)\n",
      "(244, 169, 3)\n",
      "(112, 85, 3)\n",
      "(303, 233, 3)\n",
      "(288, 196, 3)\n",
      "(222, 168, 3)\n",
      "(274, 215, 3)\n",
      "(240, 176, 3)\n",
      "(237, 170, 3)\n",
      "(257, 201, 3)\n",
      "(230, 163, 3)\n",
      "(330, 244, 3)\n",
      "(196, 162, 3)\n",
      "(195, 149, 3)\n",
      "(238, 174, 3)\n",
      "(225, 168, 3)\n",
      "(411, 287, 3)\n",
      "(183, 149, 3)\n",
      "(254, 184, 3)\n",
      "(201, 149, 3)\n",
      "(197, 139, 3)\n",
      "(258, 194, 3)\n",
      "(370, 258, 3)\n",
      "(238, 173, 3)\n",
      "(288, 210, 3)\n",
      "(209, 148, 3)\n",
      "(217, 166, 3)\n",
      "(275, 217, 3)\n",
      "(202, 152, 3)\n",
      "(209, 149, 3)\n",
      "(266, 196, 3)\n",
      "(222, 182, 3)\n",
      "(205, 142, 3)\n",
      "(240, 187, 3)\n",
      "(289, 209, 3)\n",
      "(222, 162, 3)\n",
      "(237, 168, 3)\n",
      "(156, 118, 3)\n",
      "(222, 161, 3)\n",
      "(140, 99, 3)\n",
      "(231, 168, 3)\n",
      "(341, 243, 3)\n",
      "(223, 160, 3)\n",
      "(188, 124, 3)\n",
      "(196, 145, 3)\n",
      "(275, 208, 3)\n",
      "(181, 132, 3)\n",
      "(146, 106, 3)\n",
      "(215, 163, 3)\n",
      "(364, 259, 3)\n",
      "(155, 120, 3)\n",
      "(194, 142, 3)\n",
      "(238, 173, 3)\n",
      "(243, 177, 3)\n",
      "(240, 174, 3)\n",
      "(338, 247, 3)\n",
      "(240, 166, 3)\n",
      "(246, 183, 3)\n",
      "(209, 147, 3)\n",
      "(306, 216, 3)\n",
      "(384, 268, 3)\n",
      "(216, 147, 3)\n",
      "(217, 159, 3)\n",
      "(237, 173, 3)\n",
      "(225, 174, 3)\n",
      "(140, 105, 3)\n",
      "(215, 146, 3)\n",
      "(219, 154, 3)\n",
      "(209, 153, 3)\n",
      "(285, 218, 3)\n",
      "(175, 126, 3)\n",
      "(194, 134, 3)\n",
      "(273, 195, 3)\n",
      "(208, 149, 3)\n",
      "(267, 211, 3)\n",
      "(238, 174, 3)\n",
      "(195, 146, 3)\n",
      "(180, 119, 3)\n",
      "(202, 159, 3)\n",
      "(216, 167, 3)\n",
      "(210, 155, 3)\n",
      "(226, 166, 3)\n",
      "(159, 124, 3)\n",
      "(177, 142, 3)\n",
      "(204, 135, 3)\n",
      "(252, 170, 3)\n",
      "(168, 140, 3)\n",
      "(309, 240, 3)\n",
      "(259, 205, 3)\n",
      "(210, 154, 3)\n",
      "(265, 182, 3)\n",
      "(252, 201, 3)\n",
      "(301, 210, 3)\n",
      "(266, 198, 3)\n",
      "(183, 138, 3)\n",
      "(202, 147, 3)\n",
      "(294, 216, 3)\n",
      "(209, 148, 3)\n",
      "(282, 203, 3)\n",
      "(232, 163, 3)\n",
      "(149, 125, 3)\n",
      "(161, 121, 3)\n",
      "(154, 114, 3)\n",
      "(163, 113, 3)\n",
      "(365, 259, 3)\n",
      "(180, 133, 3)\n",
      "(238, 184, 3)\n",
      "(209, 149, 3)\n",
      "(320, 246, 3)\n",
      "(224, 169, 3)\n",
      "(205, 148, 3)\n",
      "(250, 168, 3)\n",
      "(154, 118, 3)\n",
      "(345, 250, 3)\n",
      "(285, 205, 3)\n",
      "(239, 174, 3)\n",
      "(334, 236, 3)\n",
      "(188, 128, 3)\n",
      "(244, 190, 3)\n",
      "(225, 167, 3)\n",
      "(319, 259, 3)\n",
      "(211, 146, 3)\n",
      "(170, 127, 3)\n",
      "(196, 161, 3)\n",
      "(230, 156, 3)\n",
      "(187, 135, 3)\n",
      "(168, 140, 3)\n",
      "(183, 142, 3)\n",
      "(252, 174, 3)\n",
      "(244, 181, 3)\n",
      "(251, 183, 3)\n",
      "(303, 218, 3)\n",
      "(245, 168, 3)\n",
      "(209, 148, 3)\n",
      "(302, 245, 3)\n",
      "(313, 245, 3)\n",
      "(324, 251, 3)\n",
      "(198, 131, 3)\n",
      "(226, 174, 3)\n",
      "(181, 128, 3)\n",
      "(245, 191, 3)\n",
      "(321, 240, 3)\n",
      "(212, 162, 3)\n",
      "(218, 161, 3)\n",
      "(223, 156, 3)\n",
      "(152, 118, 3)\n",
      "(320, 240, 3)\n",
      "(321, 237, 3)\n",
      "(310, 240, 3)\n",
      "(230, 173, 3)\n",
      "(245, 169, 3)\n",
      "(219, 163, 3)\n",
      "(254, 187, 3)\n",
      "(251, 190, 3)\n",
      "(251, 197, 3)\n",
      "(302, 225, 3)\n",
      "(166, 127, 3)\n",
      "(267, 190, 3)\n",
      "(238, 177, 3)\n",
      "(303, 224, 3)\n",
      "(153, 120, 3)\n",
      "(218, 161, 3)\n",
      "(175, 125, 3)\n",
      "(254, 180, 3)\n",
      "(230, 174, 3)\n",
      "(229, 155, 3)\n",
      "(264, 211, 3)\n",
      "(299, 223, 3)\n",
      "(457, 324, 3)\n",
      "(238, 168, 3)\n",
      "(237, 170, 3)\n",
      "(240, 184, 3)\n",
      "(251, 194, 3)\n",
      "(303, 243, 3)\n",
      "(204, 159, 3)\n",
      "(299, 219, 3)\n",
      "(215, 149, 3)\n",
      "(173, 127, 3)\n",
      "(245, 194, 3)\n",
      "(316, 236, 3)\n",
      "(201, 142, 3)\n",
      "(182, 135, 3)\n",
      "(285, 223, 3)\n",
      "(223, 161, 3)\n",
      "(208, 154, 3)\n",
      "(231, 161, 3)\n",
      "(166, 127, 3)\n",
      "(338, 247, 3)\n",
      "(240, 177, 3)\n",
      "(259, 209, 3)\n",
      "(244, 170, 3)\n",
      "(194, 140, 3)\n",
      "(272, 210, 3)\n",
      "(201, 152, 3)\n",
      "(217, 161, 3)\n",
      "(285, 202, 3)\n",
      "(152, 110, 3)\n",
      "(285, 198, 3)\n",
      "(231, 180, 3)\n",
      "(194, 132, 3)\n",
      "(196, 146, 3)\n",
      "(210, 139, 3)\n",
      "(352, 265, 3)\n",
      "(239, 169, 3)\n",
      "(203, 142, 3)\n",
      "(196, 146, 3)\n",
      "(251, 181, 3)\n",
      "(299, 209, 3)\n",
      "(253, 180, 3)\n",
      "(232, 154, 3)\n",
      "(272, 197, 3)\n",
      "(321, 231, 3)\n",
      "(273, 210, 3)\n",
      "(194, 125, 3)\n",
      "(222, 170, 3)\n",
      "(210, 159, 3)\n",
      "(231, 169, 3)\n",
      "(309, 238, 3)\n",
      "(273, 196, 3)\n",
      "(253, 195, 3)\n",
      "(246, 170, 3)\n",
      "(197, 156, 3)\n",
      "(307, 231, 3)\n",
      "(289, 215, 3)\n",
      "(317, 247, 3)\n",
      "(286, 218, 3)\n",
      "(306, 208, 3)\n",
      "(166, 126, 3)\n",
      "(324, 245, 3)\n",
      "(198, 148, 3)\n",
      "(162, 133, 3)\n",
      "(271, 198, 3)\n",
      "(224, 163, 3)\n",
      "(177, 121, 3)\n",
      "(237, 188, 3)\n",
      "(257, 191, 3)\n",
      "(197, 166, 3)\n",
      "(250, 176, 3)\n",
      "(243, 188, 3)\n",
      "(293, 208, 3)\n",
      "(153, 114, 3)\n",
      "(295, 222, 3)\n",
      "(211, 169, 3)\n",
      "(184, 135, 3)\n",
      "(190, 142, 3)\n",
      "(250, 183, 3)\n",
      "(295, 218, 3)\n",
      "(233, 177, 3)\n",
      "(243, 183, 3)\n",
      "(204, 145, 3)\n",
      "(239, 177, 3)\n",
      "(250, 181, 3)\n",
      "(208, 154, 3)\n",
      "(218, 170, 3)\n",
      "(443, 310, 3)\n",
      "(229, 159, 3)\n",
      "(191, 135, 3)\n",
      "(341, 247, 3)\n",
      "(278, 204, 3)\n",
      "(384, 289, 3)\n",
      "(224, 162, 3)\n",
      "(313, 239, 3)\n",
      "(247, 195, 3)\n",
      "(170, 121, 3)\n",
      "(238, 180, 3)\n",
      "(224, 168, 3)\n",
      "(299, 226, 3)\n",
      "(244, 183, 3)\n",
      "(183, 139, 3)\n",
      "(252, 189, 3)\n",
      "(273, 176, 3)\n",
      "(203, 162, 3)\n",
      "(331, 231, 3)\n",
      "(153, 107, 3)\n",
      "(162, 120, 3)\n",
      "(288, 224, 3)\n",
      "(218, 166, 3)\n",
      "(292, 210, 3)\n",
      "(218, 163, 3)\n",
      "(257, 188, 3)\n",
      "(203, 140, 3)\n",
      "(335, 252, 3)\n",
      "(337, 250, 3)\n",
      "(335, 240, 3)\n",
      "(229, 161, 3)\n",
      "(162, 119, 3)\n",
      "(257, 181, 3)\n",
      "(280, 223, 3)\n",
      "(323, 225, 3)\n",
      "(239, 167, 3)\n",
      "(272, 189, 3)\n",
      "(449, 316, 3)\n",
      "(278, 191, 3)\n",
      "(230, 174, 3)\n",
      "(196, 148, 3)\n",
      "(253, 184, 3)\n",
      "(254, 187, 3)\n",
      "(205, 134, 3)\n",
      "(453, 315, 3)\n",
      "(196, 145, 3)\n",
      "(273, 232, 3)\n",
      "(343, 254, 3)\n",
      "(433, 316, 3)\n",
      "(191, 140, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(264, 198, 3)\n",
      "(250, 184, 3)\n",
      "(264, 189, 3)\n",
      "(300, 211, 3)\n",
      "(398, 281, 3)\n",
      "(247, 180, 3)\n",
      "(237, 174, 3)\n",
      "(317, 243, 3)\n",
      "(257, 198, 3)\n",
      "(225, 162, 3)\n",
      "(196, 146, 3)\n",
      "(191, 141, 3)\n",
      "(198, 125, 3)\n",
      "(194, 142, 3)\n",
      "(295, 215, 3)\n",
      "(246, 182, 3)\n",
      "(331, 243, 3)\n",
      "(224, 163, 3)\n",
      "(215, 147, 3)\n",
      "(440, 295, 3)\n",
      "(160, 121, 3)\n",
      "(226, 169, 3)\n",
      "(422, 302, 3)\n",
      "(306, 215, 3)\n",
      "(285, 212, 3)\n",
      "(265, 189, 3)\n",
      "(233, 163, 3)\n",
      "(230, 167, 3)\n",
      "(240, 180, 3)\n",
      "(285, 209, 3)\n",
      "(344, 246, 3)\n",
      "(260, 205, 3)\n",
      "(245, 176, 3)\n",
      "(254, 177, 3)\n",
      "(232, 167, 3)\n",
      "(264, 177, 3)\n",
      "(183, 135, 3)\n",
      "(236, 160, 3)\n",
      "(250, 190, 3)\n",
      "(204, 155, 3)\n",
      "(246, 176, 3)\n",
      "(253, 188, 3)\n",
      "(174, 128, 3)\n",
      "(300, 243, 3)\n",
      "(187, 126, 3)\n",
      "(310, 236, 3)\n",
      "(464, 293, 3)\n",
      "(224, 166, 3)\n",
      "(145, 106, 3)\n",
      "(218, 161, 3)\n",
      "(279, 209, 3)\n",
      "(181, 133, 3)\n",
      "(244, 180, 3)\n",
      "(230, 166, 3)\n",
      "(232, 169, 3)\n",
      "(153, 114, 3)\n",
      "(246, 181, 3)\n",
      "(250, 182, 3)\n",
      "(233, 181, 3)\n",
      "(250, 195, 3)\n",
      "(181, 141, 3)\n",
      "(259, 196, 3)\n",
      "(253, 188, 3)\n",
      "(219, 169, 3)\n",
      "(219, 161, 3)\n",
      "(378, 261, 3)\n",
      "(174, 131, 3)\n",
      "(238, 181, 3)\n",
      "(232, 163, 3)\n",
      "(152, 114, 3)\n",
      "(237, 163, 3)\n",
      "(201, 152, 3)\n",
      "(189, 132, 3)\n",
      "(204, 141, 3)\n",
      "(272, 189, 3)\n",
      "(253, 183, 3)\n",
      "(307, 232, 3)\n",
      "(211, 161, 3)\n",
      "(441, 308, 3)\n",
      "(245, 181, 3)\n",
      "(238, 167, 3)\n",
      "(215, 154, 3)\n",
      "(303, 223, 3)\n",
      "(205, 163, 3)\n",
      "(257, 180, 3)\n",
      "(247, 183, 3)\n",
      "(278, 191, 3)\n",
      "(197, 155, 3)\n",
      "(390, 295, 3)\n",
      "(197, 153, 3)\n",
      "(166, 120, 3)\n",
      "(231, 183, 3)\n",
      "(243, 180, 3)\n",
      "(245, 176, 3)\n",
      "(198, 153, 3)\n",
      "(392, 300, 3)\n",
      "(324, 232, 3)\n",
      "(237, 176, 3)\n",
      "(126, 99, 3)\n",
      "(434, 310, 3)\n",
      "(306, 240, 3)\n",
      "(223, 162, 3)\n",
      "(148, 110, 3)\n",
      "(260, 190, 3)\n",
      "(240, 177, 3)\n",
      "(149, 121, 3)\n",
      "(232, 177, 3)\n",
      "(146, 113, 3)\n",
      "(187, 128, 3)\n",
      "(302, 233, 3)\n",
      "(443, 323, 3)\n",
      "(204, 161, 3)\n",
      "(278, 209, 3)\n",
      "(225, 159, 3)\n",
      "(198, 146, 3)\n",
      "(183, 147, 3)\n",
      "(252, 196, 3)\n",
      "(257, 189, 3)\n",
      "(257, 196, 3)\n",
      "(253, 183, 3)\n",
      "(331, 232, 3)\n",
      "(224, 166, 3)\n",
      "(187, 135, 3)\n",
      "(187, 145, 3)\n",
      "(153, 131, 3)\n",
      "(173, 142, 3)\n",
      "(370, 260, 3)\n",
      "(182, 134, 3)\n",
      "(295, 230, 3)\n",
      "(320, 243, 3)\n",
      "(222, 162, 3)\n",
      "(191, 148, 3)\n",
      "(216, 163, 3)\n",
      "(282, 202, 3)\n",
      "(197, 132, 3)\n",
      "(260, 187, 3)\n",
      "(195, 132, 3)\n",
      "(260, 197, 3)\n",
      "(294, 203, 3)\n",
      "(217, 168, 3)\n",
      "(240, 176, 3)\n",
      "(212, 152, 3)\n",
      "(236, 169, 3)\n",
      "(252, 201, 3)\n",
      "(169, 121, 3)\n",
      "(231, 156, 3)\n",
      "(201, 142, 3)\n",
      "(324, 238, 3)\n",
      "(222, 167, 3)\n",
      "(261, 210, 3)\n",
      "(351, 250, 3)\n",
      "(229, 168, 3)\n",
      "(252, 202, 3)\n",
      "(449, 307, 3)\n",
      "(208, 146, 3)\n",
      "(292, 230, 3)\n",
      "(204, 153, 3)\n",
      "(292, 226, 3)\n",
      "(215, 167, 3)\n",
      "(194, 140, 3)\n",
      "(190, 154, 3)\n",
      "(250, 182, 3)\n",
      "(383, 264, 3)\n",
      "(245, 183, 3)\n",
      "(153, 119, 3)\n",
      "(343, 261, 3)\n",
      "(259, 182, 3)\n",
      "(258, 189, 3)\n",
      "(254, 201, 3)\n",
      "(292, 222, 3)\n",
      "(293, 208, 3)\n",
      "(176, 135, 3)\n",
      "(260, 177, 3)\n",
      "(278, 217, 3)\n",
      "(252, 202, 3)\n",
      "(201, 145, 3)\n",
      "(230, 162, 3)\n",
      "(222, 180, 3)\n",
      "(350, 244, 3)\n",
      "(286, 204, 3)\n",
      "(160, 124, 3)\n",
      "(282, 201, 3)\n",
      "(257, 180, 3)\n",
      "(236, 184, 3)\n",
      "(202, 148, 3)\n",
      "(321, 238, 3)\n",
      "(251, 170, 3)\n",
      "(240, 167, 3)\n",
      "(215, 152, 3)\n",
      "(160, 121, 3)\n",
      "(258, 187, 3)\n",
      "(160, 118, 3)\n",
      "(239, 174, 3)\n",
      "(237, 168, 3)\n",
      "(257, 198, 3)\n",
      "(177, 155, 3)\n",
      "(201, 152, 3)\n",
      "(210, 159, 3)\n",
      "(253, 177, 3)\n",
      "(218, 161, 3)\n",
      "(239, 176, 3)\n",
      "(223, 161, 3)\n",
      "(251, 169, 3)\n",
      "(247, 190, 3)\n",
      "(155, 118, 3)\n",
      "(254, 184, 3)\n",
      "(230, 168, 3)\n",
      "(226, 168, 3)\n",
      "(176, 138, 3)\n",
      "(205, 148, 3)\n",
      "(236, 174, 3)\n",
      "(152, 114, 3)\n",
      "(253, 176, 3)\n",
      "(205, 146, 3)\n",
      "(183, 145, 3)\n",
      "(247, 196, 3)\n",
      "(257, 189, 3)\n",
      "(218, 167, 3)\n",
      "(175, 140, 3)\n",
      "(218, 160, 3)\n",
      "(202, 146, 3)\n",
      "(254, 177, 3)\n",
      "(239, 167, 3)\n",
      "(160, 113, 3)\n",
      "(338, 259, 3)\n",
      "(247, 177, 3)\n",
      "(275, 191, 3)\n",
      "(238, 189, 3)\n",
      "(243, 177, 3)\n",
      "(439, 303, 3)\n",
      "(238, 177, 3)\n",
      "(253, 182, 3)\n",
      "(292, 230, 3)\n",
      "(232, 166, 3)\n",
      "(258, 195, 3)\n",
      "(160, 118, 3)\n",
      "(226, 168, 3)\n",
      "(369, 254, 3)\n",
      "(314, 244, 3)\n",
      "(260, 174, 3)\n",
      "(159, 120, 3)\n",
      "(258, 176, 3)\n",
      "(254, 190, 3)\n",
      "(223, 173, 3)\n",
      "(324, 230, 3)\n",
      "(184, 131, 3)\n",
      "(442, 317, 3)\n",
      "(217, 163, 3)\n",
      "(302, 211, 3)\n",
      "(238, 180, 3)\n",
      "(119, 86, 3)\n",
      "(337, 245, 3)\n",
      "(233, 170, 3)\n",
      "(211, 166, 3)\n",
      "(237, 180, 3)\n",
      "(337, 251, 3)\n",
      "(204, 152, 3)\n",
      "(154, 121, 3)\n",
      "(250, 197, 3)\n",
      "(236, 174, 3)\n",
      "(162, 118, 3)\n",
      "(240, 177, 3)\n",
      "(191, 133, 3)\n",
      "(250, 188, 3)\n",
      "(308, 246, 3)\n",
      "(153, 111, 3)\n",
      "(205, 148, 3)\n",
      "(203, 149, 3)\n",
      "(215, 174, 3)\n",
      "(232, 168, 3)\n",
      "(343, 259, 3)\n",
      "(314, 218, 3)\n",
      "(280, 204, 3)\n",
      "(349, 271, 3)\n",
      "(175, 125, 3)\n",
      "(231, 169, 3)\n",
      "(244, 175, 3)\n",
      "(161, 120, 3)\n",
      "(260, 181, 3)\n",
      "(308, 223, 3)\n",
      "(250, 170, 3)\n",
      "(257, 203, 3)\n",
      "(174, 119, 3)\n",
      "(215, 152, 3)\n",
      "(422, 299, 3)\n",
      "(240, 180, 3)\n",
      "(233, 177, 3)\n",
      "(201, 160, 3)\n",
      "(243, 168, 3)\n",
      "(288, 215, 3)\n",
      "(252, 183, 3)\n",
      "(211, 145, 3)\n",
      "(252, 188, 3)\n",
      "(230, 167, 3)\n",
      "(198, 141, 3)\n",
      "(252, 183, 3)\n",
      "(182, 140, 3)\n",
      "(181, 146, 3)\n",
      "(273, 201, 3)\n",
      "(390, 296, 3)\n",
      "(257, 184, 3)\n",
      "(238, 182, 3)\n",
      "(236, 173, 3)\n",
      "(299, 226, 3)\n",
      "(251, 196, 3)\n",
      "(246, 170, 3)\n",
      "(210, 156, 3)\n",
      "(215, 154, 3)\n",
      "(175, 125, 3)\n",
      "(177, 118, 3)\n",
      "(188, 135, 3)\n",
      "(167, 133, 3)\n",
      "(225, 166, 3)\n",
      "(210, 148, 3)\n",
      "(202, 148, 3)\n",
      "(301, 212, 3)\n",
      "(159, 120, 3)\n",
      "(240, 184, 3)\n",
      "(159, 120, 3)\n",
      "(224, 166, 3)\n",
      "(177, 146, 3)\n",
      "(226, 155, 3)\n",
      "(190, 134, 3)\n",
      "(217, 168, 3)\n",
      "(219, 154, 3)\n",
      "(191, 132, 3)\n",
      "(306, 204, 3)\n",
      "(194, 141, 3)\n",
      "(265, 203, 3)\n",
      "(341, 261, 3)\n",
      "(197, 141, 3)\n",
      "(230, 168, 3)\n",
      "(450, 322, 3)\n",
      "(253, 181, 3)\n",
      "(187, 142, 3)\n",
      "(279, 201, 3)\n",
      "(250, 173, 3)\n",
      "(238, 166, 3)\n",
      "(313, 222, 3)\n",
      "(288, 219, 3)\n",
      "(295, 217, 3)\n",
      "(210, 156, 3)\n",
      "(247, 169, 3)\n",
      "(250, 195, 3)\n",
      "(308, 225, 3)\n",
      "(238, 170, 3)\n",
      "(358, 257, 3)\n",
      "(452, 453, 3)\n",
      "(176, 128, 3)\n",
      "(292, 223, 3)\n",
      "(233, 169, 3)\n",
      "(421, 300, 3)\n",
      "(440, 302, 3)\n",
      "(323, 238, 3)\n",
      "(205, 155, 3)\n",
      "(223, 168, 3)\n",
      "(336, 240, 3)\n",
      "(223, 159, 3)\n",
      "(300, 215, 3)\n",
      "(356, 257, 3)\n",
      "(282, 209, 3)\n",
      "(229, 166, 3)\n",
      "(251, 176, 3)\n",
      "(237, 176, 3)\n",
      "(237, 188, 3)\n",
      "(216, 160, 3)\n",
      "(231, 170, 3)\n",
      "(246, 176, 3)\n",
      "(275, 216, 3)\n",
      "(212, 167, 3)\n",
      "(250, 176, 3)\n",
      "(182, 142, 3)\n",
      "(231, 168, 3)\n",
      "(272, 204, 3)\n",
      "(331, 233, 3)\n",
      "(218, 166, 3)\n",
      "(254, 181, 3)\n",
      "(239, 181, 3)\n",
      "(181, 133, 3)\n",
      "(205, 153, 3)\n",
      "(280, 217, 3)\n",
      "(195, 149, 3)\n",
      "(201, 162, 3)\n",
      "(266, 198, 3)\n",
      "(258, 170, 3)\n",
      "(160, 120, 3)\n",
      "(362, 240, 3)\n",
      "(168, 124, 3)\n",
      "(252, 201, 3)\n",
      "(202, 140, 3)\n",
      "(250, 183, 3)\n",
      "(219, 161, 3)\n",
      "(275, 208, 3)\n",
      "(345, 257, 3)\n",
      "(253, 177, 3)\n",
      "(238, 174, 3)\n",
      "(357, 258, 3)\n",
      "(196, 153, 3)\n",
      "(265, 183, 3)\n",
      "(258, 204, 3)\n",
      "(222, 148, 3)\n",
      "(211, 161, 3)\n",
      "(288, 203, 3)\n",
      "(237, 181, 3)\n",
      "(170, 127, 3)\n",
      "(211, 155, 3)\n",
      "(205, 149, 3)\n",
      "(254, 187, 3)\n",
      "(216, 168, 3)\n",
      "(322, 240, 3)\n",
      "(184, 132, 3)\n",
      "(259, 197, 3)\n",
      "(264, 188, 3)\n",
      "(216, 166, 3)\n",
      "(155, 120, 3)\n",
      "(250, 184, 3)\n",
      "(301, 226, 3)\n",
      "(392, 310, 3)\n",
      "(337, 245, 3)\n",
      "(237, 175, 3)\n",
      "(230, 175, 3)\n",
      "(322, 229, 3)\n",
      "(153, 126, 3)\n",
      "(223, 154, 3)\n",
      "(252, 175, 3)\n",
      "(289, 203, 3)\n",
      "(205, 162, 3)\n",
      "(236, 180, 3)\n",
      "(434, 309, 3)\n",
      "(181, 125, 3)\n",
      "(252, 174, 3)\n",
      "(245, 176, 3)\n",
      "(236, 181, 3)\n",
      "(254, 177, 3)\n",
      "(162, 119, 3)\n",
      "(160, 127, 3)\n",
      "(254, 177, 3)\n",
      "(167, 124, 3)\n",
      "(159, 124, 3)\n",
      "(343, 252, 3)\n",
      "(245, 176, 3)\n",
      "(329, 239, 3)\n",
      "(191, 149, 3)\n",
      "(303, 204, 3)\n",
      "(230, 175, 3)\n",
      "(189, 139, 3)\n",
      "(314, 226, 3)\n",
      "(289, 217, 3)\n",
      "(338, 245, 3)\n",
      "(204, 140, 3)\n",
      "(222, 159, 3)\n",
      "(195, 133, 3)\n",
      "(354, 264, 3)\n",
      "(217, 153, 3)\n",
      "(183, 134, 3)\n",
      "(323, 237, 3)\n",
      "(205, 152, 3)\n",
      "(239, 181, 3)\n",
      "(223, 152, 3)\n",
      "(204, 134, 3)\n",
      "(156, 113, 3)\n",
      "(216, 155, 3)\n",
      "(175, 140, 3)\n",
      "(246, 168, 3)\n",
      "(142, 97, 3)\n",
      "(343, 254, 3)\n",
      "(337, 238, 3)\n",
      "(279, 211, 3)\n",
      "(183, 133, 3)\n",
      "(201, 146, 3)\n",
      "(244, 195, 3)\n",
      "(231, 167, 3)\n",
      "(175, 149, 3)\n",
      "(142, 106, 3)\n",
      "(194, 140, 3)\n",
      "(317, 231, 3)\n",
      "(201, 141, 3)\n",
      "(229, 160, 3)\n",
      "(253, 208, 3)\n",
      "(160, 127, 3)\n",
      "(184, 138, 3)\n",
      "(204, 142, 3)\n",
      "(229, 166, 3)\n",
      "(226, 170, 3)\n",
      "(211, 163, 3)\n",
      "(232, 188, 3)\n",
      "(238, 175, 3)\n",
      "(231, 177, 3)\n",
      "(244, 175, 3)\n",
      "(203, 152, 3)\n",
      "(380, 258, 3)\n",
      "(201, 149, 3)\n",
      "(252, 197, 3)\n",
      "(252, 173, 3)\n",
      "(465, 317, 3)\n",
      "(205, 146, 3)\n",
      "(245, 188, 3)\n",
      "(426, 314, 3)\n",
      "(289, 204, 3)\n",
      "(224, 159, 3)\n",
      "(299, 219, 3)\n",
      "(168, 126, 3)\n",
      "(281, 219, 3)\n",
      "(279, 217, 3)\n",
      "(219, 168, 3)\n",
      "(210, 156, 3)\n",
      "(197, 132, 3)\n",
      "(188, 153, 3)\n",
      "(313, 219, 3)\n",
      "(345, 260, 3)\n",
      "(310, 224, 3)\n",
      "(225, 169, 3)\n",
      "(218, 173, 3)\n",
      "(247, 183, 3)\n",
      "(243, 175, 3)\n",
      "(230, 155, 3)\n",
      "(191, 147, 3)\n",
      "(244, 181, 3)\n",
      "(303, 209, 3)\n",
      "(260, 183, 3)\n",
      "(244, 187, 3)\n",
      "(196, 138, 3)\n",
      "(271, 197, 3)\n",
      "(261, 181, 3)\n",
      "(281, 210, 3)\n",
      "(163, 120, 3)\n",
      "(212, 155, 3)\n",
      "(316, 236, 3)\n",
      "(415, 301, 3)\n",
      "(147, 106, 3)\n",
      "(272, 205, 3)\n",
      "(161, 120, 3)\n",
      "(245, 182, 3)\n",
      "(266, 182, 3)\n",
      "(363, 243, 3)\n",
      "(257, 197, 3)\n",
      "(356, 254, 3)\n",
      "(309, 252, 3)\n",
      "(198, 146, 3)\n",
      "(274, 212, 3)\n",
      "(240, 176, 3)\n",
      "(187, 145, 3)\n",
      "(266, 194, 3)\n",
      "(211, 154, 3)\n",
      "(140, 104, 3)\n",
      "(300, 208, 3)\n",
      "(246, 176, 3)\n",
      "(244, 190, 3)\n",
      "(149, 112, 3)\n",
      "(355, 258, 3)\n",
      "(314, 243, 3)\n",
      "(274, 190, 3)\n",
      "(247, 191, 3)\n",
      "(258, 183, 3)\n",
      "(140, 100, 3)\n",
      "(219, 168, 3)\n",
      "(198, 145, 3)\n",
      "(245, 174, 3)\n",
      "(294, 219, 3)\n",
      "(265, 196, 3)\n",
      "(170, 128, 3)\n",
      "(261, 188, 3)\n",
      "(243, 181, 3)\n",
      "(334, 253, 3)\n",
      "(195, 146, 3)\n",
      "(251, 173, 3)\n",
      "(224, 167, 3)\n",
      "(196, 121, 3)\n",
      "(191, 142, 3)\n",
      "(208, 159, 3)\n",
      "(154, 105, 3)\n",
      "(308, 222, 3)\n",
      "(366, 254, 3)\n",
      "(243, 181, 3)\n",
      "(216, 163, 3)\n",
      "(212, 167, 3)\n",
      "(224, 168, 3)\n",
      "(296, 217, 3)\n",
      "(239, 175, 3)\n",
      "(261, 197, 3)\n",
      "(203, 146, 3)\n",
      "(265, 176, 3)\n",
      "(282, 203, 3)\n",
      "(219, 167, 3)\n",
      "(328, 238, 3)\n",
      "(146, 114, 3)\n",
      "(310, 236, 3)\n",
      "(218, 161, 3)\n",
      "(247, 181, 3)\n",
      "(280, 198, 3)\n",
      "(226, 170, 3)\n",
      "(334, 231, 3)\n",
      "(177, 128, 3)\n",
      "(231, 175, 3)\n",
      "(230, 166, 3)\n",
      "(177, 121, 3)\n",
      "(208, 152, 3)\n",
      "(84, 64, 3)\n",
      "(302, 202, 3)\n",
      "(243, 189, 3)\n",
      "(259, 195, 3)\n",
      "(223, 163, 3)\n",
      "(222, 176, 3)\n",
      "(184, 146, 3)\n",
      "(189, 146, 3)\n",
      "(244, 174, 3)\n",
      "(218, 168, 3)\n",
      "(189, 142, 3)\n",
      "(204, 153, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 153, 3)\n",
      "(274, 191, 3)\n",
      "(257, 188, 3)\n",
      "(314, 219, 3)\n",
      "(243, 184, 3)\n",
      "(222, 154, 3)\n",
      "(247, 188, 3)\n",
      "(231, 163, 3)\n",
      "(294, 212, 3)\n",
      "(243, 183, 3)\n",
      "(208, 156, 3)\n",
      "(223, 155, 3)\n",
      "(237, 175, 3)\n",
      "(246, 170, 3)\n",
      "(212, 159, 3)\n",
      "(247, 181, 3)\n",
      "(303, 250, 3)\n",
      "(236, 175, 3)\n",
      "(195, 155, 3)\n",
      "(250, 181, 3)\n",
      "(239, 173, 3)\n",
      "(149, 104, 3)\n",
      "(310, 224, 3)\n",
      "(205, 159, 3)\n",
      "(229, 176, 3)\n",
      "(385, 295, 3)\n",
      "(344, 266, 3)\n",
      "(246, 182, 3)\n",
      "(274, 203, 3)\n",
      "(231, 166, 3)\n",
      "(287, 209, 3)\n",
      "(224, 162, 3)\n",
      "(299, 237, 3)\n",
      "(254, 182, 3)\n",
      "(201, 149, 3)\n",
      "(273, 182, 3)\n",
      "(244, 175, 3)\n",
      "(204, 147, 3)\n",
      "(229, 181, 3)\n",
      "(313, 243, 3)\n",
      "(208, 160, 3)\n",
      "(233, 175, 3)\n",
      "(246, 180, 3)\n",
      "(229, 167, 3)\n",
      "(331, 252, 3)\n",
      "(154, 113, 3)\n",
      "(279, 203, 3)\n",
      "(259, 168, 3)\n",
      "(240, 166, 3)\n",
      "(247, 191, 3)\n",
      "(232, 168, 3)\n",
      "(149, 111, 3)\n",
      "(155, 117, 3)\n",
      "(161, 124, 3)\n",
      "(352, 265, 3)\n",
      "(218, 161, 3)\n",
      "(250, 189, 3)\n",
      "(253, 197, 3)\n",
      "(203, 160, 3)\n",
      "(265, 189, 3)\n",
      "(313, 237, 3)\n",
      "(181, 142, 3)\n",
      "(230, 163, 3)\n",
      "(198, 147, 3)\n",
      "(216, 166, 3)\n",
      "(226, 175, 3)\n",
      "(252, 187, 3)\n",
      "(225, 166, 3)\n",
      "(251, 180, 3)\n",
      "(211, 145, 3)\n",
      "(237, 174, 3)\n",
      "(245, 188, 3)\n",
      "(169, 126, 3)\n",
      "(324, 246, 3)\n",
      "(209, 152, 3)\n",
      "(267, 190, 3)\n",
      "(147, 107, 3)\n",
      "(265, 190, 3)\n",
      "(198, 153, 3)\n",
      "(244, 182, 3)\n",
      "(328, 243, 3)\n",
      "(209, 152, 3)\n",
      "(219, 155, 3)\n",
      "(245, 197, 3)\n",
      "(344, 251, 3)\n",
      "(259, 180, 3)\n",
      "(211, 160, 3)\n",
      "(155, 113, 3)\n",
      "(160, 117, 3)\n",
      "(156, 112, 3)\n",
      "(175, 149, 3)\n",
      "(181, 131, 3)\n",
      "(225, 168, 3)\n",
      "(201, 141, 3)\n",
      "(320, 245, 3)\n",
      "(370, 278, 3)\n",
      "(363, 266, 3)\n",
      "(300, 224, 3)\n",
      "(355, 252, 3)\n",
      "(240, 182, 3)\n",
      "(231, 163, 3)\n",
      "(197, 145, 3)\n",
      "(279, 203, 3)\n",
      "(302, 233, 3)\n",
      "(268, 202, 3)\n",
      "(323, 222, 3)\n",
      "(237, 181, 3)\n",
      "(225, 163, 3)\n",
      "(180, 134, 3)\n",
      "(254, 177, 3)\n",
      "(152, 106, 3)\n",
      "(236, 170, 3)\n",
      "(292, 222, 3)\n",
      "(236, 163, 3)\n",
      "(272, 202, 3)\n",
      "(231, 160, 3)\n",
      "(180, 138, 3)\n",
      "(232, 163, 3)\n",
      "(280, 211, 3)\n",
      "(153, 106, 3)\n",
      "(324, 210, 3)\n",
      "(246, 175, 3)\n",
      "(208, 156, 3)\n",
      "(197, 149, 3)\n",
      "(382, 285, 3)\n",
      "(265, 198, 3)\n",
      "(379, 257, 3)\n",
      "(264, 188, 3)\n",
      "(265, 191, 3)\n",
      "(223, 159, 3)\n",
      "(232, 163, 3)\n",
      "(244, 182, 3)\n",
      "(224, 166, 3)\n",
      "(287, 196, 3)\n",
      "(244, 174, 3)\n",
      "(219, 152, 3)\n",
      "(264, 191, 3)\n",
      "(306, 240, 3)\n",
      "(294, 230, 3)\n",
      "(184, 141, 3)\n",
      "(202, 161, 3)\n",
      "(223, 166, 3)\n",
      "(289, 210, 3)\n",
      "(174, 140, 3)\n",
      "(257, 191, 3)\n",
      "(148, 114, 3)\n",
      "(306, 236, 3)\n",
      "(356, 266, 3)\n",
      "(196, 147, 3)\n",
      "(329, 237, 3)\n",
      "(145, 106, 3)\n",
      "(244, 170, 3)\n",
      "(190, 142, 3)\n",
      "(245, 176, 3)\n",
      "(243, 173, 3)\n",
      "(243, 187, 3)\n",
      "(219, 168, 3)\n",
      "(303, 250, 3)\n",
      "(307, 217, 3)\n",
      "(232, 174, 3)\n",
      "(258, 188, 3)\n",
      "(224, 161, 3)\n",
      "(324, 250, 3)\n",
      "(349, 266, 3)\n",
      "(245, 197, 3)\n",
      "(287, 210, 3)\n",
      "(300, 211, 3)\n",
      "(244, 176, 3)\n",
      "(229, 169, 3)\n",
      "(167, 126, 3)\n",
      "(224, 175, 3)\n",
      "(246, 176, 3)\n",
      "(299, 224, 3)\n",
      "(250, 181, 3)\n",
      "(167, 124, 3)\n",
      "(296, 229, 3)\n",
      "(203, 132, 3)\n",
      "(225, 161, 3)\n",
      "(244, 163, 3)\n",
      "(442, 314, 3)\n",
      "(232, 169, 3)\n",
      "(308, 219, 3)\n",
      "(231, 183, 3)\n",
      "(239, 177, 3)\n",
      "(237, 175, 3)\n",
      "(222, 162, 3)\n",
      "(238, 184, 3)\n",
      "(473, 329, 3)\n",
      "(278, 197, 3)\n",
      "(153, 117, 3)\n",
      "(153, 113, 3)\n",
      "(225, 162, 3)\n",
      "(232, 183, 3)\n",
      "(210, 154, 3)\n",
      "(316, 239, 3)\n",
      "(233, 177, 3)\n",
      "(350, 259, 3)\n",
      "(254, 212, 3)\n",
      "(252, 188, 3)\n",
      "(295, 238, 3)\n",
      "(198, 146, 3)\n",
      "(252, 197, 3)\n",
      "(219, 166, 3)\n",
      "(174, 126, 3)\n",
      "(267, 210, 3)\n",
      "(306, 209, 3)\n",
      "(160, 117, 3)\n",
      "(225, 168, 3)\n",
      "(223, 163, 3)\n",
      "(224, 167, 3)\n",
      "(155, 120, 3)\n",
      "(275, 210, 3)\n",
      "(278, 222, 3)\n",
      "(240, 176, 3)\n",
      "(236, 167, 3)\n",
      "(195, 146, 3)\n",
      "(236, 177, 3)\n",
      "(184, 142, 3)\n",
      "(292, 209, 3)\n",
      "(229, 167, 3)\n",
      "(320, 238, 3)\n",
      "(253, 188, 3)\n",
      "(215, 161, 3)\n",
      "(336, 250, 3)\n",
      "(313, 237, 3)\n",
      "(217, 167, 3)\n",
      "(350, 268, 3)\n",
      "(303, 217, 3)\n",
      "(259, 173, 3)\n",
      "(307, 203, 3)\n",
      "(308, 237, 3)\n",
      "(223, 176, 3)\n",
      "(223, 147, 3)\n",
      "(224, 174, 3)\n",
      "(191, 141, 3)\n",
      "(191, 135, 3)\n",
      "(209, 152, 3)\n",
      "(177, 134, 3)\n",
      "(246, 195, 3)\n",
      "(222, 162, 3)\n",
      "(398, 337, 3)\n",
      "(257, 173, 3)\n",
      "(176, 138, 3)\n",
      "(247, 203, 3)\n",
      "(219, 166, 3)\n",
      "(176, 135, 3)\n",
      "(226, 176, 3)\n",
      "(166, 120, 3)\n",
      "(210, 153, 3)\n",
      "(240, 176, 3)\n",
      "(285, 222, 3)\n",
      "(236, 169, 3)\n",
      "(244, 188, 3)\n",
      "(189, 148, 3)\n",
      "(300, 201, 3)\n",
      "(266, 190, 3)\n",
      "(338, 239, 3)\n",
      "(188, 139, 3)\n",
      "(238, 173, 3)\n",
      "(222, 168, 3)\n",
      "(187, 148, 3)\n",
      "(203, 146, 3)\n",
      "(356, 264, 3)\n",
      "(303, 226, 3)\n",
      "(201, 153, 3)\n",
      "(230, 169, 3)\n",
      "(265, 205, 3)\n",
      "(240, 187, 3)\n",
      "(127, 93, 3)\n",
      "(226, 162, 3)\n",
      "(306, 202, 3)\n",
      "(163, 120, 3)\n",
      "(191, 149, 3)\n",
      "(266, 205, 3)\n",
      "(219, 163, 3)\n",
      "(266, 180, 3)\n",
      "(287, 205, 3)\n",
      "(345, 254, 3)\n",
      "(295, 222, 3)\n",
      "(175, 126, 3)\n",
      "(279, 202, 3)\n",
      "(239, 175, 3)\n",
      "(232, 183, 3)\n",
      "(285, 195, 3)\n",
      "(259, 195, 3)\n",
      "(327, 233, 3)\n",
      "(217, 154, 3)\n",
      "(231, 180, 3)\n",
      "(299, 210, 3)\n",
      "(266, 184, 3)\n",
      "(231, 174, 3)\n",
      "(380, 273, 3)\n",
      "(230, 168, 3)\n",
      "(292, 216, 3)\n",
      "(352, 251, 3)\n",
      "(202, 160, 3)\n",
      "(222, 166, 3)\n",
      "(244, 166, 3)\n",
      "(244, 160, 3)\n",
      "(204, 145, 3)\n",
      "(232, 170, 3)\n",
      "(224, 166, 3)\n",
      "(369, 267, 3)\n",
      "(252, 195, 3)\n",
      "(260, 190, 3)\n",
      "(251, 181, 3)\n",
      "(177, 148, 3)\n",
      "(278, 203, 3)\n",
      "(265, 198, 3)\n",
      "(188, 133, 3)\n",
      "(222, 154, 3)\n",
      "(370, 282, 3)\n",
      "(224, 166, 3)\n",
      "(335, 244, 3)\n",
      "(184, 135, 3)\n",
      "(163, 131, 3)\n",
      "(183, 139, 3)\n",
      "(261, 203, 3)\n",
      "(217, 152, 3)\n",
      "(266, 210, 3)\n",
      "(159, 120, 3)\n",
      "(289, 219, 3)\n",
      "(285, 208, 3)\n",
      "(224, 166, 3)\n",
      "(352, 250, 3)\n",
      "(163, 133, 3)\n",
      "(219, 174, 3)\n",
      "(373, 279, 3)\n",
      "(226, 175, 3)\n",
      "(296, 218, 3)\n",
      "(293, 208, 3)\n",
      "(223, 173, 3)\n",
      "(190, 142, 3)\n",
      "(273, 187, 3)\n",
      "(176, 125, 3)\n",
      "(183, 132, 3)\n",
      "(265, 190, 3)\n",
      "(208, 149, 3)\n",
      "(183, 135, 3)\n",
      "(209, 161, 3)\n",
      "(236, 166, 3)\n",
      "(230, 173, 3)\n",
      "(197, 148, 3)\n",
      "(209, 167, 3)\n",
      "(328, 240, 3)\n",
      "(342, 259, 3)\n",
      "(169, 117, 3)\n",
      "(253, 183, 3)\n",
      "(166, 125, 3)\n",
      "(184, 141, 3)\n",
      "(302, 215, 3)\n",
      "(187, 128, 3)\n",
      "(187, 134, 3)\n",
      "(286, 216, 3)\n",
      "(233, 177, 3)\n",
      "(229, 167, 3)\n",
      "(240, 190, 3)\n",
      "(236, 176, 3)\n",
      "(231, 173, 3)\n",
      "(215, 155, 3)\n",
      "(231, 169, 3)\n",
      "(292, 203, 3)\n",
      "(292, 219, 3)\n",
      "(233, 180, 3)\n",
      "(226, 167, 3)\n",
      "(205, 154, 3)\n",
      "(182, 153, 3)\n",
      "(219, 159, 3)\n",
      "(196, 149, 3)\n",
      "(336, 243, 3)\n",
      "(245, 188, 3)\n",
      "(229, 168, 3)\n",
      "(404, 302, 3)\n",
      "(173, 118, 3)\n",
      "(238, 170, 3)\n",
      "(226, 155, 3)\n",
      "(219, 170, 3)\n",
      "(182, 127, 3)\n",
      "(314, 202, 3)\n",
      "(156, 118, 3)\n",
      "(258, 195, 3)\n",
      "(202, 149, 3)\n",
      "(198, 147, 3)\n",
      "(63, 64, 3)\n",
      "(230, 163, 3)\n",
      "(231, 167, 3)\n",
      "(260, 181, 3)\n",
      "(226, 170, 3)\n",
      "(351, 252, 3)\n",
      "(174, 142, 3)\n",
      "(217, 159, 3)\n",
      "(449, 317, 3)\n",
      "(233, 176, 3)\n",
      "(364, 267, 3)\n",
      "(240, 187, 3)\n",
      "(253, 194, 3)\n",
      "(392, 279, 3)\n",
      "(201, 149, 3)\n",
      "(266, 189, 3)\n",
      "(236, 208, 3)\n",
      "(33, 26, 3)\n",
      "(217, 161, 3)\n",
      "(223, 166, 3)\n",
      "(223, 160, 3)\n",
      "(126, 99, 3)\n",
      "(191, 127, 3)\n",
      "(279, 215, 3)\n",
      "(169, 128, 3)\n",
      "(182, 131, 3)\n",
      "(335, 246, 3)\n",
      "(243, 173, 3)\n",
      "(281, 215, 3)\n",
      "(317, 239, 3)\n",
      "(189, 135, 3)\n",
      "(274, 215, 3)\n",
      "(211, 161, 3)\n",
      "(310, 223, 3)\n",
      "(274, 197, 3)\n",
      "(201, 146, 3)\n",
      "(356, 254, 3)\n",
      "(336, 243, 3)\n",
      "(299, 217, 3)\n",
      "(161, 125, 3)\n",
      "(245, 182, 3)\n",
      "(201, 147, 3)\n",
      "(203, 149, 3)\n",
      "(237, 168, 3)\n",
      "(212, 167, 3)\n",
      "(127, 98, 3)\n",
      "(211, 146, 3)\n",
      "(196, 142, 3)\n",
      "(245, 176, 3)\n",
      "(201, 146, 3)\n",
      "(259, 190, 3)\n",
      "(286, 201, 3)\n",
      "(218, 168, 3)\n",
      "(313, 251, 3)\n",
      "(204, 162, 3)\n",
      "(226, 166, 3)\n",
      "(254, 188, 3)\n",
      "(251, 173, 3)\n",
      "(449, 338, 3)\n",
      "(259, 189, 3)\n",
      "(174, 141, 3)\n",
      "(196, 152, 3)\n",
      "(245, 189, 3)\n",
      "(208, 155, 3)\n",
      "(278, 203, 3)\n",
      "(328, 239, 3)\n",
      "(229, 166, 3)\n",
      "(215, 159, 3)\n",
      "(233, 175, 3)\n",
      "(174, 153, 3)\n",
      "(245, 180, 3)\n",
      "(243, 188, 3)\n",
      "(184, 142, 3)\n",
      "(426, 310, 3)\n",
      "(315, 251, 3)\n",
      "(236, 183, 3)\n",
      "(226, 163, 3)\n",
      "(237, 162, 3)\n",
      "(212, 168, 3)\n",
      "(232, 173, 3)\n",
      "(278, 217, 3)\n",
      "(225, 160, 3)\n",
      "(198, 149, 3)\n",
      "(211, 154, 3)\n",
      "(189, 140, 3)\n",
      "(222, 166, 3)\n",
      "(210, 167, 3)\n",
      "(211, 166, 3)\n",
      "(253, 189, 3)\n",
      "(219, 173, 3)\n",
      "(275, 210, 3)\n",
      "(252, 174, 3)\n",
      "(147, 106, 3)\n",
      "(299, 217, 3)\n",
      "(208, 147, 3)\n",
      "(280, 208, 3)\n",
      "(160, 121, 3)\n",
      "(238, 173, 3)\n",
      "(229, 160, 3)\n",
      "(334, 245, 3)\n",
      "(291, 237, 3)\n",
      "(155, 120, 3)\n",
      "(217, 161, 3)\n",
      "(275, 217, 3)\n",
      "(175, 118, 3)\n",
      "(246, 189, 3)\n",
      "(231, 175, 3)\n",
      "(274, 203, 3)\n",
      "(225, 173, 3)\n",
      "(421, 303, 3)\n",
      "(216, 166, 3)\n",
      "(322, 247, 3)\n",
      "(205, 161, 3)\n",
      "(181, 121, 3)\n",
      "(189, 155, 3)\n",
      "(217, 159, 3)\n",
      "(155, 117, 3)\n",
      "(237, 183, 3)\n",
      "(204, 161, 3)\n",
      "(287, 236, 3)\n",
      "(218, 166, 3)\n",
      "(240, 168, 3)\n",
      "(233, 168, 3)\n",
      "(218, 162, 3)\n",
      "(265, 191, 3)\n",
      "(166, 113, 3)\n",
      "(230, 167, 3)\n",
      "(254, 180, 3)\n",
      "(229, 155, 3)\n",
      "(296, 222, 3)\n",
      "(210, 149, 3)\n",
      "(202, 155, 3)\n",
      "(245, 191, 3)\n",
      "(156, 121, 3)\n",
      "(203, 154, 3)\n",
      "(194, 156, 3)\n",
      "(309, 218, 3)\n",
      "(251, 182, 3)\n",
      "(168, 127, 3)\n",
      "(247, 180, 3)\n",
      "(257, 177, 3)\n",
      "(239, 175, 3)\n",
      "(147, 126, 3)\n",
      "(230, 174, 3)\n",
      "(272, 202, 3)\n",
      "(289, 210, 3)\n",
      "(245, 174, 3)\n",
      "(252, 181, 3)\n",
      "(246, 184, 3)\n",
      "(324, 229, 3)\n",
      "(251, 180, 3)\n",
      "(246, 183, 3)\n",
      "(253, 175, 3)\n",
      "(187, 145, 3)\n",
      "(259, 194, 3)\n",
      "(238, 176, 3)\n",
      "(29, 23, 3)\n",
      "(224, 155, 3)\n",
      "(258, 181, 3)\n",
      "(266, 197, 3)\n",
      "(258, 177, 3)\n",
      "(211, 166, 3)\n",
      "(279, 212, 3)\n",
      "(320, 230, 3)\n",
      "(306, 223, 3)\n",
      "(236, 177, 3)\n",
      "(208, 154, 3)\n",
      "(183, 148, 3)\n",
      "(267, 180, 3)\n",
      "(183, 148, 3)\n",
      "(216, 163, 3)\n",
      "(202, 142, 3)\n",
      "(216, 153, 3)\n",
      "(202, 156, 3)\n",
      "(314, 239, 3)\n",
      "(266, 183, 3)\n",
      "(156, 117, 3)\n",
      "(254, 191, 3)\n",
      "(252, 182, 3)\n",
      "(183, 146, 3)\n",
      "(190, 154, 3)\n",
      "(281, 204, 3)\n",
      "(197, 140, 3)\n",
      "(216, 160, 3)\n",
      "(215, 145, 3)\n",
      "(133, 97, 3)\n",
      "(240, 182, 3)\n",
      "(247, 189, 3)\n",
      "(222, 162, 3)\n",
      "(205, 159, 3)\n",
      "(265, 175, 3)\n",
      "(175, 126, 3)\n",
      "(260, 180, 3)\n",
      "(275, 205, 3)\n",
      "(210, 153, 3)\n",
      "(316, 239, 3)\n",
      "(230, 184, 3)\n",
      "(202, 155, 3)\n",
      "(237, 166, 3)\n",
      "(450, 313, 3)\n",
      "(278, 196, 3)\n",
      "(231, 169, 3)\n",
      "(243, 184, 3)\n",
      "(369, 267, 3)\n",
      "(226, 180, 3)\n",
      "(240, 177, 3)\n",
      "(224, 169, 3)\n",
      "(219, 163, 3)\n",
      "(229, 174, 3)\n",
      "(191, 142, 3)\n",
      "(315, 230, 3)\n",
      "(314, 215, 3)\n",
      "(369, 264, 3)\n",
      "(293, 212, 3)\n",
      "(219, 181, 3)\n",
      "(210, 153, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 162, 3)\n",
      "(377, 266, 3)\n",
      "(217, 148, 3)\n",
      "(265, 189, 3)\n",
      "(252, 189, 3)\n",
      "(114, 89, 3)\n",
      "(306, 209, 3)\n",
      "(222, 154, 3)\n",
      "(219, 166, 3)\n",
      "(148, 110, 3)\n",
      "(187, 134, 3)\n",
      "(243, 177, 3)\n",
      "(244, 175, 3)\n",
      "(254, 182, 3)\n",
      "(244, 194, 3)\n",
      "(324, 253, 3)\n",
      "(250, 184, 3)\n",
      "(149, 110, 3)\n",
      "(300, 246, 3)\n",
      "(252, 184, 3)\n",
      "(240, 177, 3)\n",
      "(251, 167, 3)\n",
      "(232, 169, 3)\n",
      "(338, 250, 3)\n",
      "(176, 134, 3)\n",
      "(226, 162, 3)\n",
      "(233, 163, 3)\n",
      "(127, 93, 3)\n",
      "(204, 163, 3)\n",
      "(222, 163, 3)\n",
      "(141, 104, 3)\n",
      "(236, 170, 3)\n",
      "(245, 173, 3)\n",
      "(209, 145, 3)\n",
      "(226, 161, 3)\n",
      "(343, 252, 3)\n",
      "(215, 167, 3)\n",
      "(322, 231, 3)\n",
      "(245, 166, 3)\n",
      "(246, 166, 3)\n",
      "(233, 174, 3)\n",
      "(229, 174, 3)\n",
      "(237, 167, 3)\n",
      "(253, 190, 3)\n",
      "(279, 202, 3)\n",
      "(341, 253, 3)\n",
      "(177, 133, 3)\n",
      "(271, 196, 3)\n",
      "(236, 168, 3)\n",
      "(285, 203, 3)\n",
      "(289, 212, 3)\n",
      "(321, 237, 3)\n",
      "(177, 149, 3)\n",
      "(296, 224, 3)\n",
      "(254, 175, 3)\n",
      "(218, 166, 3)\n",
      "(352, 246, 3)\n",
      "(246, 184, 3)\n",
      "(202, 142, 3)\n",
      "(334, 267, 3)\n",
      "(183, 156, 3)\n",
      "(245, 168, 3)\n",
      "(216, 163, 3)\n",
      "(243, 177, 3)\n",
      "(308, 211, 3)\n",
      "(282, 202, 3)\n",
      "(240, 174, 3)\n",
      "(449, 314, 3)\n",
      "(342, 253, 3)\n",
      "(384, 303, 3)\n",
      "(152, 113, 3)\n",
      "(308, 223, 3)\n",
      "(167, 125, 3)\n",
      "(257, 183, 3)\n",
      "(224, 166, 3)\n",
      "(160, 114, 3)\n",
      "(175, 142, 3)\n",
      "(289, 209, 3)\n",
      "(204, 153, 3)\n",
      "(232, 161, 3)\n",
      "(286, 205, 3)\n",
      "(258, 204, 3)\n",
      "(224, 167, 3)\n",
      "(237, 180, 3)\n",
      "(238, 175, 3)\n",
      "(153, 110, 3)\n",
      "(203, 140, 3)\n",
      "(266, 211, 3)\n",
      "(212, 152, 3)\n",
      "(168, 121, 3)\n",
      "(198, 154, 3)\n",
      "(231, 180, 3)\n",
      "(187, 128, 3)\n",
      "(211, 147, 3)\n",
      "(272, 202, 3)\n",
      "(231, 159, 3)\n",
      "(247, 177, 3)\n",
      "(226, 166, 3)\n",
      "(233, 169, 3)\n",
      "(224, 174, 3)\n",
      "(211, 159, 3)\n",
      "(229, 166, 3)\n",
      "(223, 169, 3)\n",
      "(245, 170, 3)\n",
      "(210, 162, 3)\n",
      "(201, 155, 3)\n",
      "(202, 146, 3)\n",
      "(215, 170, 3)\n",
      "(261, 194, 3)\n",
      "(219, 163, 3)\n",
      "(209, 146, 3)\n",
      "(254, 180, 3)\n",
      "(432, 348, 3)\n",
      "(195, 142, 3)\n",
      "(222, 163, 3)\n",
      "(245, 181, 3)\n",
      "(183, 132, 3)\n",
      "(320, 244, 3)\n",
      "(190, 138, 3)\n",
      "(268, 195, 3)\n",
      "(292, 203, 3)\n",
      "(251, 181, 3)\n",
      "(239, 181, 3)\n",
      "(141, 99, 3)\n",
      "(204, 147, 3)\n",
      "(189, 145, 3)\n",
      "(254, 173, 3)\n",
      "(246, 180, 3)\n",
      "(251, 177, 3)\n",
      "(320, 208, 3)\n",
      "(303, 245, 3)\n",
      "(387, 289, 3)\n",
      "(211, 156, 3)\n",
      "(323, 232, 3)\n",
      "(251, 198, 3)\n",
      "(377, 289, 3)\n",
      "(237, 173, 3)\n",
      "(226, 166, 3)\n",
      "(182, 142, 3)\n",
      "(219, 162, 3)\n",
      "(261, 184, 3)\n",
      "(320, 239, 3)\n",
      "(233, 170, 3)\n",
      "(222, 166, 3)\n",
      "(315, 224, 3)\n",
      "(243, 180, 3)\n",
      "(225, 163, 3)\n",
      "(286, 205, 3)\n",
      "(201, 138, 3)\n",
      "(219, 166, 3)\n",
      "(215, 161, 3)\n",
      "(230, 170, 3)\n",
      "(240, 180, 3)\n",
      "(258, 208, 3)\n",
      "(334, 225, 3)\n",
      "(153, 107, 3)\n",
      "(267, 209, 3)\n",
      "(258, 180, 3)\n",
      "(250, 170, 3)\n",
      "(175, 134, 3)\n",
      "(260, 177, 3)\n",
      "(152, 110, 3)\n",
      "(365, 260, 3)\n",
      "(233, 168, 3)\n",
      "(223, 176, 3)\n",
      "(187, 142, 3)\n",
      "(203, 148, 3)\n",
      "(254, 188, 3)\n",
      "(334, 247, 3)\n",
      "(230, 167, 3)\n",
      "(268, 202, 3)\n",
      "(196, 141, 3)\n",
      "(247, 176, 3)\n",
      "(187, 135, 3)\n",
      "(244, 181, 3)\n",
      "(379, 261, 3)\n",
      "(180, 135, 3)\n",
      "(266, 194, 3)\n",
      "(258, 191, 3)\n",
      "(216, 154, 3)\n",
      "(226, 167, 3)\n",
      "(208, 162, 3)\n",
      "(306, 243, 3)\n",
      "(218, 162, 3)\n",
      "(237, 175, 3)\n",
      "(219, 153, 3)\n",
      "(314, 215, 3)\n",
      "(308, 229, 3)\n",
      "(203, 149, 3)\n",
      "(251, 194, 3)\n",
      "(204, 148, 3)\n",
      "(422, 303, 3)\n",
      "(189, 141, 3)\n",
      "(30, 23, 3)\n",
      "(280, 204, 3)\n",
      "(295, 208, 3)\n",
      "(257, 198, 3)\n",
      "(195, 149, 3)\n",
      "(260, 176, 3)\n",
      "(166, 119, 3)\n",
      "(251, 175, 3)\n",
      "(324, 246, 3)\n",
      "(225, 166, 3)\n",
      "(240, 177, 3)\n",
      "(230, 163, 3)\n",
      "(252, 177, 3)\n",
      "(251, 182, 3)\n",
      "(233, 176, 3)\n",
      "(198, 145, 3)\n",
      "(343, 244, 3)\n",
      "(217, 162, 3)\n",
      "(182, 132, 3)\n",
      "(258, 189, 3)\n",
      "(239, 170, 3)\n",
      "(236, 177, 3)\n",
      "(231, 168, 3)\n",
      "(292, 205, 3)\n",
      "(238, 168, 3)\n",
      "(156, 126, 3)\n",
      "(253, 183, 3)\n",
      "(201, 149, 3)\n",
      "(174, 118, 3)\n",
      "(257, 187, 3)\n",
      "(198, 149, 3)\n",
      "(156, 120, 3)\n",
      "(328, 229, 3)\n",
      "(209, 153, 3)\n",
      "(254, 187, 3)\n",
      "(240, 176, 3)\n",
      "(355, 236, 3)\n",
      "(212, 148, 3)\n",
      "(258, 196, 3)\n",
      "(287, 229, 3)\n",
      "(121, 98, 3)\n",
      "(301, 205, 3)\n",
      "(156, 120, 3)\n",
      "(168, 138, 3)\n",
      "(224, 154, 3)\n",
      "(175, 119, 3)\n",
      "(417, 302, 3)\n",
      "(149, 117, 3)\n",
      "(224, 162, 3)\n",
      "(250, 175, 3)\n",
      "(245, 163, 3)\n",
      "(321, 238, 3)\n",
      "(307, 219, 3)\n",
      "(232, 173, 3)\n",
      "(323, 219, 3)\n",
      "(201, 176, 3)\n",
      "(327, 250, 3)\n",
      "(365, 254, 3)\n",
      "(279, 191, 3)\n",
      "(223, 166, 3)\n",
      "(358, 258, 3)\n",
      "(194, 154, 3)\n",
      "(62, 65, 3)\n",
      "(181, 142, 3)\n",
      "(384, 268, 3)\n",
      "(219, 167, 3)\n",
      "(224, 169, 3)\n",
      "(265, 180, 3)\n",
      "(253, 174, 3)\n",
      "(233, 167, 3)\n",
      "(303, 212, 3)\n",
      "(133, 100, 3)\n",
      "(203, 142, 3)\n",
      "(169, 134, 3)\n",
      "(243, 162, 3)\n",
      "(400, 301, 3)\n",
      "(208, 153, 3)\n",
      "(229, 166, 3)\n",
      "(320, 225, 3)\n",
      "(148, 117, 3)\n",
      "(189, 125, 3)\n",
      "(252, 174, 3)\n",
      "(203, 154, 3)\n",
      "(202, 147, 3)\n",
      "(336, 252, 3)\n",
      "(196, 140, 3)\n",
      "(203, 147, 3)\n",
      "(253, 181, 3)\n",
      "(243, 176, 3)\n",
      "(264, 198, 3)\n",
      "(146, 112, 3)\n",
      "(230, 169, 3)\n",
      "(83, 64, 3)\n",
      "(292, 222, 3)\n",
      "(224, 160, 3)\n",
      "(231, 154, 3)\n",
      "(203, 142, 3)\n",
      "(229, 168, 3)\n",
      "(253, 204, 3)\n",
      "(289, 225, 3)\n",
      "(211, 154, 3)\n",
      "(176, 128, 3)\n",
      "(197, 135, 3)\n",
      "(233, 167, 3)\n",
      "(250, 181, 3)\n",
      "(208, 159, 3)\n",
      "(314, 230, 3)\n",
      "(331, 231, 3)\n",
      "(230, 156, 3)\n",
      "(253, 182, 3)\n",
      "(212, 163, 3)\n",
      "(142, 100, 3)\n",
      "(243, 181, 3)\n",
      "(313, 239, 3)\n",
      "(209, 159, 3)\n",
      "(203, 152, 3)\n",
      "(218, 170, 3)\n",
      "(237, 170, 3)\n",
      "(244, 181, 3)\n",
      "(285, 209, 3)\n",
      "(278, 191, 3)\n",
      "(188, 133, 3)\n",
      "(339, 254, 3)\n",
      "(371, 271, 3)\n",
      "(191, 140, 3)\n",
      "(327, 246, 3)\n",
      "(215, 156, 3)\n",
      "(202, 140, 3)\n",
      "(219, 152, 3)\n",
      "(338, 247, 3)\n",
      "(322, 239, 3)\n",
      "(309, 230, 3)\n",
      "(275, 211, 3)\n",
      "(217, 149, 3)\n",
      "(134, 96, 3)\n",
      "(254, 187, 3)\n",
      "(219, 162, 3)\n",
      "(365, 264, 3)\n",
      "(230, 161, 3)\n",
      "(246, 177, 3)\n",
      "(259, 201, 3)\n",
      "(198, 145, 3)\n",
      "(163, 132, 3)\n",
      "(292, 215, 3)\n",
      "(317, 225, 3)\n",
      "(163, 121, 3)\n",
      "(156, 125, 3)\n",
      "(155, 111, 3)\n",
      "(239, 166, 3)\n",
      "(223, 160, 3)\n",
      "(245, 196, 3)\n",
      "(309, 230, 3)\n",
      "(316, 237, 3)\n",
      "(357, 267, 3)\n",
      "(279, 205, 3)\n",
      "(224, 180, 3)\n",
      "(350, 253, 3)\n",
      "(222, 148, 3)\n",
      "(306, 245, 3)\n",
      "(292, 226, 3)\n",
      "(217, 170, 3)\n",
      "(181, 138, 3)\n",
      "(408, 288, 3)\n",
      "(437, 315, 3)\n",
      "(244, 177, 3)\n",
      "(280, 215, 3)\n",
      "(187, 131, 3)\n",
      "(201, 146, 3)\n",
      "(233, 188, 3)\n",
      "(330, 246, 3)\n",
      "(185, 141, 3)\n",
      "(204, 162, 3)\n",
      "(450, 315, 3)\n",
      "(261, 184, 3)\n",
      "(285, 223, 3)\n",
      "(260, 218, 3)\n",
      "(337, 245, 3)\n",
      "(266, 201, 3)\n",
      "(212, 147, 3)\n",
      "(380, 275, 3)\n",
      "(191, 149, 3)\n",
      "(142, 107, 3)\n",
      "(208, 169, 3)\n",
      "(317, 247, 3)\n",
      "(239, 168, 3)\n",
      "(440, 314, 3)\n",
      "(133, 96, 3)\n",
      "(229, 163, 3)\n",
      "(250, 189, 3)\n",
      "(289, 216, 3)\n",
      "(247, 182, 3)\n",
      "(149, 107, 3)\n",
      "(188, 142, 3)\n",
      "(288, 218, 3)\n",
      "(271, 182, 3)\n",
      "(161, 124, 3)\n",
      "(455, 343, 3)\n",
      "(202, 153, 3)\n",
      "(448, 316, 3)\n",
      "(337, 238, 3)\n",
      "(188, 133, 3)\n",
      "(253, 174, 3)\n",
      "(247, 169, 3)\n",
      "(239, 182, 3)\n",
      "(189, 139, 3)\n",
      "(316, 226, 3)\n",
      "(436, 307, 3)\n",
      "(152, 113, 3)\n",
      "(194, 119, 3)\n",
      "(238, 169, 3)\n",
      "(219, 167, 3)\n",
      "(349, 250, 3)\n",
      "(257, 180, 3)\n",
      "(226, 173, 3)\n",
      "(261, 175, 3)\n",
      "(303, 237, 3)\n",
      "(190, 145, 3)\n",
      "(464, 315, 3)\n",
      "(195, 152, 3)\n",
      "(247, 184, 3)\n",
      "(250, 182, 3)\n",
      "(201, 153, 3)\n",
      "(159, 119, 3)\n",
      "(198, 140, 3)\n",
      "(254, 181, 3)\n",
      "(376, 251, 3)\n",
      "(204, 149, 3)\n",
      "(208, 148, 3)\n",
      "(272, 205, 3)\n",
      "(222, 166, 3)\n",
      "(210, 153, 3)\n",
      "(194, 147, 3)\n",
      "(310, 243, 3)\n",
      "(225, 167, 3)\n",
      "(203, 145, 3)\n",
      "(273, 188, 3)\n",
      "(231, 177, 3)\n",
      "(264, 203, 3)\n",
      "(237, 175, 3)\n",
      "(247, 170, 3)\n",
      "(338, 240, 3)\n",
      "(272, 197, 3)\n",
      "(229, 162, 3)\n",
      "(238, 175, 3)\n",
      "(238, 194, 3)\n",
      "(163, 125, 3)\n",
      "(239, 173, 3)\n",
      "(182, 147, 3)\n",
      "(267, 195, 3)\n",
      "(183, 145, 3)\n",
      "(272, 197, 3)\n",
      "(223, 167, 3)\n",
      "(208, 148, 3)\n",
      "(154, 110, 3)\n",
      "(245, 177, 3)\n",
      "(198, 138, 3)\n",
      "(349, 252, 3)\n",
      "(272, 201, 3)\n",
      "(215, 159, 3)\n",
      "(411, 335, 3)\n",
      "(222, 168, 3)\n",
      "(240, 184, 3)\n",
      "(149, 100, 3)\n",
      "(168, 119, 3)\n",
      "(63, 64, 3)\n",
      "(233, 181, 3)\n",
      "(218, 154, 3)\n",
      "(240, 173, 3)\n",
      "(224, 160, 3)\n",
      "(197, 132, 3)\n",
      "(159, 119, 3)\n",
      "(271, 210, 3)\n",
      "(272, 184, 3)\n",
      "(310, 230, 3)\n",
      "(197, 147, 3)\n",
      "(236, 175, 3)\n",
      "(275, 184, 3)\n",
      "(156, 119, 3)\n",
      "(189, 131, 3)\n",
      "(232, 173, 3)\n",
      "(173, 120, 3)\n",
      "(162, 126, 3)\n",
      "(250, 177, 3)\n",
      "(224, 175, 3)\n",
      "(238, 182, 3)\n",
      "(233, 174, 3)\n",
      "(233, 173, 3)\n",
      "(285, 217, 3)\n",
      "(352, 266, 3)\n",
      "(246, 188, 3)\n",
      "(243, 175, 3)\n",
      "(224, 167, 3)\n",
      "(240, 189, 3)\n",
      "(310, 240, 3)\n",
      "(250, 180, 3)\n",
      "(237, 187, 3)\n",
      "(250, 180, 3)\n",
      "(275, 209, 3)\n",
      "(247, 170, 3)\n",
      "(252, 187, 3)\n",
      "(202, 145, 3)\n",
      "(309, 238, 3)\n",
      "(208, 145, 3)\n",
      "(190, 135, 3)\n",
      "(226, 169, 3)\n",
      "(231, 182, 3)\n",
      "(182, 149, 3)\n",
      "(232, 174, 3)\n",
      "(251, 194, 3)\n",
      "(209, 142, 3)\n",
      "(308, 219, 3)\n",
      "(226, 167, 3)\n",
      "(191, 154, 3)\n",
      "(232, 175, 3)\n",
      "(260, 183, 3)\n",
      "(320, 252, 3)\n",
      "(265, 195, 3)\n",
      "(160, 121, 3)\n",
      "(292, 218, 3)\n",
      "(464, 350, 3)\n",
      "(182, 139, 3)\n",
      "(160, 118, 3)\n",
      "(211, 148, 3)\n",
      "(344, 254, 3)\n",
      "(293, 210, 3)\n",
      "(209, 167, 3)\n",
      "(216, 159, 3)\n",
      "(203, 145, 3)\n",
      "(229, 167, 3)\n",
      "(302, 238, 3)\n",
      "(190, 140, 3)\n",
      "(314, 230, 3)\n",
      "(293, 224, 3)\n",
      "(288, 224, 3)\n",
      "(264, 187, 3)\n",
      "(180, 140, 3)\n",
      "(363, 252, 3)\n",
      "(314, 244, 3)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-abd2f86c01aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in lis:\n",
    "    img = cv2.imread(i)\n",
    "    print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31855, 17508]\n",
      "[1.5496154449850887, 2.819453963902216]\n"
     ]
    }
   ],
   "source": [
    "# https://discuss.pytorch.org/t/balanced-sampling-between-classes-with-torchvision-dataloader/2703/3\n",
    "def make_weights_for_balanced_classes(images, nclasses):                        \n",
    "    count = [0] * nclasses                                                      \n",
    "    for item in images:                                                         \n",
    "        count[item[1]] += 1                                                     \n",
    "    weight_per_class = [0.] * nclasses                                      \n",
    "    N = float(sum(count))  \n",
    "    print(count)\n",
    "    for i in range(nclasses):                                                   \n",
    "        weight_per_class[i] = N/float(count[i])   \n",
    "    print(weight_per_class)\n",
    "    weight = [0] * len(images)                                              \n",
    "    for idx, val in enumerate(images):                                          \n",
    "        weight[idx] = weight_per_class[val[1]]                                  \n",
    "    return weight   \n",
    "weights = make_weights_for_balanced_classes(train_data.imgs, len(train_data.classes))                                                                \n",
    "weights = torch.DoubleTensor(weights)                                       \n",
    "sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5496, 1.5496, 1.5496,  ..., 2.8195, 2.8195, 2.8195],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=16,                             \n",
    "                    sampler = sampler, num_workers=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/tampm/miniconda3/envs/face/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/tampm/miniconda3/envs/face/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/tampm/miniconda3/envs/face/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/tampm/miniconda3/envs/face/lib/python3.7/site-packages/torchvision/datasets/folder.py\", line 140, in __getitem__\n    sample = self.transform(sample)\n  File \"/home/tampm/miniconda3/envs/face/lib/python3.7/site-packages/torchvision/transforms/transforms.py\", line 70, in __call__\n    img = t(img)\n  File \"/home/tampm/miniconda3/envs/face/lib/python3.7/site-packages/torchvision/transforms/transforms.py\", line 207, in __call__\n    return F.resize(img, self.size, self.interpolation)\n  File \"/home/tampm/miniconda3/envs/face/lib/python3.7/site-packages/torchvision/transforms/functional.py\", line 250, in resize\n    return img.resize((ow, oh), interpolation)\n  File \"/home/tampm/miniconda3/envs/face/lib/python3.7/site-packages/PIL/Image.py\", line 1834, in resize\n    message + \" Use \" + \", \".join(filters[:-1]) + \" or \" + filters[-1]\nValueError: Unknown resampling filter (256). Use Image.NEAREST (0), Image.LANCZOS (1), Image.BILINEAR (2), Image.BICUBIC (3), Image.BOX (4) or Image.HAMMING (5)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-503423b283c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/face/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/face/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/face/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/face/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/tampm/miniconda3/envs/face/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/tampm/miniconda3/envs/face/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/tampm/miniconda3/envs/face/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/tampm/miniconda3/envs/face/lib/python3.7/site-packages/torchvision/datasets/folder.py\", line 140, in __getitem__\n    sample = self.transform(sample)\n  File \"/home/tampm/miniconda3/envs/face/lib/python3.7/site-packages/torchvision/transforms/transforms.py\", line 70, in __call__\n    img = t(img)\n  File \"/home/tampm/miniconda3/envs/face/lib/python3.7/site-packages/torchvision/transforms/transforms.py\", line 207, in __call__\n    return F.resize(img, self.size, self.interpolation)\n  File \"/home/tampm/miniconda3/envs/face/lib/python3.7/site-packages/torchvision/transforms/functional.py\", line 250, in resize\n    return img.resize((ow, oh), interpolation)\n  File \"/home/tampm/miniconda3/envs/face/lib/python3.7/site-packages/PIL/Image.py\", line 1834, in resize\n    message + \" Use \" + \", \".join(filters[:-1]) + \" or \" + filters[-1]\nValueError: Unknown resampling filter (256). Use Image.NEAREST (0), Image.LANCZOS (1), Image.BILINEAR (2), Image.BICUBIC (3), Image.BOX (4) or Image.HAMMING (5)\n"
     ]
    }
   ],
   "source": [
    "iter(trainloader).next()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.ImageFolder('/data/tam/kaggle/extract_raw_img_test',       \n",
    "                    transform=train_transforms)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=16,num_workers=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 256, 256])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter(testloader).next()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss().cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() \n",
    "                                  else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/39873 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 1/39873 [00:00<3:13:03,  3.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 2/39873 [00:00<2:40:48,  4.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 3/39873 [00:00<2:17:02,  4.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 4/39873 [00:00<2:00:13,  5.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 6/39873 [00:00<1:40:59,  6.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 7/39873 [00:00<1:31:51,  7.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 8/39873 [00:01<1:31:16,  7.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 9/39873 [00:01<2:13:20,  4.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 10/39873 [00:01<2:03:16,  5.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 12/39873 [00:01<1:49:19,  6.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 14/39873 [00:02<1:38:22,  6.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 15/39873 [00:02<1:37:11,  6.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 16/39873 [00:02<1:30:39,  7.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 17/39873 [00:02<1:27:16,  7.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 18/39873 [00:02<1:26:08,  7.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 20/39873 [00:02<1:19:50,  8.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 21/39873 [00:02<1:26:49,  7.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 22/39873 [00:02<1:21:24,  8.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 23/39873 [00:03<1:23:44,  7.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 24/39873 [00:03<1:19:16,  8.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 25/39873 [00:03<1:20:52,  8.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 26/39873 [00:03<1:21:11,  8.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 28/39873 [00:03<1:15:35,  8.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 30/39873 [00:03<1:09:05,  9.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 31/39873 [00:03<1:12:58,  9.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 32/39873 [00:04<1:15:51,  8.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 34/39873 [00:04<1:12:24,  9.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 35/39873 [00:04<1:10:53,  9.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 36/39873 [00:04<1:10:22,  9.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 37/39873 [00:04<1:13:50,  8.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 38/39873 [00:04<1:13:39,  9.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 39/39873 [00:04<1:17:18,  8.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 40/39873 [00:04<1:15:14,  8.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 41/39873 [00:05<1:14:00,  8.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 42/39873 [00:05<1:18:25,  8.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 43/39873 [00:05<1:20:15,  8.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 44/39873 [00:05<1:20:03,  8.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 45/39873 [00:05<1:17:44,  8.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 47/39873 [00:05<1:14:28,  8.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 49/39873 [00:05<1:09:07,  9.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 51/39873 [00:06<1:10:20,  9.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 52/39873 [00:06<1:23:36,  7.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 54/39873 [00:06<1:21:51,  8.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 55/39873 [00:06<1:28:55,  7.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 57/39873 [00:06<1:19:02,  8.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 58/39873 [00:06<1:16:59,  8.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 60/39873 [00:07<1:14:13,  8.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 61/39873 [00:07<1:15:58,  8.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 63/39873 [00:07<1:14:39,  8.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 65/39873 [00:07<1:10:31,  9.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 67/39873 [00:07<1:09:51,  9.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 68/39873 [00:08<1:11:22,  9.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 69/39873 [00:08<1:16:15,  8.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 70/39873 [00:08<1:18:04,  8.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 71/39873 [00:08<1:27:48,  7.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 73/39873 [00:08<1:22:07,  8.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 75/39873 [00:08<1:17:28,  8.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 76/39873 [00:08<1:22:23,  8.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 77/39873 [00:09<1:25:07,  7.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 78/39873 [00:09<1:23:20,  7.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 79/39873 [00:09<1:24:39,  7.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 80/39873 [00:09<1:23:00,  7.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 81/39873 [00:09<1:18:05,  8.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 82/39873 [00:09<1:15:21,  8.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 83/39873 [00:09<1:21:44,  8.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 85/39873 [00:10<1:15:58,  8.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 87/39873 [00:10<1:13:42,  9.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 88/39873 [00:10<1:14:37,  8.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 90/39873 [00:10<1:12:33,  9.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 92/39873 [00:10<1:08:28,  9.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 94/39873 [00:10<1:06:48,  9.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 96/39873 [00:11<1:07:30,  9.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 97/39873 [00:11<1:07:48,  9.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 98/39873 [00:11<1:10:02,  9.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 100/39873 [00:11<1:10:28,  9.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 101/39873 [00:11<2:00:08,  5.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 102/39873 [00:12<1:47:42,  6.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 104/39873 [00:12<1:34:17,  7.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 106/39873 [00:12<1:17:46,  8.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 108/39873 [00:12<1:18:56,  8.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 110/39873 [00:12<1:22:46,  8.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 112/39873 [00:13<1:14:36,  8.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 114/39873 [00:13<1:12:01,  9.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 116/39873 [00:13<1:11:20,  9.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 117/39873 [00:13<1:14:33,  8.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 118/39873 [00:13<1:13:58,  8.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 119/39873 [00:13<1:15:55,  8.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 121/39873 [00:13<1:08:21,  9.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 123/39873 [00:14<1:09:27,  9.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 125/39873 [00:14<1:09:46,  9.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 126/39873 [00:14<1:09:39,  9.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 127/39873 [00:14<1:20:15,  8.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 128/39873 [00:14<1:16:41,  8.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 130/39873 [00:14<1:16:44,  8.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 131/39873 [00:15<1:18:27,  8.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 132/39873 [00:15<1:15:09,  8.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 134/39873 [00:15<1:08:58,  9.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 135/39873 [00:15<1:15:05,  8.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 137/39873 [00:15<1:13:30,  9.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 139/39873 [00:15<1:12:54,  9.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 141/39873 [00:16<1:09:37,  9.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 142/39873 [00:16<1:14:28,  8.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 143/39873 [00:16<1:16:18,  8.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 145/39873 [00:16<1:10:58,  9.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 147/39873 [00:16<1:12:48,  9.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 148/39873 [00:16<1:11:26,  9.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 149/39873 [00:17<1:14:56,  8.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 150/39873 [00:17<1:15:16,  8.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 152/39873 [00:17<1:10:34,  9.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 154/39873 [00:17<1:10:17,  9.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 155/39873 [00:17<1:21:59,  8.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 156/39873 [00:17<1:17:44,  8.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 158/39873 [00:17<1:12:57,  9.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 159/39873 [00:18<1:12:23,  9.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 161/39873 [00:18<1:08:39,  9.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 163/39873 [00:18<1:08:51,  9.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 164/39873 [00:18<1:14:38,  8.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 165/39873 [00:18<1:18:27,  8.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 167/39873 [00:18<1:12:49,  9.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 168/39873 [00:19<1:16:56,  8.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 170/39873 [00:19<1:12:26,  9.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 172/39873 [00:19<1:09:20,  9.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 174/39873 [00:19<1:06:12,  9.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 176/39873 [00:19<1:04:39, 10.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 178/39873 [00:20<1:07:23,  9.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 180/39873 [00:20<1:10:15,  9.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 181/39873 [00:20<1:09:49,  9.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 182/39873 [00:20<1:25:38,  7.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 184/39873 [00:20<1:20:46,  8.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 185/39873 [00:20<1:20:53,  8.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 186/39873 [00:20<1:20:00,  8.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 187/39873 [00:21<1:21:32,  8.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 188/39873 [00:21<1:20:15,  8.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 190/39873 [00:21<1:12:20,  9.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 192/39873 [00:21<1:05:06, 10.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 194/39873 [00:21<1:04:14, 10.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 196/39873 [00:21<1:02:05, 10.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 198/39873 [00:22<1:30:14,  7.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 199/39873 [00:22<1:33:14,  7.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 200/39873 [00:22<1:29:45,  7.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 201/39873 [00:22<1:26:35,  7.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 202/39873 [00:22<1:27:05,  7.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 204/39873 [00:23<1:20:27,  8.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 205/39873 [00:23<1:24:15,  7.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 206/39873 [00:23<1:20:55,  8.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 207/39873 [00:23<1:18:14,  8.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 208/39873 [00:23<1:16:20,  8.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 210/39873 [00:23<1:11:23,  9.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 212/39873 [00:23<1:07:22,  9.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 214/39873 [00:24<1:06:45,  9.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 216/39873 [00:24<1:09:33,  9.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 218/39873 [00:24<1:06:52,  9.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 220/39873 [00:24<1:04:30, 10.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 222/39873 [00:24<1:06:03, 10.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 224/39873 [00:25<1:10:15,  9.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 225/39873 [00:25<1:10:36,  9.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 226/39873 [00:25<1:14:46,  8.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 228/39873 [00:25<1:09:41,  9.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 230/39873 [00:25<1:04:09, 10.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 232/39873 [00:25<1:08:39,  9.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 233/39873 [00:26<1:09:40,  9.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 234/39873 [00:26<1:08:53,  9.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 236/39873 [00:26<1:09:49,  9.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 238/39873 [00:26<1:06:48,  9.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 240/39873 [00:26<1:07:07,  9.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 242/39873 [00:26<1:05:04, 10.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 244/39873 [00:27<1:04:49, 10.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 246/39873 [00:27<1:04:59, 10.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 248/39873 [00:27<1:19:28,  8.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 249/39873 [00:27<1:18:24,  8.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 250/39873 [00:27<1:20:01,  8.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 251/39873 [00:28<1:15:54,  8.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 252/39873 [00:28<1:14:50,  8.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 254/39873 [00:28<1:08:46,  9.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 255/39873 [00:28<1:14:51,  8.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 257/39873 [00:28<1:10:20,  9.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 258/39873 [00:28<1:10:05,  9.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 260/39873 [00:28<1:07:38,  9.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 262/39873 [00:29<1:11:08,  9.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 263/39873 [00:29<1:21:40,  8.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 265/39873 [00:29<1:16:41,  8.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 266/39873 [00:29<1:16:33,  8.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 268/39873 [00:29<1:13:07,  9.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 269/39873 [00:29<1:12:06,  9.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 270/39873 [00:30<1:12:19,  9.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 271/39873 [00:30<1:13:11,  9.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 272/39873 [00:30<1:13:33,  8.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 274/39873 [00:30<1:13:29,  8.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 276/39873 [00:30<1:05:57, 10.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 278/39873 [00:30<1:09:12,  9.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 279/39873 [00:31<1:22:05,  8.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 280/39873 [00:31<1:26:03,  7.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 281/39873 [00:31<1:20:37,  8.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 283/39873 [00:31<1:14:21,  8.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 285/39873 [00:31<1:11:23,  9.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 286/39873 [00:31<1:11:14,  9.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 287/39873 [00:31<1:16:10,  8.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 289/39873 [00:32<1:16:05,  8.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 290/39873 [00:32<1:17:43,  8.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 292/39873 [00:32<1:13:28,  8.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 293/39873 [00:32<1:36:29,  6.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 294/39873 [00:32<1:41:02,  6.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 295/39873 [00:32<1:31:11,  7.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 296/39873 [00:33<1:27:13,  7.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 297/39873 [00:33<1:21:11,  8.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 298/39873 [00:33<1:24:35,  7.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 299/39873 [00:33<1:21:19,  8.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 300/39873 [00:33<1:29:22,  7.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 302/39873 [00:33<1:23:08,  7.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 303/39873 [00:33<1:22:19,  8.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 304/39873 [00:34<1:21:08,  8.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 305/39873 [00:34<1:16:39,  8.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 306/39873 [00:34<1:14:16,  8.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 307/39873 [00:34<1:17:59,  8.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 308/39873 [00:34<1:16:03,  8.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 310/39873 [00:34<1:11:25,  9.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 312/39873 [00:34<1:09:17,  9.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 314/39873 [00:35<1:07:56,  9.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 315/39873 [00:35<1:12:56,  9.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 316/39873 [00:35<1:11:06,  9.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 318/39873 [00:35<1:07:18,  9.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 320/39873 [00:35<1:03:44, 10.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 322/39873 [00:35<1:03:02, 10.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 324/39873 [00:36<1:04:10, 10.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 326/39873 [00:36<1:04:11, 10.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 328/39873 [00:36<1:07:45,  9.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 330/39873 [00:36<1:05:35, 10.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 332/39873 [00:36<1:05:05, 10.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 334/39873 [00:37<1:02:59, 10.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 336/39873 [00:37<1:06:15,  9.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 338/39873 [00:37<1:06:57,  9.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 339/39873 [00:37<1:07:07,  9.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 340/39873 [00:37<1:10:18,  9.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 342/39873 [00:37<1:08:05,  9.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 344/39873 [00:38<1:06:00,  9.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 346/39873 [00:38<1:05:52, 10.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 348/39873 [00:38<1:05:19, 10.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 350/39873 [00:38<1:05:27, 10.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 352/39873 [00:38<1:06:26,  9.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 353/39873 [00:38<1:06:52,  9.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 355/39873 [00:39<1:07:39,  9.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 357/39873 [00:39<1:03:51, 10.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 359/39873 [00:39<1:07:07,  9.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 360/39873 [00:39<1:11:09,  9.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 361/39873 [00:39<1:14:58,  8.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 363/39873 [00:40<1:13:56,  8.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 364/39873 [00:40<1:22:15,  8.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 366/39873 [00:40<1:17:01,  8.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 367/39873 [00:40<1:17:40,  8.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 369/39873 [00:40<1:12:10,  9.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 370/39873 [00:40<1:13:55,  8.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 372/39873 [00:40<1:10:50,  9.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 373/39873 [00:41<1:11:35,  9.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 374/39873 [00:41<1:17:47,  8.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 375/39873 [00:41<1:15:55,  8.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 376/39873 [00:41<1:13:03,  9.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 378/39873 [00:41<1:11:30,  9.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 379/39873 [00:41<1:14:19,  8.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 380/39873 [00:41<1:12:59,  9.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 382/39873 [00:42<1:15:52,  8.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 383/39873 [00:42<1:24:22,  7.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 384/39873 [00:42<1:20:49,  8.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 386/39873 [00:42<1:13:09,  9.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 387/39873 [00:42<1:15:47,  8.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 388/39873 [00:42<1:13:29,  8.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 389/39873 [00:42<1:12:53,  9.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 391/39873 [00:43<1:19:08,  8.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 393/39873 [00:43<1:16:07,  8.64it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 395/39873 [00:43<1:14:54,  8.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 396/39873 [00:43<1:18:00,  8.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 398/39873 [00:43<1:09:59,  9.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 399/39873 [00:44<1:10:55,  9.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 400/39873 [00:44<1:16:25,  8.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 402/39873 [00:44<1:12:39,  9.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 404/39873 [00:44<1:07:28,  9.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 406/39873 [00:44<1:02:42, 10.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 408/39873 [00:44<1:07:22,  9.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 410/39873 [00:45<1:02:48, 10.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 412/39873 [00:45<1:10:35,  9.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 413/39873 [00:45<1:11:09,  9.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 415/39873 [00:45<1:09:21,  9.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 416/39873 [00:45<1:11:07,  9.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 418/39873 [00:45<1:03:47, 10.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 420/39873 [00:46<1:06:35,  9.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 422/39873 [00:46<1:06:45,  9.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 424/39873 [00:46<1:06:03,  9.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 426/39873 [00:46<1:11:55,  9.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 428/39873 [00:46<1:07:06,  9.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 430/39873 [00:47<1:12:38,  9.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 432/39873 [00:47<1:11:24,  9.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 434/39873 [00:47<1:12:20,  9.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 436/39873 [00:47<1:05:05, 10.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 438/39873 [00:48<1:11:19,  9.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 440/39873 [00:48<1:14:23,  8.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 441/39873 [00:48<1:25:42,  7.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 442/39873 [00:48<1:27:26,  7.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 444/39873 [00:48<1:19:27,  8.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 446/39873 [00:48<1:10:26,  9.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 448/39873 [00:49<1:08:59,  9.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 450/39873 [00:49<1:06:26,  9.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 452/39873 [00:49<1:08:20,  9.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 453/39873 [00:49<1:11:30,  9.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 454/39873 [00:49<1:10:42,  9.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 456/39873 [00:50<1:11:49,  9.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 457/39873 [00:50<1:13:17,  8.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 459/39873 [00:50<1:07:58,  9.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 460/39873 [00:50<1:11:27,  9.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 461/39873 [00:50<1:10:48,  9.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 463/39873 [00:50<1:06:12,  9.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 465/39873 [00:50<1:03:01, 10.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 467/39873 [00:51<1:12:14,  9.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 468/39873 [00:51<1:11:48,  9.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 470/39873 [00:51<1:08:23,  9.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 472/39873 [00:51<1:06:27,  9.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 474/39873 [00:51<1:07:11,  9.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 475/39873 [00:51<1:09:26,  9.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 477/39873 [00:52<1:09:11,  9.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 478/39873 [00:52<1:09:13,  9.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 480/39873 [00:52<1:06:00,  9.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 482/39873 [00:52<1:05:06, 10.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 484/39873 [00:52<1:08:57,  9.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 486/39873 [00:53<1:07:59,  9.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 488/39873 [00:53<1:06:40,  9.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 489/39873 [00:53<1:31:51,  7.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 491/39873 [00:53<1:21:54,  8.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 492/39873 [00:53<1:17:50,  8.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 494/39873 [00:53<1:11:21,  9.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 496/39873 [00:54<1:06:40,  9.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 498/39873 [00:54<1:06:58,  9.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 500/39873 [00:54<1:03:56, 10.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 502/39873 [00:54<1:00:06, 10.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 504/39873 [00:54<1:00:06, 10.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 506/39873 [00:55<1:02:15, 10.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 508/39873 [00:55<1:01:56, 10.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 510/39873 [00:55<1:03:56, 10.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 512/39873 [00:55<1:00:21, 10.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 514/39873 [00:55<1:03:01, 10.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 516/39873 [00:55<1:00:25, 10.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 518/39873 [00:56<58:18, 11.25it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 520/39873 [00:56<59:01, 11.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 522/39873 [00:56<1:00:34, 10.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 524/39873 [00:56<1:00:15, 10.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 526/39873 [00:57<1:11:10,  9.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 528/39873 [00:57<1:05:31, 10.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 530/39873 [00:57<1:00:55, 10.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 532/39873 [00:57<1:04:46, 10.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 534/39873 [00:57<1:06:27,  9.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 536/39873 [00:57<1:09:31,  9.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 537/39873 [00:58<1:09:00,  9.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 538/39873 [00:58<1:12:47,  9.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 540/39873 [00:58<1:12:50,  9.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 541/39873 [00:58<1:12:04,  9.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 542/39873 [00:58<1:12:45,  9.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 543/39873 [00:58<1:41:15,  6.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 544/39873 [00:59<1:36:51,  6.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 545/39873 [00:59<1:28:52,  7.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 547/39873 [00:59<1:20:19,  8.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 549/39873 [00:59<1:15:57,  8.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 550/39873 [00:59<1:15:47,  8.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 551/39873 [00:59<1:22:28,  7.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 553/39873 [00:59<1:14:36,  8.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 554/39873 [01:00<1:14:14,  8.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 555/39873 [01:00<1:13:36,  8.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 557/39873 [01:00<1:07:27,  9.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 559/39873 [01:00<1:05:22, 10.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 561/39873 [01:00<1:03:13, 10.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 563/39873 [01:00<1:00:22, 10.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 565/39873 [01:01<1:02:41, 10.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 567/39873 [01:01<1:05:04, 10.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 569/39873 [01:01<1:03:09, 10.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 571/39873 [01:01<1:01:34, 10.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 573/39873 [01:01<1:02:18, 10.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 575/39873 [01:02<1:02:22, 10.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 577/39873 [01:02<1:03:09, 10.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 579/39873 [01:02<1:00:21, 10.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 581/39873 [01:02<59:59, 10.91it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 583/39873 [01:02<59:20, 11.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 585/39873 [01:02<1:00:30, 10.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 587/39873 [01:03<1:04:04, 10.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 589/39873 [01:03<1:07:42,  9.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 591/39873 [01:03<1:09:09,  9.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 593/39873 [01:03<1:18:18,  8.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 594/39873 [01:04<1:27:10,  7.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 595/39873 [01:04<1:29:21,  7.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 596/39873 [01:04<1:28:08,  7.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 597/39873 [01:04<1:36:51,  6.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|         | 598/39873 [01:04<1:30:04,  7.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 599/39873 [01:04<1:27:24,  7.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 600/39873 [01:04<1:21:33,  8.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 601/39873 [01:05<1:18:20,  8.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 603/39873 [01:05<1:10:50,  9.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 605/39873 [01:05<1:03:03, 10.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 607/39873 [01:05<1:05:32,  9.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 609/39873 [01:05<1:02:38, 10.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 611/39873 [01:05<1:07:10,  9.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 613/39873 [01:06<1:09:30,  9.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 614/39873 [01:06<1:10:03,  9.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 616/39873 [01:06<1:05:47,  9.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 618/39873 [01:06<1:08:53,  9.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 620/39873 [01:06<1:06:14,  9.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 622/39873 [01:07<1:04:36, 10.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 624/39873 [01:07<59:41, 10.96it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 626/39873 [01:07<59:03, 11.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 628/39873 [01:07<1:02:02, 10.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 630/39873 [01:07<1:03:01, 10.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 632/39873 [01:07<1:04:32, 10.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 634/39873 [01:08<1:02:56, 10.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 636/39873 [01:08<1:01:23, 10.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 638/39873 [01:08<1:01:22, 10.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 640/39873 [01:08<1:00:47, 10.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 642/39873 [01:08<59:19, 11.02it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 644/39873 [01:09<1:00:54, 10.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 646/39873 [01:09<1:06:31,  9.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 648/39873 [01:09<1:12:00,  9.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 649/39873 [01:09<1:17:19,  8.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 651/39873 [01:09<1:13:39,  8.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 652/39873 [01:10<1:12:38,  9.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 653/39873 [01:10<1:11:30,  9.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 655/39873 [01:10<1:11:27,  9.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 657/39873 [01:10<1:06:24,  9.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 659/39873 [01:10<1:08:11,  9.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 661/39873 [01:10<1:03:45, 10.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 663/39873 [01:11<1:06:06,  9.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 665/39873 [01:11<1:05:30,  9.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 667/39873 [01:11<1:05:49,  9.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 669/39873 [01:11<1:05:06, 10.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 671/39873 [01:11<1:10:11,  9.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 673/39873 [01:12<1:08:36,  9.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 674/39873 [01:12<1:13:53,  8.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 676/39873 [01:12<1:07:17,  9.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 678/39873 [01:12<1:06:22,  9.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 680/39873 [01:12<1:02:02, 10.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 682/39873 [01:13<1:03:58, 10.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 684/39873 [01:13<1:13:21,  8.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 685/39873 [01:13<1:12:34,  9.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 687/39873 [01:13<1:08:27,  9.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 689/39873 [01:13<1:04:44, 10.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 691/39873 [01:13<1:02:23, 10.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 693/39873 [01:14<1:08:24,  9.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 694/39873 [01:14<1:38:22,  6.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 695/39873 [01:14<1:46:28,  6.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 696/39873 [01:14<1:41:01,  6.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 697/39873 [01:14<1:33:50,  6.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 699/39873 [01:15<1:22:50,  7.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 700/39873 [01:15<1:22:37,  7.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 702/39873 [01:15<1:21:43,  7.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 703/39873 [01:15<1:20:44,  8.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 704/39873 [01:15<1:18:48,  8.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 706/39873 [01:15<1:10:29,  9.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 707/39873 [01:15<1:12:46,  8.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 708/39873 [01:16<1:11:22,  9.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 709/39873 [01:16<1:17:13,  8.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 711/39873 [01:16<1:12:18,  9.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 713/39873 [01:16<1:07:14,  9.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 715/39873 [01:16<1:06:35,  9.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 717/39873 [01:16<1:08:38,  9.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 719/39873 [01:17<1:07:43,  9.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 721/39873 [01:17<1:06:30,  9.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 723/39873 [01:17<1:05:15, 10.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 725/39873 [01:17<1:05:43,  9.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 727/39873 [01:18<1:08:31,  9.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 729/39873 [01:18<1:04:33, 10.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 731/39873 [01:18<1:04:11, 10.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 733/39873 [01:18<1:01:48, 10.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 735/39873 [01:18<1:05:22,  9.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 737/39873 [01:19<1:09:09,  9.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 739/39873 [01:19<1:05:06, 10.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 741/39873 [01:19<1:04:30, 10.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 743/39873 [01:19<1:11:21,  9.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 744/39873 [01:19<1:43:26,  6.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 745/39873 [01:20<1:37:51,  6.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 747/39873 [01:20<1:26:04,  7.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 748/39873 [01:20<1:24:08,  7.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 750/39873 [01:20<1:17:03,  8.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 752/39873 [01:20<1:12:49,  8.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 753/39873 [01:20<1:11:12,  9.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 755/39873 [01:21<1:06:18,  9.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 757/39873 [01:21<1:04:13, 10.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 759/39873 [01:21<1:05:07, 10.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 761/39873 [01:21<1:02:39, 10.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 763/39873 [01:21<1:02:42, 10.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 765/39873 [01:21<1:02:48, 10.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 767/39873 [01:22<58:17, 11.18it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 769/39873 [01:22<55:51, 11.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 771/39873 [01:22<1:01:45, 10.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 773/39873 [01:22<1:05:23,  9.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 775/39873 [01:22<1:09:18,  9.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 777/39873 [01:23<1:06:15,  9.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 779/39873 [01:23<1:02:42, 10.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 781/39873 [01:23<1:00:15, 10.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 783/39873 [01:23<1:05:47,  9.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 785/39873 [01:23<1:06:53,  9.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 786/39873 [01:24<1:06:34,  9.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 788/39873 [01:24<1:06:25,  9.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 790/39873 [01:24<1:02:57, 10.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 792/39873 [01:24<1:04:24, 10.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 794/39873 [01:24<1:02:56, 10.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 796/39873 [01:24<1:02:53, 10.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 798/39873 [01:25<1:16:12,  8.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 799/39873 [01:25<1:15:23,  8.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 800/39873 [01:25<1:18:32,  8.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 801/39873 [01:25<1:18:15,  8.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 803/39873 [01:25<1:16:39,  8.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 805/39873 [01:26<1:09:40,  9.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 807/39873 [01:26<1:06:52,  9.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 809/39873 [01:26<1:07:50,  9.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 810/39873 [01:26<1:09:24,  9.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 812/39873 [01:26<1:05:30,  9.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 814/39873 [01:26<1:04:27, 10.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 816/39873 [01:27<1:03:35, 10.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 818/39873 [01:27<1:00:32, 10.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 820/39873 [01:27<59:02, 11.02it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 822/39873 [01:27<58:33, 11.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 824/39873 [01:27<56:37, 11.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 826/39873 [01:28<1:00:53, 10.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 828/39873 [01:28<59:56, 10.86it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 830/39873 [01:28<58:44, 11.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 832/39873 [01:28<1:00:28, 10.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 834/39873 [01:28<1:00:24, 10.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 836/39873 [01:28<1:00:49, 10.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 838/39873 [01:29<59:57, 10.85it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 840/39873 [01:29<1:00:52, 10.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 842/39873 [01:29<1:01:25, 10.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 844/39873 [01:29<1:01:40, 10.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 846/39873 [01:29<1:06:41,  9.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 847/39873 [01:30<1:07:49,  9.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 849/39873 [01:30<1:14:41,  8.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 850/39873 [01:30<1:42:24,  6.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 851/39873 [01:30<1:32:47,  7.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 853/39873 [01:30<1:20:41,  8.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 854/39873 [01:30<1:22:57,  7.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 855/39873 [01:31<1:26:51,  7.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 856/39873 [01:31<1:20:52,  8.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 857/39873 [01:31<1:23:37,  7.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 858/39873 [01:31<1:22:35,  7.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 859/39873 [01:31<1:24:02,  7.74it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 861/39873 [01:31<1:17:47,  8.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 863/39873 [01:31<1:11:10,  9.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 864/39873 [01:32<1:16:49,  8.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 865/39873 [01:32<1:17:21,  8.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 866/39873 [01:32<1:18:45,  8.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 867/39873 [01:32<1:17:31,  8.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 868/39873 [01:32<1:14:38,  8.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 870/39873 [01:32<1:08:01,  9.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 871/39873 [01:32<1:11:13,  9.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 873/39873 [01:33<1:06:22,  9.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 875/39873 [01:33<1:11:30,  9.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 876/39873 [01:33<1:11:42,  9.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 877/39873 [01:33<1:10:55,  9.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 879/39873 [01:33<1:11:21,  9.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 880/39873 [01:33<1:12:36,  8.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 882/39873 [01:34<1:09:13,  9.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 884/39873 [01:34<1:05:52,  9.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 886/39873 [01:34<1:01:32, 10.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 888/39873 [01:34<1:00:08, 10.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 890/39873 [01:34<1:04:53, 10.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 892/39873 [01:34<1:03:20, 10.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 894/39873 [01:35<1:01:40, 10.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 896/39873 [01:35<1:00:42, 10.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 898/39873 [01:35<57:56, 11.21it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 900/39873 [01:35<1:04:16, 10.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 902/39873 [01:35<1:02:54, 10.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 904/39873 [01:36<1:03:08, 10.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 906/39873 [01:36<1:01:24, 10.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 908/39873 [01:36<1:03:26, 10.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 910/39873 [01:36<1:02:51, 10.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 912/39873 [01:36<59:20, 10.94it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 914/39873 [01:37<59:33, 10.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 916/39873 [01:37<58:23, 11.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 918/39873 [01:37<57:10, 11.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 920/39873 [01:37<57:40, 11.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 922/39873 [01:37<56:49, 11.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 924/39873 [01:37<57:24, 11.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 926/39873 [01:38<56:15, 11.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 928/39873 [01:38<1:02:07, 10.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 930/39873 [01:38<1:03:17, 10.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 932/39873 [01:38<1:02:06, 10.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 934/39873 [01:38<1:06:54,  9.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 935/39873 [01:39<1:08:41,  9.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 936/39873 [01:39<1:08:36,  9.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 937/39873 [01:39<1:08:19,  9.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 939/39873 [01:39<1:00:36, 10.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 941/39873 [01:39<54:18, 11.95it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 943/39873 [01:39<57:21, 11.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 945/39873 [01:39<56:42, 11.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 947/39873 [01:40<55:40, 11.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 949/39873 [01:40<54:56, 11.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 951/39873 [01:40<54:52, 11.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 953/39873 [01:40<59:33, 10.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 955/39873 [01:40<1:13:43,  8.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 956/39873 [01:41<1:13:24,  8.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 957/39873 [01:41<1:13:11,  8.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 958/39873 [01:41<1:12:01,  9.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 959/39873 [01:41<1:15:26,  8.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 960/39873 [01:41<1:22:44,  7.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 962/39873 [01:41<1:18:36,  8.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 963/39873 [01:41<1:15:26,  8.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 964/39873 [01:41<1:13:19,  8.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 966/39873 [01:42<1:06:59,  9.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 968/39873 [01:42<1:05:24,  9.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 970/39873 [01:42<1:08:38,  9.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 972/39873 [01:42<1:04:36, 10.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 974/39873 [01:42<1:04:06, 10.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 976/39873 [01:43<58:14, 11.13it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 978/39873 [01:43<59:37, 10.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 980/39873 [01:43<1:05:14,  9.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 982/39873 [01:43<1:08:33,  9.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 984/39873 [01:43<1:07:08,  9.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 985/39873 [01:44<1:22:36,  7.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 987/39873 [01:44<1:15:50,  8.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 988/39873 [01:44<1:12:44,  8.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 989/39873 [01:44<1:15:32,  8.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 990/39873 [01:44<1:15:07,  8.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 991/39873 [01:44<1:14:17,  8.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 992/39873 [01:44<1:12:44,  8.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 994/39873 [01:44<1:04:07, 10.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|         | 996/39873 [01:45<1:03:35, 10.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 998/39873 [01:45<59:11, 10.95it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1000/39873 [01:45<57:39, 11.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1002/39873 [01:45<59:18, 10.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1004/39873 [01:45<1:01:15, 10.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1006/39873 [01:46<1:01:32, 10.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1008/39873 [01:46<1:05:53,  9.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1010/39873 [01:46<1:09:50,  9.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1012/39873 [01:46<1:04:21, 10.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1014/39873 [01:46<1:03:10, 10.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1016/39873 [01:47<1:00:44, 10.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1018/39873 [01:47<1:04:41, 10.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1020/39873 [01:47<1:06:02,  9.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1022/39873 [01:47<1:03:20, 10.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1024/39873 [01:47<1:04:29, 10.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1026/39873 [01:48<1:07:24,  9.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1028/39873 [01:48<1:06:38,  9.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1029/39873 [01:48<1:06:44,  9.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1030/39873 [01:48<1:09:03,  9.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1031/39873 [01:48<1:09:03,  9.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1032/39873 [01:48<1:12:13,  8.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1034/39873 [01:48<1:07:26,  9.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1035/39873 [01:49<1:11:33,  9.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1037/39873 [01:49<1:02:48, 10.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1039/39873 [01:49<1:04:40, 10.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1041/39873 [01:49<1:07:43,  9.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1043/39873 [01:49<1:06:53,  9.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1045/39873 [01:50<1:06:04,  9.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1047/39873 [01:50<1:05:06,  9.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1049/39873 [01:50<1:04:03, 10.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1051/39873 [01:50<1:06:29,  9.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1053/39873 [01:50<1:01:10, 10.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1055/39873 [01:50<1:00:05, 10.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1057/39873 [01:51<1:04:01, 10.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1059/39873 [01:51<1:07:40,  9.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1060/39873 [01:51<1:22:38,  7.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1061/39873 [01:51<1:20:18,  8.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1062/39873 [01:51<1:19:29,  8.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1063/39873 [01:51<1:17:02,  8.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1065/39873 [01:52<1:13:56,  8.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1066/39873 [01:52<1:13:10,  8.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1067/39873 [01:52<1:15:13,  8.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1069/39873 [01:52<1:08:35,  9.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1070/39873 [01:52<1:09:37,  9.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1072/39873 [01:52<1:06:42,  9.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1074/39873 [01:53<1:03:56, 10.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1076/39873 [01:53<1:04:18, 10.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1078/39873 [01:53<1:03:29, 10.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1080/39873 [01:53<1:02:37, 10.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1082/39873 [01:53<1:00:25, 10.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1084/39873 [01:54<1:00:08, 10.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1086/39873 [01:54<1:01:30, 10.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1088/39873 [01:54<1:01:26, 10.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1090/39873 [01:54<1:00:41, 10.65it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 1092/39873 [01:54<57:53, 11.16it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1094/39873 [01:54<55:20, 11.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1096/39873 [01:55<1:00:07, 10.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1098/39873 [01:55<1:00:49, 10.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1100/39873 [01:55<55:44, 11.59it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1102/39873 [01:55<59:38, 10.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1104/39873 [01:55<58:28, 11.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1106/39873 [01:56<1:00:27, 10.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1108/39873 [01:56<1:06:19,  9.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1110/39873 [01:56<1:07:08,  9.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1112/39873 [01:56<1:05:35,  9.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1114/39873 [01:56<1:05:29,  9.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1116/39873 [01:57<1:05:30,  9.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1118/39873 [01:57<1:04:11, 10.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1120/39873 [01:57<1:01:49, 10.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1122/39873 [01:57<59:29, 10.86it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1124/39873 [01:57<1:01:34, 10.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1126/39873 [01:58<1:03:00, 10.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1128/39873 [01:58<1:03:44, 10.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1130/39873 [01:58<1:05:52,  9.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1131/39873 [01:58<1:09:08,  9.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1132/39873 [01:58<1:10:50,  9.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1134/39873 [01:58<1:04:49,  9.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1136/39873 [01:59<1:04:57,  9.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1138/39873 [01:59<1:06:09,  9.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1139/39873 [01:59<1:15:09,  8.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1141/39873 [01:59<1:06:54,  9.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1143/39873 [01:59<1:01:31, 10.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1145/39873 [01:59<1:02:22, 10.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1147/39873 [02:00<59:43, 10.81it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1149/39873 [02:00<59:31, 10.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1151/39873 [02:00<1:01:24, 10.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1153/39873 [02:00<1:07:23,  9.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1155/39873 [02:00<1:04:21, 10.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1157/39873 [02:01<1:02:29, 10.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1159/39873 [02:01<59:12, 10.90it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1161/39873 [02:01<57:12, 11.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1163/39873 [02:01<1:14:11,  8.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1164/39873 [02:01<1:13:28,  8.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1165/39873 [02:01<1:18:44,  8.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1166/39873 [02:02<1:18:38,  8.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1167/39873 [02:02<1:15:08,  8.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1169/39873 [02:02<1:08:12,  9.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1170/39873 [02:02<1:07:49,  9.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1171/39873 [02:02<1:12:45,  8.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1172/39873 [02:02<1:17:00,  8.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1173/39873 [02:02<1:32:40,  6.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1174/39873 [02:03<1:33:13,  6.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1175/39873 [02:03<1:29:35,  7.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1177/39873 [02:03<1:18:58,  8.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1178/39873 [02:03<1:15:02,  8.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1180/39873 [02:03<1:08:32,  9.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1182/39873 [02:03<1:08:13,  9.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1183/39873 [02:03<1:07:42,  9.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1185/39873 [02:04<1:06:17,  9.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1186/39873 [02:04<1:08:00,  9.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1188/39873 [02:04<1:05:12,  9.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1190/39873 [02:04<1:00:22, 10.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1192/39873 [02:04<1:00:48, 10.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1194/39873 [02:04<1:00:25, 10.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1196/39873 [02:05<55:50, 11.54it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1198/39873 [02:05<1:03:55, 10.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1200/39873 [02:05<59:06, 10.91it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1202/39873 [02:05<59:45, 10.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1204/39873 [02:05<59:13, 10.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1206/39873 [02:06<58:06, 11.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1208/39873 [02:06<57:48, 11.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1210/39873 [02:06<1:00:51, 10.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1212/39873 [02:06<1:00:17, 10.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1214/39873 [02:06<59:56, 10.75it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1216/39873 [02:07<1:01:02, 10.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1218/39873 [02:07<1:01:57, 10.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1220/39873 [02:07<1:05:31,  9.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1221/39873 [02:07<1:07:59,  9.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1222/39873 [02:07<1:11:54,  8.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1224/39873 [02:07<1:07:06,  9.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1225/39873 [02:07<1:09:05,  9.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1226/39873 [02:08<1:08:31,  9.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1227/39873 [02:08<1:10:22,  9.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1229/39873 [02:08<1:07:16,  9.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1230/39873 [02:08<1:15:26,  8.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1232/39873 [02:08<1:07:42,  9.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1234/39873 [02:08<1:06:45,  9.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1236/39873 [02:09<1:05:48,  9.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1238/39873 [02:09<1:00:48, 10.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1240/39873 [02:09<1:03:10, 10.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1242/39873 [02:09<59:30, 10.82it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1244/39873 [02:09<59:47, 10.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1246/39873 [02:09<59:05, 10.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1248/39873 [02:10<1:02:30, 10.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1250/39873 [02:10<1:07:09,  9.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1252/39873 [02:10<1:01:43, 10.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1254/39873 [02:10<1:04:53,  9.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1256/39873 [02:11<1:03:03, 10.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1258/39873 [02:11<1:07:57,  9.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1259/39873 [02:11<1:06:58,  9.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1261/39873 [02:11<1:06:29,  9.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1262/39873 [02:11<1:07:18,  9.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1264/39873 [02:11<1:05:08,  9.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1265/39873 [02:11<1:10:48,  9.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1266/39873 [02:12<1:10:32,  9.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1268/39873 [02:12<1:08:13,  9.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1270/39873 [02:12<1:05:36,  9.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1272/39873 [02:12<1:03:18, 10.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1274/39873 [02:12<59:45, 10.77it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1276/39873 [02:12<59:37, 10.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1278/39873 [02:13<58:16, 11.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1280/39873 [02:13<1:00:34, 10.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1282/39873 [02:13<54:44, 11.75it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1284/39873 [02:13<54:53, 11.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1286/39873 [02:13<1:01:20, 10.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1288/39873 [02:14<1:00:18, 10.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1290/39873 [02:14<56:13, 11.44it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1292/39873 [02:14<56:56, 11.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1294/39873 [02:14<1:00:54, 10.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1296/39873 [02:14<58:17, 11.03it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1298/39873 [02:14<58:27, 11.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1300/39873 [02:15<1:00:15, 10.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1302/39873 [02:15<1:01:43, 10.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1304/39873 [02:15<1:00:36, 10.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1306/39873 [02:15<56:22, 11.40it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1308/39873 [02:15<59:36, 10.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1310/39873 [02:16<1:04:21,  9.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1312/39873 [02:16<59:20, 10.83it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1314/39873 [02:16<1:02:37, 10.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1316/39873 [02:16<1:00:25, 10.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1318/39873 [02:16<1:01:23, 10.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1320/39873 [02:17<1:12:09,  8.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1322/39873 [02:17<1:07:53,  9.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1324/39873 [02:17<1:07:33,  9.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1326/39873 [02:17<1:04:44,  9.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1328/39873 [02:17<59:33, 10.79it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1330/39873 [02:18<1:05:07,  9.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1332/39873 [02:18<1:06:45,  9.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1333/39873 [02:18<1:07:51,  9.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1334/39873 [02:18<1:07:15,  9.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1335/39873 [02:18<1:08:01,  9.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1337/39873 [02:18<1:03:28, 10.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1339/39873 [02:19<1:02:46, 10.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1341/39873 [02:19<1:02:59, 10.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1343/39873 [02:19<1:03:16, 10.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1345/39873 [02:19<1:02:46, 10.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1347/39873 [02:19<1:04:01, 10.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1349/39873 [02:20<1:04:43,  9.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1351/39873 [02:20<1:02:45, 10.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1353/39873 [02:20<1:03:24, 10.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1355/39873 [02:20<1:05:16,  9.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1357/39873 [02:20<59:52, 10.72it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1359/39873 [02:20<59:07, 10.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1361/39873 [02:21<1:03:17, 10.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1363/39873 [02:21<1:02:23, 10.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1365/39873 [02:21<1:06:14,  9.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1367/39873 [02:21<1:04:28,  9.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1369/39873 [02:22<1:10:55,  9.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1370/39873 [02:22<1:10:29,  9.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1371/39873 [02:22<1:16:34,  8.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1372/39873 [02:22<1:14:43,  8.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1373/39873 [02:22<1:25:46,  7.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1375/39873 [02:22<1:15:19,  8.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1377/39873 [02:22<1:07:48,  9.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1379/39873 [02:23<1:08:31,  9.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1380/39873 [02:23<1:09:15,  9.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1382/39873 [02:23<1:04:39,  9.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1384/39873 [02:23<1:04:47,  9.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1386/39873 [02:23<1:03:20, 10.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1388/39873 [02:24<1:01:47, 10.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1390/39873 [02:24<1:00:49, 10.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1392/39873 [02:24<1:06:21,  9.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|         | 1394/39873 [02:24<1:01:19, 10.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1396/39873 [02:24<58:02, 11.05it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1398/39873 [02:24<59:33, 10.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1400/39873 [02:25<1:00:24, 10.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1402/39873 [02:25<1:00:25, 10.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1404/39873 [02:25<1:01:32, 10.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1406/39873 [02:25<1:04:51,  9.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1408/39873 [02:25<1:05:15,  9.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1410/39873 [02:26<1:04:02, 10.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1412/39873 [02:26<1:01:34, 10.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1414/39873 [02:26<1:02:38, 10.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1416/39873 [02:26<1:00:41, 10.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1418/39873 [02:26<54:57, 11.66it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1420/39873 [02:26<54:56, 11.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1422/39873 [02:27<58:57, 10.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1424/39873 [02:27<1:09:43,  9.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1426/39873 [02:27<1:06:26,  9.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1428/39873 [02:27<1:08:33,  9.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1429/39873 [02:28<1:07:35,  9.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1431/39873 [02:28<1:05:11,  9.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1433/39873 [02:28<1:04:53,  9.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1435/39873 [02:28<1:06:16,  9.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1437/39873 [02:28<1:02:22, 10.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1439/39873 [02:29<1:05:00,  9.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1441/39873 [02:29<1:06:31,  9.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1442/39873 [02:29<1:09:28,  9.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1443/39873 [02:29<1:08:15,  9.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1445/39873 [02:29<1:06:05,  9.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1446/39873 [02:29<1:08:38,  9.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1448/39873 [02:29<1:08:34,  9.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1450/39873 [02:30<1:02:51, 10.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1452/39873 [02:30<1:00:55, 10.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1454/39873 [02:30<59:12, 10.81it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1456/39873 [02:30<1:02:31, 10.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1458/39873 [02:30<57:22, 11.16it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1460/39873 [02:31<1:06:30,  9.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1462/39873 [02:31<1:10:17,  9.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1463/39873 [02:31<1:09:58,  9.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1464/39873 [02:31<1:12:10,  8.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1465/39873 [02:31<1:10:06,  9.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1467/39873 [02:31<1:07:01,  9.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1469/39873 [02:32<1:05:13,  9.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1471/39873 [02:32<1:03:12, 10.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1473/39873 [02:32<1:21:32,  7.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1475/39873 [02:32<1:19:57,  8.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1476/39873 [02:33<1:19:34,  8.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1478/39873 [02:33<1:13:21,  8.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1480/39873 [02:33<1:07:49,  9.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1482/39873 [02:33<1:04:49,  9.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1484/39873 [02:33<1:05:40,  9.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1486/39873 [02:33<1:02:10, 10.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1488/39873 [02:34<1:02:49, 10.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1490/39873 [02:34<59:43, 10.71it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1492/39873 [02:34<1:03:09, 10.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1494/39873 [02:34<58:03, 11.02it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1496/39873 [02:34<59:30, 10.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1498/39873 [02:35<59:31, 10.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1500/39873 [02:35<59:26, 10.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1502/39873 [02:35<54:10, 11.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1504/39873 [02:35<56:09, 11.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1506/39873 [02:35<56:57, 11.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1508/39873 [02:35<58:12, 10.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1510/39873 [02:36<58:26, 10.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1512/39873 [02:36<1:03:31, 10.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1514/39873 [02:36<1:00:47, 10.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1516/39873 [02:36<1:02:05, 10.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1518/39873 [02:36<1:01:32, 10.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1520/39873 [02:37<1:01:55, 10.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1522/39873 [02:37<1:01:14, 10.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1524/39873 [02:37<1:00:36, 10.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1526/39873 [02:37<1:02:31, 10.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1528/39873 [02:38<1:26:17,  7.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1529/39873 [02:38<1:30:36,  7.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1530/39873 [02:38<1:24:00,  7.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1531/39873 [02:38<1:24:29,  7.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1532/39873 [02:38<1:21:18,  7.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1533/39873 [02:38<1:23:56,  7.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1534/39873 [02:38<1:28:19,  7.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1535/39873 [02:39<1:29:11,  7.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1537/39873 [02:39<1:20:30,  7.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1538/39873 [02:39<1:21:09,  7.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1539/39873 [02:39<1:17:09,  8.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1541/39873 [02:39<1:12:52,  8.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1543/39873 [02:39<1:07:15,  9.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1544/39873 [02:39<1:11:06,  8.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1546/39873 [02:40<1:05:14,  9.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1548/39873 [02:40<1:03:50, 10.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1550/39873 [02:40<1:05:27,  9.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1551/39873 [02:40<1:12:02,  8.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1553/39873 [02:40<1:06:21,  9.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1555/39873 [02:41<1:07:45,  9.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1556/39873 [02:41<1:12:37,  8.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1558/39873 [02:41<1:12:10,  8.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1560/39873 [02:41<1:12:40,  8.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1562/39873 [02:41<1:11:23,  8.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1564/39873 [02:42<1:06:11,  9.65it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 1565/39873 [02:42<1:07:26,  9.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1567/39873 [02:42<1:01:35, 10.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1569/39873 [02:42<1:01:59, 10.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1571/39873 [02:42<1:01:51, 10.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1573/39873 [02:42<1:02:42, 10.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1575/39873 [02:43<1:03:17, 10.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1577/39873 [02:43<1:16:13,  8.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1578/39873 [02:43<1:17:17,  8.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1580/39873 [02:43<1:14:36,  8.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1581/39873 [02:43<1:12:05,  8.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1583/39873 [02:44<1:08:20,  9.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1585/39873 [02:44<1:09:07,  9.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1586/39873 [02:44<1:08:29,  9.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1587/39873 [02:44<1:13:19,  8.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1589/39873 [02:44<1:12:23,  8.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1591/39873 [02:44<1:08:41,  9.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1592/39873 [02:45<1:07:48,  9.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1594/39873 [02:45<1:05:48,  9.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1595/39873 [02:45<1:08:20,  9.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1597/39873 [02:45<1:02:01, 10.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1599/39873 [02:45<1:06:23,  9.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1601/39873 [02:45<1:01:37, 10.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1603/39873 [02:46<1:04:30,  9.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1605/39873 [02:46<1:05:05,  9.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1607/39873 [02:46<1:02:38, 10.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1609/39873 [02:46<1:01:30, 10.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1611/39873 [02:46<59:57, 10.64it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1613/39873 [02:47<59:31, 10.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1615/39873 [02:47<1:01:40, 10.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1617/39873 [02:47<1:06:58,  9.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1619/39873 [02:47<1:02:35, 10.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1621/39873 [02:47<1:01:34, 10.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1623/39873 [02:48<59:19, 10.74it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1625/39873 [02:48<55:39, 11.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1627/39873 [02:48<1:20:08,  7.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1628/39873 [02:48<1:17:10,  8.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1629/39873 [02:48<1:13:19,  8.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1630/39873 [02:48<1:12:01,  8.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1632/39873 [02:49<1:06:42,  9.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1634/39873 [02:49<1:05:48,  9.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1636/39873 [02:49<1:00:03, 10.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1638/39873 [02:49<1:01:18, 10.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1640/39873 [02:49<1:01:51, 10.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1642/39873 [02:50<1:06:23,  9.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1643/39873 [02:50<1:06:51,  9.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1645/39873 [02:50<1:02:52, 10.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1647/39873 [02:50<57:28, 11.09it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1649/39873 [02:50<59:21, 10.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1651/39873 [02:50<1:01:50, 10.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1653/39873 [02:51<1:01:34, 10.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1655/39873 [02:51<1:07:49,  9.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1657/39873 [02:51<1:03:40, 10.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1659/39873 [02:51<1:01:35, 10.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1661/39873 [02:51<1:01:28, 10.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1663/39873 [02:52<1:06:01,  9.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1665/39873 [02:52<1:02:21, 10.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1667/39873 [02:52<1:04:01,  9.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1669/39873 [02:52<1:06:19,  9.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1671/39873 [02:52<1:02:48, 10.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1673/39873 [02:53<59:37, 10.68it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1675/39873 [02:53<59:58, 10.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1677/39873 [02:53<59:56, 10.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1679/39873 [02:53<58:41, 10.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1681/39873 [02:53<1:10:37,  9.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1683/39873 [02:54<1:06:11,  9.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1685/39873 [02:54<1:04:19,  9.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1687/39873 [02:54<1:05:50,  9.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1688/39873 [02:54<1:05:38,  9.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1690/39873 [02:54<1:02:15, 10.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1692/39873 [02:54<59:45, 10.65it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1694/39873 [02:55<1:00:12, 10.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1696/39873 [02:55<1:00:12, 10.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1698/39873 [02:55<1:00:29, 10.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1700/39873 [02:55<56:39, 11.23it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1702/39873 [02:55<53:31, 11.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1704/39873 [02:56<54:48, 11.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1706/39873 [02:56<53:48, 11.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1708/39873 [02:56<56:24, 11.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1710/39873 [02:56<1:02:14, 10.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1712/39873 [02:56<1:05:12,  9.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1714/39873 [02:57<1:00:44, 10.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1716/39873 [02:57<1:01:41, 10.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1718/39873 [02:57<1:07:58,  9.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1719/39873 [02:57<1:08:21,  9.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1720/39873 [02:57<1:11:46,  8.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1722/39873 [02:57<1:08:33,  9.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1723/39873 [02:58<1:08:14,  9.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1725/39873 [02:58<1:04:42,  9.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1726/39873 [02:58<1:04:46,  9.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1728/39873 [02:58<1:03:06, 10.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1730/39873 [02:58<1:02:56, 10.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1732/39873 [02:58<1:14:04,  8.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1733/39873 [02:59<1:28:19,  7.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1735/39873 [02:59<1:17:45,  8.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1737/39873 [02:59<1:08:53,  9.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1739/39873 [02:59<1:07:47,  9.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1741/39873 [02:59<1:08:29,  9.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1742/39873 [03:00<1:08:08,  9.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1744/39873 [03:00<1:02:30, 10.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1746/39873 [03:00<1:00:59, 10.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1748/39873 [03:00<1:01:51, 10.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1750/39873 [03:00<1:01:42, 10.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1752/39873 [03:00<56:38, 11.22it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1754/39873 [03:01<1:00:04, 10.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1756/39873 [03:01<58:20, 10.89it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1758/39873 [03:01<58:48, 10.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1760/39873 [03:01<58:56, 10.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1762/39873 [03:01<59:37, 10.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1764/39873 [03:02<1:05:30,  9.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1765/39873 [03:02<1:07:31,  9.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1767/39873 [03:02<1:03:23, 10.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1769/39873 [03:02<1:07:08,  9.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1771/39873 [03:02<1:06:59,  9.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1773/39873 [03:03<1:04:56,  9.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1775/39873 [03:03<1:02:17, 10.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1777/39873 [03:03<1:01:00, 10.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1779/39873 [03:03<56:10, 11.30it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1781/39873 [03:03<1:02:52, 10.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1783/39873 [03:03<1:01:37, 10.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1785/39873 [03:04<1:07:51,  9.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1787/39873 [03:04<1:05:54,  9.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1788/39873 [03:04<1:06:18,  9.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1790/39873 [03:04<1:05:34,  9.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1792/39873 [03:04<1:02:44, 10.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|         | 1794/39873 [03:05<1:05:45,  9.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|         | 1796/39873 [03:05<1:02:58, 10.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|         | 1798/39873 [03:05<1:00:19, 10.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|         | 1800/39873 [03:05<1:01:34, 10.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|         | 1802/39873 [03:05<1:04:34,  9.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|         | 1804/39873 [03:06<1:03:44,  9.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|         | 1806/39873 [03:06<1:03:17, 10.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|         | 1808/39873 [03:06<1:03:01, 10.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|         | 1810/39873 [03:06<1:04:29,  9.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|         | 1811/39873 [03:06<1:11:05,  8.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|         | 1812/39873 [03:06<1:12:17,  8.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|         | 1813/39873 [03:07<1:14:18,  8.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|         | 1815/39873 [03:07<1:10:07,  9.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|         | 1817/39873 [03:07<1:02:27, 10.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|         | 1819/39873 [03:07<1:02:31, 10.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|         | 1821/39873 [03:07<1:00:01, 10.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|         | 1823/39873 [03:07<56:22, 11.25it/s]  \u001b[A\u001b[A\n",
      "\n",
      "  5%|         | 1825/39873 [03:08<53:24, 11.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|         | 1827/39873 [03:08<55:27, 11.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|         | 1829/39873 [03:08<1:00:15, 10.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|         | 1831/39873 [03:08<1:01:55, 10.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|         | 1833/39873 [03:08<1:01:36, 10.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|         | 1835/39873 [03:09<1:08:26,  9.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|         | 1836/39873 [03:09<1:34:52,  6.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|         | 1837/39873 [03:09<1:42:17,  6.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|         | 1839/39873 [03:09<1:33:08,  6.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|         | 1840/39873 [03:09<1:27:05,  7.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|         | 1841/39873 [03:10<1:22:01,  7.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|         | 1842/39873 [03:10<1:24:46,  7.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|         | 1844/39873 [03:10<1:15:53,  8.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|         | 1845/39873 [03:10<1:15:47,  8.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|         | 1847/39873 [03:10<1:07:56,  9.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|         | 1848/39873 [03:10<1:07:10,  9.43it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-823ada0845a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/face/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/face/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/face/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/face/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/face/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/face/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/face/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for inputs, labels in tqdm(trainloader):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/39873 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[AException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f0761393a70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tampm/miniconda3/envs/face/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/tampm/miniconda3/envs/face/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/tampm/miniconda3/envs/face/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 1/39873 [00:00<5:12:48,  2.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 3/39873 [00:00<3:59:14,  2.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 4/39873 [00:00<3:14:06,  3.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 5/39873 [00:00<2:37:21,  4.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 6/39873 [00:01<2:18:22,  4.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 7/39873 [00:01<2:00:30,  5.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 8/39873 [00:01<1:45:57,  6.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 10/39873 [00:01<1:34:51,  7.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 11/39873 [00:01<1:27:19,  7.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 12/39873 [00:01<1:27:54,  7.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 13/39873 [00:01<1:22:59,  8.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 14/39873 [00:01<1:27:21,  7.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 15/39873 [00:02<1:29:46,  7.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 16/39873 [00:02<1:28:19,  7.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 18/39873 [00:02<1:23:23,  7.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 19/39873 [00:02<1:23:53,  7.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 20/39873 [00:02<1:28:45,  7.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 21/39873 [00:02<1:29:26,  7.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 22/39873 [00:03<1:31:42,  7.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 24/39873 [00:03<1:34:50,  7.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 25/39873 [00:03<2:00:08,  5.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 26/39873 [00:03<1:48:16,  6.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 27/39873 [00:03<1:42:22,  6.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 28/39873 [00:04<1:42:35,  6.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 29/39873 [00:04<1:37:25,  6.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 30/39873 [00:04<1:30:21,  7.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 31/39873 [00:04<1:26:20,  7.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 32/39873 [00:04<1:26:50,  7.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 34/39873 [00:04<1:21:52,  8.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 35/39873 [00:04<1:23:59,  7.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 36/39873 [00:05<1:35:25,  6.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-b96504ac8c4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/face/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                     \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 10\n",
    "train_losses, test_losses = [], []\n",
    "for epoch in range(epochs):\n",
    "    for inputs, labels in tqdm(trainloader):\n",
    "#     for inputs, labels in tqdm(testloader):\n",
    "\n",
    "        steps += 1\n",
    "#         labels = np.array([labels])\n",
    "        inputs, labels = inputs.to(device), labels.float().to(device)\n",
    "#         inputs, labels = inputs.to(device), labels[1].float().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logps = model.forward(inputs)[:,0]\n",
    "#         loss = criterion(logps, labels)\n",
    "        loss = F.binary_cross_entropy_with_logits(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in testloader:\n",
    "                    inputs, labels = inputs.to(device),labels.float().to(device)\n",
    "                    logps = model.forward(inputs)[:,0]\n",
    "                    batch_loss = criterion(logps, labels)\n",
    "                    test_loss += batch_loss.item()\n",
    "                    equals = labels == (logps >0.5)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "                  f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
    "                  f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
    "            running_loss = 0\n",
    "            model.train()\n",
    "            \n",
    "            #######################\n",
    "#             with torch.no_grad():\n",
    "#                 for inputs, labels in testloader:\n",
    "#                     inputs, labels = inputs.to(device),labels.float().to(device)\n",
    "#                     logps = model.forward(inputs)\n",
    "#                     batch_loss = criterion(logps, labels)\n",
    "#                     test_loss += batch_loss.item()\n",
    "                    \n",
    "#                     ps = torch.exp(logps)\n",
    "#                     top_p, top_class = ps.topk(1, dim=1)\n",
    "#                     equals = top_class == labels.view(*top_class.shape)\n",
    "#                     accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "#             train_losses.append(running_loss/len(trainloader))\n",
    "#             test_losses.append(test_loss/len(testloader))                    \n",
    "#             print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "#                   f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "#                   f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
    "#                   f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
    "#             running_loss = 0\n",
    "#             model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
